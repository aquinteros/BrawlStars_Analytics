2023-06-10 21:23:09,609:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:23:09,610:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:23:09,610:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:23:09,610:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:23:10,828:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-10 21:27:02,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:27:02,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:27:02,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:27:02,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:27:04,249:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-10 21:28:47,089:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:28:47,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:28:47,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:28:47,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:28:48,925:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-11 20:53:15,586:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 20:53:15,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 20:53:15,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 20:53:15,593:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 20:53:19,763:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-11 20:53:35,707:INFO:Initializing load_model()
2023-06-11 20:53:35,708:INFO:load_model(model_name=bs_predictor, platform=None, authentication=None, verbose=True)
2023-06-11 20:53:57,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 20:53:57,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 20:53:57,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 20:53:57,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 20:53:58,770:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-11 20:54:06,229:INFO:Initializing load_model()
2023-06-11 20:54:06,230:INFO:load_model(model_name=bs_predictor, platform=None, authentication=None, verbose=True)
2023-06-11 20:54:07,977:INFO:Initializing predict_model()
2023-06-11 20:54:07,977:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216F2B781C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['barriers', 'barriers_center',
                                             'bushes', 'bushes_center',
                                             'waterProp',
                                             'avg_brawler_Range_Num_diff',
                                             'avg_brawler_trophies_diff',
                                             'avg_brawler_...
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=4813))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('feature_selection',
                 TransformerWrapper(exclude=[],
                                    transformer=SelectFromModel(estimator=LGBMClassifier(),
                                                                max_features=13,
                                                                threshold=-inf))),
                ('actual_estimator', LGBMClassifier(random_state=4813))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000216DBF4FB50>)
2023-06-11 20:54:07,977:INFO:Checking exceptions
2023-06-11 20:54:07,977:INFO:Preloading libraries
2023-06-11 20:54:07,977:INFO:Set up data.
2023-06-11 20:54:08,030:INFO:Set up index.
2023-06-11 20:56:26,592:INFO:Initializing predict_model()
2023-06-11 20:56:26,592:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216F1EC4430>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['barriers', 'barriers_center',
                                             'bushes', 'bushes_center',
                                             'waterProp',
                                             'avg_brawler_Range_Num_diff',
                                             'avg_brawler_trophies_diff',
                                             'avg_brawler_...
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=4813))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('feature_selection',
                 TransformerWrapper(exclude=[],
                                    transformer=SelectFromModel(estimator=LGBMClassifier(),
                                                                max_features=13,
                                                                threshold=-inf))),
                ('actual_estimator', LGBMClassifier(random_state=4813))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000216DBF4DBD0>)
2023-06-11 20:56:26,592:INFO:Checking exceptions
2023-06-11 20:56:26,592:INFO:Preloading libraries
2023-06-11 20:56:26,593:INFO:Set up data.
2023-06-11 20:56:26,690:INFO:Set up index.
2023-06-11 21:45:05,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 21:45:05,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 21:45:05,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 21:45:05,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 21:45:09,419:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-11 21:45:31,009:INFO:Initializing load_model()
2023-06-11 21:45:31,010:INFO:load_model(model_name=models/bs_predictor, platform=None, authentication=None, verbose=True)
2023-06-11 21:56:38,042:INFO:PyCaret ClassificationExperiment
2023-06-11 21:56:38,042:INFO:Logging name: clf-default-name
2023-06-11 21:56:38,042:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-11 21:56:38,042:INFO:version 3.0.2
2023-06-11 21:56:38,043:INFO:Initializing setup()
2023-06-11 21:56:38,043:INFO:self.USI: 6e20
2023-06-11 21:56:38,043:INFO:self._variable_keys: {'X', 'fold_generator', 'is_multiclass', 'logging_param', 'fold_groups_param', 'exp_id', 'data', 'gpu_param', 'log_plots_param', 'idx', 'seed', 'memory', 'X_test', 'target_param', 'y_train', 'gpu_n_jobs_param', '_available_plots', '_ml_usecase', 'y_test', 'html_param', 'pipeline', 'exp_name_log', 'n_jobs_param', 'X_train', 'y', 'fix_imbalance', 'USI', 'fold_shuffle_param'}
2023-06-11 21:56:38,043:INFO:Checking environment
2023-06-11 21:56:38,044:INFO:python_version: 3.10.10
2023-06-11 21:56:38,044:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-11 21:56:38,044:INFO:machine: AMD64
2023-06-11 21:56:38,044:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-11 21:56:38,047:INFO:Memory: svmem(total=17034072064, available=9568903168, percent=43.8, used=7465168896, free=9568903168)
2023-06-11 21:56:38,047:INFO:Physical Core: 2
2023-06-11 21:56:38,047:INFO:Logical Core: 4
2023-06-11 21:56:38,047:INFO:Checking libraries
2023-06-11 21:56:38,047:INFO:System:
2023-06-11 21:56:38,048:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-11 21:56:38,048:INFO:executable: c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-11 21:56:38,048:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-11 21:56:38,048:INFO:PyCaret required dependencies:
2023-06-11 21:56:38,048:INFO:                 pip: 23.1.2
2023-06-11 21:56:38,048:INFO:          setuptools: 65.5.0
2023-06-11 21:56:38,048:INFO:             pycaret: 3.0.2
2023-06-11 21:56:38,049:INFO:             IPython: 8.14.0
2023-06-11 21:56:38,049:INFO:          ipywidgets: 8.0.6
2023-06-11 21:56:38,049:INFO:                tqdm: 4.65.0
2023-06-11 21:56:38,049:INFO:               numpy: 1.23.5
2023-06-11 21:56:38,049:INFO:              pandas: 1.5.3
2023-06-11 21:56:38,049:INFO:              jinja2: 3.1.2
2023-06-11 21:56:38,049:INFO:               scipy: 1.10.1
2023-06-11 21:56:38,049:INFO:              joblib: 1.2.0
2023-06-11 21:56:38,049:INFO:             sklearn: 1.2.2
2023-06-11 21:56:38,050:INFO:                pyod: 1.0.9
2023-06-11 21:56:38,050:INFO:            imblearn: 0.10.1
2023-06-11 21:56:38,050:INFO:   category_encoders: 2.6.1
2023-06-11 21:56:38,050:INFO:            lightgbm: 3.3.5
2023-06-11 21:56:38,050:INFO:               numba: 0.57.0
2023-06-11 21:56:38,050:INFO:            requests: 2.31.0
2023-06-11 21:56:38,050:INFO:          matplotlib: 3.7.1
2023-06-11 21:56:38,050:INFO:          scikitplot: 0.3.7
2023-06-11 21:56:38,050:INFO:         yellowbrick: 1.5
2023-06-11 21:56:38,050:INFO:              plotly: 5.15.0
2023-06-11 21:56:38,050:INFO:             kaleido: 0.2.1
2023-06-11 21:56:38,050:INFO:         statsmodels: 0.14.0
2023-06-11 21:56:38,050:INFO:              sktime: 0.17.0
2023-06-11 21:56:38,052:INFO:               tbats: 1.1.3
2023-06-11 21:56:38,053:INFO:            pmdarima: 2.0.3
2023-06-11 21:56:38,053:INFO:              psutil: 5.9.5
2023-06-11 21:56:38,053:INFO:PyCaret optional dependencies:
2023-06-11 21:56:38,108:INFO:                shap: Not installed
2023-06-11 21:56:38,108:INFO:           interpret: Not installed
2023-06-11 21:56:38,108:INFO:                umap: Not installed
2023-06-11 21:56:38,108:INFO:    pandas_profiling: Not installed
2023-06-11 21:56:38,108:INFO:  explainerdashboard: Not installed
2023-06-11 21:56:38,108:INFO:             autoviz: Not installed
2023-06-11 21:56:38,108:INFO:           fairlearn: Not installed
2023-06-11 21:56:38,108:INFO:             xgboost: Not installed
2023-06-11 21:56:38,108:INFO:            catboost: Not installed
2023-06-11 21:56:38,108:INFO:              kmodes: Not installed
2023-06-11 21:56:38,108:INFO:             mlxtend: Not installed
2023-06-11 21:56:38,109:INFO:       statsforecast: Not installed
2023-06-11 21:56:38,109:INFO:        tune_sklearn: Not installed
2023-06-11 21:56:38,109:INFO:                 ray: Not installed
2023-06-11 21:56:38,109:INFO:            hyperopt: Not installed
2023-06-11 21:56:38,109:INFO:              optuna: Not installed
2023-06-11 21:56:38,109:INFO:               skopt: Not installed
2023-06-11 21:56:38,109:INFO:              mlflow: 2.4.1
2023-06-11 21:56:38,109:INFO:              gradio: Not installed
2023-06-11 21:56:38,109:INFO:             fastapi: Not installed
2023-06-11 21:56:38,109:INFO:             uvicorn: Not installed
2023-06-11 21:56:38,109:INFO:              m2cgen: Not installed
2023-06-11 21:56:38,109:INFO:           evidently: Not installed
2023-06-11 21:56:38,109:INFO:               fugue: Not installed
2023-06-11 21:56:38,109:INFO:           streamlit: 1.23.1
2023-06-11 21:56:38,109:INFO:             prophet: Not installed
2023-06-11 21:56:38,109:INFO:None
2023-06-11 21:56:38,109:INFO:Set up data.
2023-06-11 21:56:38,144:INFO:Set up train/test split.
2023-06-11 21:56:38,237:INFO:Set up index.
2023-06-11 21:56:38,241:INFO:Set up folding strategy.
2023-06-11 21:56:38,241:INFO:Assigning column types.
2023-06-11 21:56:38,265:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-11 21:56:38,335:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-11 21:56:38,349:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-11 21:56:38,447:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,508:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-11 21:56:38,510:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-11 21:56:38,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,547:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-11 21:56:38,603:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-11 21:56:38,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,691:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-11 21:56:38,724:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,725:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-11 21:56:38,809:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,809:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,889:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,890:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,893:INFO:Preparing preprocessing pipeline...
2023-06-11 21:56:38,898:INFO:Set up label encoding.
2023-06-11 21:56:38,898:INFO:Set up simple imputation.
2023-06-11 21:56:38,921:INFO:Set up encoding of categorical features.
2023-06-11 21:56:38,922:INFO:Set up removing outliers.
2023-06-11 21:56:38,922:INFO:Set up imbalanced handling.
2023-06-11 21:56:38,922:INFO:Set up feature selection.
2023-06-11 21:56:38,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:43,515:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 21:57:25,505:INFO:Finished creating preprocessing pipeline.
2023-06-11 21:57:25,545:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2023-06-11 21:57:25,546:INFO:Creating final display dataframe.
2023-06-11 21:57:26,563:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 21:58:06,730:INFO:Setup _display_container:                     Description             Value
0                    Session id              5999
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape       (96892, 22)
5        Transformed data shape        (94490, 5)
6   Transformed train set shape        (65422, 5)
7    Transformed test set shape        (29068, 5)
8              Numeric features                13
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               100
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20            Feature selection              True
21     Feature selection method           classic
22  Feature selection estimator          lightgbm
23  Number of features selected               0.2
24               Fold Generator   StratifiedKFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment      MlflowLogger
29              Experiment Name  clf-default-name
30                          USI              6e20
2023-06-11 21:58:06,887:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:58:06,887:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:58:06,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:58:06,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:58:06,969:INFO:Logging experiment in loggers
2023-06-11 21:58:07,812:INFO:SubProcess save_model() called ==================================
2023-06-11 21:58:07,902:INFO:Initializing save_model()
2023-06-11 21:58:07,902:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmpktfyjipa\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-11 21:58:07,903:INFO:Adding model into prep_pipe
2023-06-11 21:58:07,903:WARNING:Only Model saved as it was a pipeline.
2023-06-11 21:58:08,084:INFO:C:\Users\alniquia\AppData\Local\Temp\tmpktfyjipa\Transformation Pipeline.pkl saved in current working directory
2023-06-11 21:58:08,127:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2023-06-11 21:58:08,128:INFO:save_model() successfully completed......................................
2023-06-11 21:58:08,300:INFO:SubProcess save_model() end ==================================
2023-06-11 21:58:08,400:INFO:setup() successfully completed in 107.96s...............
2023-06-11 21:59:30,778:INFO:Initializing create_model()
2023-06-11 21:59:30,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC8970CEE0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-11 21:59:30,779:INFO:Checking exceptions
2023-06-11 21:59:30,811:INFO:Importing libraries
2023-06-11 21:59:30,811:INFO:Copying training dataset
2023-06-11 21:59:30,878:INFO:Defining folds
2023-06-11 21:59:30,878:INFO:Declaring metric variables
2023-06-11 21:59:30,889:INFO:Importing untrained model
2023-06-11 21:59:30,899:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-11 21:59:30,917:INFO:Starting cross validation
2023-06-11 21:59:31,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-11 21:59:48,829:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 21:59:49,073:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 21:59:49,091:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 22:00:40,313:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:00:40,822:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:00:40,880:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:00:40,920:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:00:41,742:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-11 22:00:41,756:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-11 22:01:48,678:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:01:49,267:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-11 22:01:50,491:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-11 22:01:50,693:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-11 22:01:51,636:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:01:52,519:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:01:53,823:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:01:54,694:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:01:54,896:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:02:37,524:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-11 22:02:38,150:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-11 22:02:39,004:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 22:02:39,087:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 22:02:39,131:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 22:02:39,481:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 22:03:28,208:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:03:28,430:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:03:28,718:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:03:29,446:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:03:29,528:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-11 22:03:30,340:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-11 22:04:47,389:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:04:50,705:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:05:25,440:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 22:05:25,922:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 22:07:27,263:INFO:Calculating mean and std
2023-06-11 22:07:27,266:INFO:Creating metrics dataframe
2023-06-11 22:07:27,278:INFO:Finalizing model
2023-06-11 22:07:56,699:INFO:Creating Dashboard logs
2023-06-11 22:07:56,706:INFO:Model: Light Gradient Boosting Machine
2023-06-11 22:07:56,835:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5999, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-11 22:07:57,121:INFO:Initializing predict_model()
2023-06-11 22:07:57,121:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC8970CEE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EC89A1DF30>)
2023-06-11 22:07:57,121:INFO:Checking exceptions
2023-06-11 22:07:57,121:INFO:Preloading libraries
2023-06-11 22:07:58,047:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-06-11 22:08:16,383:INFO:Uploading results into container
2023-06-11 22:08:16,386:INFO:Uploading model into container now
2023-06-11 22:08:16,417:INFO:_master_model_container: 1
2023-06-11 22:08:16,418:INFO:_display_container: 2
2023-06-11 22:08:16,419:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-11 22:08:16,419:INFO:create_model() successfully completed......................................
2023-06-11 22:08:16,635:INFO:Initializing tune_model()
2023-06-11 22:08:16,636:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC8970CEE0>)
2023-06-11 22:08:16,636:INFO:Checking exceptions
2023-06-11 22:08:16,709:INFO:Copying training dataset
2023-06-11 22:08:16,768:INFO:Checking base model
2023-06-11 22:08:16,769:INFO:Base model : Light Gradient Boosting Machine
2023-06-11 22:08:16,779:INFO:Declaring metric variables
2023-06-11 22:08:16,785:INFO:Defining Hyperparameters
2023-06-11 22:08:17,069:INFO:Tuning with n_jobs=-1
2023-06-11 22:08:17,069:INFO:Initializing RandomizedSearchCV
2023-06-11 22:08:27,900:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:08:29,845:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:08:30,500:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:08:35,837:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:08:35,858:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:08:35,972:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:08:39,380:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:08:39,604:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:08:39,665:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:09:12,947:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:09:19,558:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:09:23,226:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:09:24,173:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:09:24,715:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:09:24,988:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:09:30,839:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:09:31,320:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:09:31,732:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:09:34,840:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:09:35,199:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:09:35,579:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:10:10,050:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:10:15,081:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:10:15,552:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:10:18,213:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:10:20,658:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:10:23,814:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:10:25,457:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:11:48,870:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:12:14,095:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:12:39,641:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:28:33,517:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:39:54,476:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:47:53,392:INFO:best_params: {'actual_estimator__reg_lambda': 10, 'actual_estimator__reg_alpha': 1e-07, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 290, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 21, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.6}
2023-06-11 22:47:53,394:INFO:Hyperparameter search completed
2023-06-11 22:47:53,394:INFO:SubProcess create_model() called ==================================
2023-06-11 22:47:53,396:INFO:Initializing create_model()
2023-06-11 22:47:53,396:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC8970CEE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EC8C624DC0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 10, 'reg_alpha': 1e-07, 'num_leaves': 30, 'n_estimators': 290, 'min_split_gain': 0.3, 'min_child_samples': 21, 'learning_rate': 0.001, 'feature_fraction': 0.4, 'bagging_freq': 0, 'bagging_fraction': 0.6})
2023-06-11 22:47:53,397:INFO:Checking exceptions
2023-06-11 22:47:53,398:INFO:Importing libraries
2023-06-11 22:47:53,398:INFO:Copying training dataset
2023-06-11 22:47:53,464:INFO:Defining folds
2023-06-11 22:47:53,464:INFO:Declaring metric variables
2023-06-11 22:47:53,471:INFO:Importing untrained model
2023-06-11 22:47:53,472:INFO:Declaring custom model
2023-06-11 22:47:53,479:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-11 22:47:53,494:INFO:Starting cross validation
2023-06-11 22:47:53,580:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-11 22:51:51,852:INFO:Calculating mean and std
2023-06-11 22:51:51,853:INFO:Creating metrics dataframe
2023-06-11 22:51:51,873:INFO:Finalizing model
2023-06-11 22:51:55,691:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-06-11 22:51:55,692:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-06-11 22:51:55,692:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-06-11 22:52:21,855:INFO:Uploading results into container
2023-06-11 22:52:21,856:INFO:Uploading model into container now
2023-06-11 22:52:21,858:INFO:_master_model_container: 2
2023-06-11 22:52:21,858:INFO:_display_container: 3
2023-06-11 22:52:21,859:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=290, n_jobs=-1, num_leaves=30, objective=None,
               random_state=5999, reg_alpha=1e-07, reg_lambda=10, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-11 22:52:21,860:INFO:create_model() successfully completed......................................
2023-06-11 22:52:22,046:INFO:SubProcess create_model() end ==================================
2023-06-11 22:52:22,047:INFO:choose_better activated
2023-06-11 22:52:22,052:INFO:SubProcess create_model() called ==================================
2023-06-11 22:52:22,053:INFO:Initializing create_model()
2023-06-11 22:52:22,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC8970CEE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-11 22:52:22,054:INFO:Checking exceptions
2023-06-11 22:52:22,058:INFO:Importing libraries
2023-06-11 22:52:22,058:INFO:Copying training dataset
2023-06-11 22:52:22,121:INFO:Defining folds
2023-06-11 22:52:22,121:INFO:Declaring metric variables
2023-06-11 22:52:22,121:INFO:Importing untrained model
2023-06-11 22:52:22,121:INFO:Declaring custom model
2023-06-11 22:52:22,122:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-11 22:52:22,122:INFO:Starting cross validation
2023-06-11 22:52:22,190:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-11 22:55:55,553:INFO:Calculating mean and std
2023-06-11 22:55:55,554:INFO:Creating metrics dataframe
2023-06-11 22:55:55,556:INFO:Finalizing model
2023-06-11 22:56:20,748:INFO:Uploading results into container
2023-06-11 22:56:20,762:INFO:Uploading model into container now
2023-06-11 22:56:20,762:INFO:_master_model_container: 3
2023-06-11 22:56:20,762:INFO:_display_container: 4
2023-06-11 22:56:20,763:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-11 22:56:20,763:INFO:create_model() successfully completed......................................
2023-06-11 22:56:20,879:INFO:SubProcess create_model() end ==================================
2023-06-11 22:56:20,880:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6235
2023-06-11 22:56:20,881:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=290, n_jobs=-1, num_leaves=30, objective=None,
               random_state=5999, reg_alpha=1e-07, reg_lambda=10, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6195
2023-06-11 22:56:20,881:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-06-11 22:56:20,881:INFO:choose_better completed
2023-06-11 22:56:20,881:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-11 22:56:20,882:INFO:Creating Dashboard logs
2023-06-11 22:56:20,889:INFO:Model: Light Gradient Boosting Machine
2023-06-11 22:56:25,310:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5999, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-11 22:56:26,827:INFO:Initializing predict_model()
2023-06-11 22:56:26,828:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC8970CEE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EC89A1F250>)
2023-06-11 22:56:26,828:INFO:Checking exceptions
2023-06-11 22:56:26,828:INFO:Preloading libraries
2023-06-11 22:56:51,988:INFO:_master_model_container: 3
2023-06-11 22:56:51,989:INFO:_display_container: 3
2023-06-11 22:56:51,989:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-11 22:56:51,990:INFO:tune_model() successfully completed......................................
2023-06-11 22:57:08,888:INFO:Initializing finalize_model()
2023-06-11 22:57:08,889:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC8970CEE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-11 22:57:08,890:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-11 22:57:08,909:INFO:Initializing create_model()
2023-06-11 22:57:08,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC8970CEE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-11 22:57:08,910:INFO:Checking exceptions
2023-06-11 22:57:08,913:INFO:Importing libraries
2023-06-11 22:57:08,913:INFO:Copying training dataset
2023-06-11 22:57:08,916:INFO:Defining folds
2023-06-11 22:57:08,916:INFO:Declaring metric variables
2023-06-11 22:57:08,917:INFO:Importing untrained model
2023-06-11 22:57:08,917:INFO:Declaring custom model
2023-06-11 22:57:08,919:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-11 22:57:08,995:INFO:Cross validation set to False
2023-06-11 22:57:08,995:INFO:Fitting Model
2023-06-11 22:57:14,917:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 22:58:30,794:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-11 22:58:30,794:INFO:create_model() successfully completed......................................
2023-06-11 22:58:30,943:INFO:Creating Dashboard logs
2023-06-11 22:58:30,944:INFO:Model: Light Gradient Boosting Machine
2023-06-11 22:58:41,034:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5999, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-11 22:58:42,428:INFO:_master_model_container: 3
2023-06-11 22:58:42,428:INFO:_display_container: 3
2023-06-11 22:58:42,451:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-11 22:58:42,451:INFO:finalize_model() successfully completed......................................
2023-06-11 22:59:02,163:INFO:Initializing save_model()
2023-06-11 22:59:02,163:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=bs_predictor, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-11 22:59:02,163:INFO:Adding model into prep_pipe
2023-06-11 22:59:02,163:WARNING:Only Model saved as it was a pipeline.
2023-06-11 22:59:02,409:INFO:bs_predictor.pkl saved in current working directory
2023-06-11 22:59:02,452:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-11 22:59:02,452:INFO:save_model() successfully completed......................................
2023-06-11 22:59:02,702:INFO:Initializing predict_model()
2023-06-11 22:59:02,703:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC8970CEE0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EC89205A20>)
2023-06-11 22:59:02,703:INFO:Checking exceptions
2023-06-11 22:59:02,703:INFO:Preloading libraries
2023-06-11 22:59:02,707:INFO:Set up data.
2023-06-11 22:59:02,737:INFO:Set up index.
2023-06-12 09:27:56,854:INFO:PyCaret ClassificationExperiment
2023-06-12 09:27:56,855:INFO:Logging name: clf-default-name
2023-06-12 09:27:56,855:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 09:27:56,856:INFO:version 3.0.2
2023-06-12 09:27:56,856:INFO:Initializing setup()
2023-06-12 09:27:56,856:INFO:self.USI: 9de2
2023-06-12 09:27:56,857:INFO:self._variable_keys: {'X', 'fold_generator', 'is_multiclass', 'logging_param', 'fold_groups_param', 'exp_id', 'data', 'gpu_param', 'log_plots_param', 'idx', 'seed', 'memory', 'X_test', 'target_param', 'y_train', 'gpu_n_jobs_param', '_available_plots', '_ml_usecase', 'y_test', 'html_param', 'pipeline', 'exp_name_log', 'n_jobs_param', 'X_train', 'y', 'fix_imbalance', 'USI', 'fold_shuffle_param'}
2023-06-12 09:27:56,857:INFO:Checking environment
2023-06-12 09:27:56,857:INFO:python_version: 3.10.10
2023-06-12 09:27:56,857:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 09:27:56,857:INFO:machine: AMD64
2023-06-12 09:27:56,857:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 09:27:56,861:INFO:Memory: svmem(total=17034072064, available=7907196928, percent=53.6, used=9126875136, free=7907196928)
2023-06-12 09:27:56,861:INFO:Physical Core: 2
2023-06-12 09:27:56,861:INFO:Logical Core: 4
2023-06-12 09:27:56,861:INFO:Checking libraries
2023-06-12 09:27:56,861:INFO:System:
2023-06-12 09:27:56,861:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 09:27:56,861:INFO:executable: c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 09:27:56,861:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 09:27:56,861:INFO:PyCaret required dependencies:
2023-06-12 09:27:56,862:INFO:                 pip: 23.1.2
2023-06-12 09:27:56,862:INFO:          setuptools: 65.5.0
2023-06-12 09:27:56,862:INFO:             pycaret: 3.0.2
2023-06-12 09:27:56,862:INFO:             IPython: 8.14.0
2023-06-12 09:27:56,862:INFO:          ipywidgets: 8.0.6
2023-06-12 09:27:56,862:INFO:                tqdm: 4.65.0
2023-06-12 09:27:56,863:INFO:               numpy: 1.23.5
2023-06-12 09:27:56,863:INFO:              pandas: 1.5.3
2023-06-12 09:27:56,863:INFO:              jinja2: 3.1.2
2023-06-12 09:27:56,863:INFO:               scipy: 1.10.1
2023-06-12 09:27:56,863:INFO:              joblib: 1.2.0
2023-06-12 09:27:56,863:INFO:             sklearn: 1.2.2
2023-06-12 09:27:56,863:INFO:                pyod: 1.0.9
2023-06-12 09:27:56,863:INFO:            imblearn: 0.10.1
2023-06-12 09:27:56,863:INFO:   category_encoders: 2.6.1
2023-06-12 09:27:56,864:INFO:            lightgbm: 3.3.5
2023-06-12 09:27:56,864:INFO:               numba: 0.57.0
2023-06-12 09:27:56,864:INFO:            requests: 2.31.0
2023-06-12 09:27:56,864:INFO:          matplotlib: 3.7.1
2023-06-12 09:27:56,864:INFO:          scikitplot: 0.3.7
2023-06-12 09:27:56,864:INFO:         yellowbrick: 1.5
2023-06-12 09:27:56,864:INFO:              plotly: 5.15.0
2023-06-12 09:27:56,865:INFO:             kaleido: 0.2.1
2023-06-12 09:27:56,865:INFO:         statsmodels: 0.14.0
2023-06-12 09:27:56,865:INFO:              sktime: 0.17.0
2023-06-12 09:27:56,868:INFO:               tbats: 1.1.3
2023-06-12 09:27:56,868:INFO:            pmdarima: 2.0.3
2023-06-12 09:27:56,869:INFO:              psutil: 5.9.5
2023-06-12 09:27:56,869:INFO:PyCaret optional dependencies:
2023-06-12 09:27:56,869:INFO:                shap: Not installed
2023-06-12 09:27:56,870:INFO:           interpret: Not installed
2023-06-12 09:27:56,871:INFO:                umap: Not installed
2023-06-12 09:27:56,871:INFO:    pandas_profiling: Not installed
2023-06-12 09:27:56,871:INFO:  explainerdashboard: Not installed
2023-06-12 09:27:56,871:INFO:             autoviz: Not installed
2023-06-12 09:27:56,871:INFO:           fairlearn: Not installed
2023-06-12 09:27:56,872:INFO:             xgboost: Not installed
2023-06-12 09:27:56,872:INFO:            catboost: Not installed
2023-06-12 09:27:56,872:INFO:              kmodes: Not installed
2023-06-12 09:27:56,872:INFO:             mlxtend: Not installed
2023-06-12 09:27:56,873:INFO:       statsforecast: Not installed
2023-06-12 09:27:56,873:INFO:        tune_sklearn: Not installed
2023-06-12 09:27:56,873:INFO:                 ray: Not installed
2023-06-12 09:27:56,873:INFO:            hyperopt: Not installed
2023-06-12 09:27:56,874:INFO:              optuna: Not installed
2023-06-12 09:27:56,874:INFO:               skopt: Not installed
2023-06-12 09:27:56,874:INFO:              mlflow: 2.4.1
2023-06-12 09:27:56,874:INFO:              gradio: Not installed
2023-06-12 09:27:56,874:INFO:             fastapi: Not installed
2023-06-12 09:27:56,874:INFO:             uvicorn: Not installed
2023-06-12 09:27:56,874:INFO:              m2cgen: Not installed
2023-06-12 09:27:56,874:INFO:           evidently: Not installed
2023-06-12 09:27:56,875:INFO:               fugue: Not installed
2023-06-12 09:27:56,875:INFO:           streamlit: 1.23.1
2023-06-12 09:27:56,875:INFO:             prophet: Not installed
2023-06-12 09:27:56,875:INFO:None
2023-06-12 09:27:56,875:INFO:Set up data.
2023-06-12 09:27:56,920:INFO:Set up train/test split.
2023-06-12 09:27:56,995:INFO:Set up index.
2023-06-12 09:27:56,998:INFO:Set up folding strategy.
2023-06-12 09:27:56,998:INFO:Assigning column types.
2023-06-12 09:27:57,025:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 09:27:57,079:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 09:27:57,080:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:27:57,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,121:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,190:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 09:27:57,195:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:27:57,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,266:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 09:27:57,403:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:27:57,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,724:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:27:57,788:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,789:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 09:27:57,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,996:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:58,002:INFO:Preparing preprocessing pipeline...
2023-06-12 09:27:58,008:INFO:Set up label encoding.
2023-06-12 09:27:58,008:INFO:Set up simple imputation.
2023-06-12 09:27:58,037:INFO:Set up encoding of categorical features.
2023-06-12 09:27:58,038:INFO:Set up removing outliers.
2023-06-12 09:27:58,039:INFO:Set up imbalanced handling.
2023-06-12 09:27:58,040:INFO:Set up feature selection.
2023-06-12 09:27:58,170:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:58,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:28:03,289:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-12 09:28:57,802:INFO:Finished creating preprocessing pipeline.
2023-06-12 09:28:57,843:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2023-06-12 09:28:57,843:INFO:Creating final display dataframe.
2023-06-12 09:28:59,276:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-12 09:29:55,458:INFO:Setup _display_container:                     Description             Value
0                    Session id              6308
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape       (96892, 25)
5        Transformed data shape        (94668, 5)
6   Transformed train set shape        (65600, 5)
7    Transformed test set shape        (29068, 5)
8              Numeric features                16
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               100
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20            Feature selection              True
21     Feature selection method           classic
22  Feature selection estimator          lightgbm
23  Number of features selected               0.2
24               Fold Generator   StratifiedKFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment      MlflowLogger
29              Experiment Name  clf-default-name
30                          USI              9de2
2023-06-12 09:29:55,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:29:55,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:29:55,715:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:29:55,716:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:29:55,716:INFO:Logging experiment in loggers
2023-06-12 09:29:55,916:INFO:SubProcess save_model() called ==================================
2023-06-12 09:29:55,977:INFO:Initializing save_model()
2023-06-12 09:29:55,978:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmpdrk257_v\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 09:29:55,978:INFO:Adding model into prep_pipe
2023-06-12 09:29:55,978:WARNING:Only Model saved as it was a pipeline.
2023-06-12 09:29:56,224:INFO:C:\Users\alniquia\AppData\Local\Temp\tmpdrk257_v\Transformation Pipeline.pkl saved in current working directory
2023-06-12 09:29:56,267:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2023-06-12 09:29:56,268:INFO:save_model() successfully completed......................................
2023-06-12 09:29:56,429:INFO:SubProcess save_model() end ==================================
2023-06-12 09:29:56,560:INFO:setup() successfully completed in 146.25s...............
2023-06-12 09:30:17,665:INFO:Initializing create_model()
2023-06-12 09:30:17,666:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC84E20FA0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 09:30:17,666:INFO:Checking exceptions
2023-06-12 09:30:17,691:INFO:Importing libraries
2023-06-12 09:30:17,692:INFO:Copying training dataset
2023-06-12 09:30:17,773:INFO:Defining folds
2023-06-12 09:30:17,774:INFO:Declaring metric variables
2023-06-12 09:30:17,784:INFO:Importing untrained model
2023-06-12 09:30:17,797:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 09:30:17,817:INFO:Starting cross validation
2023-06-12 09:30:18,011:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 09:31:00,179:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 09:31:00,192:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 09:31:00,202:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 09:31:00,279:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 09:31:02,833:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-12 09:31:02,833:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-12 09:31:02,838:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-12 09:31:02,864:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-12 09:32:04,051:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 09:32:04,155:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 09:32:04,367:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 09:32:04,896:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 09:32:05,649:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 09:33:14,854:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 09:34:37,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 09:34:37,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 09:34:37,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 09:34:37,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 09:34:42,304:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-12 09:35:18,957:INFO:PyCaret ClassificationExperiment
2023-06-12 09:35:18,957:INFO:Logging name: clf-default-name
2023-06-12 09:35:18,957:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 09:35:18,957:INFO:version 3.0.2
2023-06-12 09:35:18,957:INFO:Initializing setup()
2023-06-12 09:35:18,957:INFO:self.USI: e806
2023-06-12 09:35:18,957:INFO:self._variable_keys: {'X_train', 'is_multiclass', '_available_plots', 'USI', 'memory', 'X_test', 'y', 'pipeline', 'fold_shuffle_param', 'idx', 'y_train', 'log_plots_param', '_ml_usecase', 'fold_generator', 'exp_name_log', 'exp_id', 'html_param', 'data', 'y_test', 'fold_groups_param', 'fix_imbalance', 'target_param', 'logging_param', 'gpu_n_jobs_param', 'n_jobs_param', 'seed', 'X', 'gpu_param'}
2023-06-12 09:35:18,957:INFO:Checking environment
2023-06-12 09:35:18,957:INFO:python_version: 3.10.10
2023-06-12 09:35:18,957:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 09:35:18,957:INFO:machine: AMD64
2023-06-12 09:35:18,957:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 09:35:18,960:INFO:Memory: svmem(total=17034072064, available=8023826432, percent=52.9, used=9010245632, free=8023826432)
2023-06-12 09:35:18,960:INFO:Physical Core: 2
2023-06-12 09:35:18,960:INFO:Logical Core: 4
2023-06-12 09:35:18,960:INFO:Checking libraries
2023-06-12 09:35:18,960:INFO:System:
2023-06-12 09:35:18,960:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 09:35:18,960:INFO:executable: c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 09:35:18,960:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 09:35:18,960:INFO:PyCaret required dependencies:
2023-06-12 09:35:18,960:INFO:                 pip: 23.1.2
2023-06-12 09:35:18,961:INFO:          setuptools: 65.5.0
2023-06-12 09:35:18,961:INFO:             pycaret: 3.0.2
2023-06-12 09:35:18,961:INFO:             IPython: 8.14.0
2023-06-12 09:35:18,961:INFO:          ipywidgets: 8.0.6
2023-06-12 09:35:18,961:INFO:                tqdm: 4.65.0
2023-06-12 09:35:18,961:INFO:               numpy: 1.23.5
2023-06-12 09:35:18,961:INFO:              pandas: 1.5.3
2023-06-12 09:35:18,961:INFO:              jinja2: 3.1.2
2023-06-12 09:35:18,961:INFO:               scipy: 1.10.1
2023-06-12 09:35:18,961:INFO:              joblib: 1.2.0
2023-06-12 09:35:18,962:INFO:             sklearn: 1.2.2
2023-06-12 09:35:18,962:INFO:                pyod: 1.0.9
2023-06-12 09:35:18,962:INFO:            imblearn: 0.10.1
2023-06-12 09:35:18,962:INFO:   category_encoders: 2.6.1
2023-06-12 09:35:18,962:INFO:            lightgbm: 3.3.5
2023-06-12 09:35:18,962:INFO:               numba: 0.57.0
2023-06-12 09:35:18,962:INFO:            requests: 2.31.0
2023-06-12 09:35:18,962:INFO:          matplotlib: 3.7.1
2023-06-12 09:35:18,962:INFO:          scikitplot: 0.3.7
2023-06-12 09:35:18,962:INFO:         yellowbrick: 1.5
2023-06-12 09:35:18,963:INFO:              plotly: 5.15.0
2023-06-12 09:35:18,963:INFO:             kaleido: 0.2.1
2023-06-12 09:35:18,963:INFO:         statsmodels: 0.14.0
2023-06-12 09:35:18,963:INFO:              sktime: 0.17.0
2023-06-12 09:35:18,963:INFO:               tbats: 1.1.3
2023-06-12 09:35:18,963:INFO:            pmdarima: 2.0.3
2023-06-12 09:35:18,963:INFO:              psutil: 5.9.5
2023-06-12 09:35:18,963:INFO:PyCaret optional dependencies:
2023-06-12 09:35:19,019:INFO:                shap: Not installed
2023-06-12 09:35:19,019:INFO:           interpret: Not installed
2023-06-12 09:35:19,019:INFO:                umap: Not installed
2023-06-12 09:35:19,019:INFO:    pandas_profiling: Not installed
2023-06-12 09:35:19,019:INFO:  explainerdashboard: Not installed
2023-06-12 09:35:19,020:INFO:             autoviz: Not installed
2023-06-12 09:35:19,020:INFO:           fairlearn: Not installed
2023-06-12 09:35:19,020:INFO:             xgboost: Not installed
2023-06-12 09:35:19,020:INFO:            catboost: Not installed
2023-06-12 09:35:19,020:INFO:              kmodes: Not installed
2023-06-12 09:35:19,020:INFO:             mlxtend: Not installed
2023-06-12 09:35:19,020:INFO:       statsforecast: Not installed
2023-06-12 09:35:19,020:INFO:        tune_sklearn: Not installed
2023-06-12 09:35:19,021:INFO:                 ray: Not installed
2023-06-12 09:35:19,021:INFO:            hyperopt: Not installed
2023-06-12 09:35:19,021:INFO:              optuna: Not installed
2023-06-12 09:35:19,021:INFO:               skopt: Not installed
2023-06-12 09:35:19,021:INFO:              mlflow: 2.4.1
2023-06-12 09:35:19,021:INFO:              gradio: Not installed
2023-06-12 09:35:19,021:INFO:             fastapi: Not installed
2023-06-12 09:35:19,021:INFO:             uvicorn: Not installed
2023-06-12 09:35:19,021:INFO:              m2cgen: Not installed
2023-06-12 09:35:19,021:INFO:           evidently: Not installed
2023-06-12 09:35:19,021:INFO:               fugue: Not installed
2023-06-12 09:35:19,021:INFO:           streamlit: 1.23.1
2023-06-12 09:35:19,021:INFO:             prophet: Not installed
2023-06-12 09:35:19,021:INFO:None
2023-06-12 09:35:19,022:INFO:Set up data.
2023-06-12 09:35:19,060:INFO:Set up train/test split.
2023-06-12 09:35:19,129:INFO:Set up index.
2023-06-12 09:35:19,132:INFO:Set up folding strategy.
2023-06-12 09:35:19,132:INFO:Assigning column types.
2023-06-12 09:35:19,157:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 09:35:19,208:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 09:35:19,222:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:35:19,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,416:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 09:35:19,417:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:35:19,450:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,453:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 09:35:19,505:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:35:19,539:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,590:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:35:19,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,623:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 09:35:19,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,710:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,796:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,800:INFO:Preparing preprocessing pipeline...
2023-06-12 09:35:19,807:INFO:Set up label encoding.
2023-06-12 09:35:19,807:INFO:Set up simple imputation.
2023-06-12 09:35:19,825:INFO:Set up encoding of categorical features.
2023-06-12 09:35:21,489:INFO:Finished creating preprocessing pipeline.
2023-06-12 09:35:21,499:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 09:35:21,499:INFO:Creating final display dataframe.
2023-06-12 09:35:26,211:INFO:Setup _display_container:                     Description             Value
0                    Session id              3366
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape       (96892, 25)
5        Transformed data shape      (96892, 468)
6   Transformed train set shape      (67824, 468)
7    Transformed test set shape      (29068, 468)
8              Numeric features                16
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               100
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              e806
2023-06-12 09:35:26,363:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:26,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:26,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:26,490:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:26,491:INFO:Logging experiment in loggers
2023-06-12 09:35:28,789:INFO:SubProcess save_model() called ==================================
2023-06-12 09:35:28,805:INFO:Initializing save_model()
2023-06-12 09:35:28,805:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmpx3ldrp17\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 09:35:28,805:INFO:Adding model into prep_pipe
2023-06-12 09:35:28,806:WARNING:Only Model saved as it was a pipeline.
2023-06-12 09:35:28,833:INFO:C:\Users\alniquia\AppData\Local\Temp\tmpx3ldrp17\Transformation Pipeline.pkl saved in current working directory
2023-06-12 09:35:28,840:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 09:35:28,840:INFO:save_model() successfully completed......................................
2023-06-12 09:35:28,928:INFO:SubProcess save_model() end ==================================
2023-06-12 09:35:28,958:INFO:setup() successfully completed in 27.11s...............
2023-06-12 09:36:45,382:INFO:PyCaret ClassificationExperiment
2023-06-12 09:36:45,382:INFO:Logging name: clf-default-name
2023-06-12 09:36:45,382:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 09:36:45,382:INFO:version 3.0.2
2023-06-12 09:36:45,382:INFO:Initializing setup()
2023-06-12 09:36:45,382:INFO:self.USI: 9d66
2023-06-12 09:36:45,382:INFO:self._variable_keys: {'X_train', 'is_multiclass', '_available_plots', 'USI', 'memory', 'X_test', 'y', 'pipeline', 'fold_shuffle_param', 'idx', 'y_train', 'log_plots_param', '_ml_usecase', 'fold_generator', 'exp_name_log', 'exp_id', 'html_param', 'data', 'y_test', 'fold_groups_param', 'fix_imbalance', 'target_param', 'logging_param', 'gpu_n_jobs_param', 'n_jobs_param', 'seed', 'X', 'gpu_param'}
2023-06-12 09:36:45,382:INFO:Checking environment
2023-06-12 09:36:45,382:INFO:python_version: 3.10.10
2023-06-12 09:36:45,382:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 09:36:45,382:INFO:machine: AMD64
2023-06-12 09:36:45,382:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 09:36:45,385:INFO:Memory: svmem(total=17034072064, available=7893180416, percent=53.7, used=9140891648, free=7893180416)
2023-06-12 09:36:45,385:INFO:Physical Core: 2
2023-06-12 09:36:45,386:INFO:Logical Core: 4
2023-06-12 09:36:45,386:INFO:Checking libraries
2023-06-12 09:36:45,386:INFO:System:
2023-06-12 09:36:45,386:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 09:36:45,386:INFO:executable: c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 09:36:45,386:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 09:36:45,386:INFO:PyCaret required dependencies:
2023-06-12 09:36:45,386:INFO:                 pip: 23.1.2
2023-06-12 09:36:45,386:INFO:          setuptools: 65.5.0
2023-06-12 09:36:45,386:INFO:             pycaret: 3.0.2
2023-06-12 09:36:45,386:INFO:             IPython: 8.14.0
2023-06-12 09:36:45,386:INFO:          ipywidgets: 8.0.6
2023-06-12 09:36:45,386:INFO:                tqdm: 4.65.0
2023-06-12 09:36:45,386:INFO:               numpy: 1.23.5
2023-06-12 09:36:45,386:INFO:              pandas: 1.5.3
2023-06-12 09:36:45,386:INFO:              jinja2: 3.1.2
2023-06-12 09:36:45,387:INFO:               scipy: 1.10.1
2023-06-12 09:36:45,387:INFO:              joblib: 1.2.0
2023-06-12 09:36:45,387:INFO:             sklearn: 1.2.2
2023-06-12 09:36:45,387:INFO:                pyod: 1.0.9
2023-06-12 09:36:45,387:INFO:            imblearn: 0.10.1
2023-06-12 09:36:45,387:INFO:   category_encoders: 2.6.1
2023-06-12 09:36:45,387:INFO:            lightgbm: 3.3.5
2023-06-12 09:36:45,387:INFO:               numba: 0.57.0
2023-06-12 09:36:45,387:INFO:            requests: 2.31.0
2023-06-12 09:36:45,387:INFO:          matplotlib: 3.7.1
2023-06-12 09:36:45,387:INFO:          scikitplot: 0.3.7
2023-06-12 09:36:45,387:INFO:         yellowbrick: 1.5
2023-06-12 09:36:45,387:INFO:              plotly: 5.15.0
2023-06-12 09:36:45,387:INFO:             kaleido: 0.2.1
2023-06-12 09:36:45,387:INFO:         statsmodels: 0.14.0
2023-06-12 09:36:45,387:INFO:              sktime: 0.17.0
2023-06-12 09:36:45,387:INFO:               tbats: 1.1.3
2023-06-12 09:36:45,387:INFO:            pmdarima: 2.0.3
2023-06-12 09:36:45,387:INFO:              psutil: 5.9.5
2023-06-12 09:36:45,387:INFO:PyCaret optional dependencies:
2023-06-12 09:36:45,387:INFO:                shap: Not installed
2023-06-12 09:36:45,387:INFO:           interpret: Not installed
2023-06-12 09:36:45,388:INFO:                umap: Not installed
2023-06-12 09:36:45,388:INFO:    pandas_profiling: Not installed
2023-06-12 09:36:45,388:INFO:  explainerdashboard: Not installed
2023-06-12 09:36:45,388:INFO:             autoviz: Not installed
2023-06-12 09:36:45,388:INFO:           fairlearn: Not installed
2023-06-12 09:36:45,388:INFO:             xgboost: Not installed
2023-06-12 09:36:45,388:INFO:            catboost: Not installed
2023-06-12 09:36:45,388:INFO:              kmodes: Not installed
2023-06-12 09:36:45,388:INFO:             mlxtend: Not installed
2023-06-12 09:36:45,388:INFO:       statsforecast: Not installed
2023-06-12 09:36:45,388:INFO:        tune_sklearn: Not installed
2023-06-12 09:36:45,388:INFO:                 ray: Not installed
2023-06-12 09:36:45,388:INFO:            hyperopt: Not installed
2023-06-12 09:36:45,388:INFO:              optuna: Not installed
2023-06-12 09:36:45,389:INFO:               skopt: Not installed
2023-06-12 09:36:45,389:INFO:              mlflow: 2.4.1
2023-06-12 09:36:45,389:INFO:              gradio: Not installed
2023-06-12 09:36:45,389:INFO:             fastapi: Not installed
2023-06-12 09:36:45,389:INFO:             uvicorn: Not installed
2023-06-12 09:36:45,389:INFO:              m2cgen: Not installed
2023-06-12 09:36:45,389:INFO:           evidently: Not installed
2023-06-12 09:36:45,389:INFO:               fugue: Not installed
2023-06-12 09:36:45,389:INFO:           streamlit: 1.23.1
2023-06-12 09:36:45,389:INFO:             prophet: Not installed
2023-06-12 09:36:45,389:INFO:None
2023-06-12 09:36:45,394:INFO:Set up data.
2023-06-12 09:36:45,454:INFO:Set up train/test split.
2023-06-12 09:36:45,548:INFO:Set up index.
2023-06-12 09:36:45,551:INFO:Set up folding strategy.
2023-06-12 09:36:45,551:INFO:Assigning column types.
2023-06-12 09:36:45,585:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 09:36:45,686:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 09:36:45,687:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:36:45,751:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:45,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:45,832:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 09:36:45,833:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:36:45,869:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:45,870:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:45,870:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 09:36:45,929:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:36:45,967:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:45,967:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:46,028:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:36:46,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:46,068:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:46,068:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 09:36:46,166:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:46,166:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:46,264:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:46,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:46,265:INFO:Preparing preprocessing pipeline...
2023-06-12 09:36:46,269:INFO:Set up label encoding.
2023-06-12 09:36:46,269:INFO:Set up simple imputation.
2023-06-12 09:36:46,297:INFO:Set up encoding of categorical features.
2023-06-12 09:36:48,262:INFO:Finished creating preprocessing pipeline.
2023-06-12 09:36:48,270:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 09:36:48,270:INFO:Creating final display dataframe.
2023-06-12 09:36:54,414:INFO:Setup _display_container:                     Description             Value
0                    Session id               885
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape       (96892, 25)
5        Transformed data shape      (96892, 467)
6   Transformed train set shape      (67824, 467)
7    Transformed test set shape      (29068, 467)
8              Numeric features                16
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              9d66
2023-06-12 09:36:54,555:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:54,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:54,663:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:54,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:54,664:INFO:Logging experiment in loggers
2023-06-12 09:36:54,916:INFO:SubProcess save_model() called ==================================
2023-06-12 09:36:54,934:INFO:Initializing save_model()
2023-06-12 09:36:54,934:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmpema9ouf4\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 09:36:54,934:INFO:Adding model into prep_pipe
2023-06-12 09:36:54,934:WARNING:Only Model saved as it was a pipeline.
2023-06-12 09:36:54,956:INFO:C:\Users\alniquia\AppData\Local\Temp\tmpema9ouf4\Transformation Pipeline.pkl saved in current working directory
2023-06-12 09:36:54,967:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 09:36:54,967:INFO:save_model() successfully completed......................................
2023-06-12 09:36:55,116:INFO:SubProcess save_model() end ==================================
2023-06-12 09:36:55,183:INFO:setup() successfully completed in 32.44s...............
2023-06-12 09:37:35,612:INFO:Initializing create_model()
2023-06-12 09:37:35,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8541C5DE0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 09:37:35,612:INFO:Checking exceptions
2023-06-12 09:37:35,655:INFO:Importing libraries
2023-06-12 09:37:35,656:INFO:Copying training dataset
2023-06-12 09:37:35,777:INFO:Defining folds
2023-06-12 09:37:35,777:INFO:Declaring metric variables
2023-06-12 09:37:35,790:INFO:Importing untrained model
2023-06-12 09:37:35,801:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 09:37:35,855:INFO:Starting cross validation
2023-06-12 09:37:35,861:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 09:39:12,745:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:39:12,811:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:39:12,878:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:39:13,413:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:40:10,309:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:40:11,098:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:42:42,590:INFO:Calculating mean and std
2023-06-12 09:42:42,592:INFO:Creating metrics dataframe
2023-06-12 09:42:42,599:INFO:Finalizing model
2023-06-12 09:43:09,611:INFO:Creating Dashboard logs
2023-06-12 09:43:09,616:INFO:Model: Light Gradient Boosting Machine
2023-06-12 09:43:09,731:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 885, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 09:43:09,981:INFO:Initializing predict_model()
2023-06-12 09:43:09,981:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8541C5DE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=885, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D86ABA48B0>)
2023-06-12 09:43:09,981:INFO:Checking exceptions
2023-06-12 09:43:09,981:INFO:Preloading libraries
2023-06-12 09:43:11,219:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-06-12 09:43:31,922:INFO:Uploading results into container
2023-06-12 09:43:31,923:INFO:Uploading model into container now
2023-06-12 09:43:31,939:INFO:_master_model_container: 1
2023-06-12 09:43:31,939:INFO:_display_container: 2
2023-06-12 09:43:31,939:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=885, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 09:43:31,939:INFO:create_model() successfully completed......................................
2023-06-12 09:43:43,096:INFO:Initializing tune_model()
2023-06-12 09:43:43,097:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=885, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8541C5DE0>)
2023-06-12 09:43:43,097:INFO:Checking exceptions
2023-06-12 09:43:43,171:INFO:Copying training dataset
2023-06-12 09:43:43,229:INFO:Checking base model
2023-06-12 09:43:43,229:INFO:Base model : Light Gradient Boosting Machine
2023-06-12 09:43:43,237:INFO:Declaring metric variables
2023-06-12 09:43:43,247:INFO:Defining Hyperparameters
2023-06-12 09:43:43,405:INFO:Tuning with n_jobs=-1
2023-06-12 09:43:43,406:INFO:Initializing RandomizedSearchCV
2023-06-12 09:44:47,819:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:44:48,062:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:44:48,103:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:44:48,111:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:45:47,840:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 09:45:55,698:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:45:56,629:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:46:43,067:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:47:21,286:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:47:22,730:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 09:47:57,611:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:47:59,083:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 09:48:50,107:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:49:19,211:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 09:50:07,332:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:50:47,831:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:51:54,082:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:56:49,322:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:56:50,555:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 09:57:21,293:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:57:22,648:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 09:57:51,224:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:57:53,037:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 09:58:23,427:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:58:25,459:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 09:58:53,838:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:58:55,777:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 09:59:46,930:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:59:50,823:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:00:42,054:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:00:45,766:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:01:39,950:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:01:43,075:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:02:36,276:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:02:38,329:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:03:10,114:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:03:11,980:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:03:34,820:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:03:36,216:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:04:01,672:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:04:04,160:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:04:27,805:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:04:30,127:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:04:55,733:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:04:57,083:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:05:21,570:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:05:22,776:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:05:51,434:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:05:53,109:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:06:19,318:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:06:20,899:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:06:45,753:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:06:47,999:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:07:12,020:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:07:13,888:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:07:41,349:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:08:23,092:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:09:00,247:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:12:06,911:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:12:07,906:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:12:41,543:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:15:32,526:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:21:35,520:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:22:14,826:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:22:16,577:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:22:50,509:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:22:52,106:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:23:21,325:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:23:24,326:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:23:53,328:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:23:55,992:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:24:29,937:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:24:33,356:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:25:00,881:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:25:03,793:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:25:32,142:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:25:34,836:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:26:00,686:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:26:04,106:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:26:30,790:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:26:34,063:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:27:05,182:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:27:08,076:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:27:30,789:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:27:32,383:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:27:54,721:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:27:56,533:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:28:17,659:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:28:19,531:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:28:40,812:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:28:42,468:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:29:05,574:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:29:08,211:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:29:31,891:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:29:33,881:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:29:58,682:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:30:01,103:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:30:25,454:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:30:27,273:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:30:56,525:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:30:59,393:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:31:28,087:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:31:30,486:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:34:25,552:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 0.4, 'actual_estimator__num_leaves': 8, 'actual_estimator__n_estimators': 200, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-06-12 10:34:25,556:INFO:Hyperparameter search completed
2023-06-12 10:34:25,556:INFO:SubProcess create_model() called ==================================
2023-06-12 10:34:25,558:INFO:Initializing create_model()
2023-06-12 10:34:25,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8541C5DE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=885, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D8682C9990>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.001, 'reg_alpha': 0.4, 'num_leaves': 8, 'n_estimators': 200, 'min_split_gain': 0.7, 'min_child_samples': 91, 'learning_rate': 0.1, 'feature_fraction': 0.6, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-06-12 10:34:25,558:INFO:Checking exceptions
2023-06-12 10:34:25,558:INFO:Importing libraries
2023-06-12 10:34:25,558:INFO:Copying training dataset
2023-06-12 10:34:25,624:INFO:Defining folds
2023-06-12 10:34:25,625:INFO:Declaring metric variables
2023-06-12 10:34:25,633:INFO:Importing untrained model
2023-06-12 10:34:25,633:INFO:Declaring custom model
2023-06-12 10:34:25,641:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 10:34:25,652:INFO:Starting cross validation
2023-06-12 10:34:25,657:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 10:35:28,405:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:37:37,886:INFO:Calculating mean and std
2023-06-12 10:37:37,890:INFO:Creating metrics dataframe
2023-06-12 10:37:37,903:INFO:Finalizing model
2023-06-12 10:37:39,712:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2023-06-12 10:37:39,712:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-06-12 10:37:39,713:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-06-12 10:38:08,621:INFO:Uploading results into container
2023-06-12 10:38:08,621:INFO:Uploading model into container now
2023-06-12 10:38:08,621:INFO:_master_model_container: 2
2023-06-12 10:38:08,621:INFO:_display_container: 3
2023-06-12 10:38:08,621:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=200, n_jobs=-1, num_leaves=8, objective=None,
               random_state=885, reg_alpha=0.4, reg_lambda=0.001, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 10:38:08,621:INFO:create_model() successfully completed......................................
2023-06-12 10:38:08,706:INFO:SubProcess create_model() end ==================================
2023-06-12 10:38:08,706:INFO:choose_better activated
2023-06-12 10:38:08,710:INFO:SubProcess create_model() called ==================================
2023-06-12 10:38:08,711:INFO:Initializing create_model()
2023-06-12 10:38:08,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8541C5DE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=885, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 10:38:08,711:INFO:Checking exceptions
2023-06-12 10:38:08,713:INFO:Importing libraries
2023-06-12 10:38:08,713:INFO:Copying training dataset
2023-06-12 10:38:08,751:INFO:Defining folds
2023-06-12 10:38:08,751:INFO:Declaring metric variables
2023-06-12 10:38:08,751:INFO:Importing untrained model
2023-06-12 10:38:08,751:INFO:Declaring custom model
2023-06-12 10:38:08,752:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 10:38:08,752:INFO:Starting cross validation
2023-06-12 10:38:08,755:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 10:41:05,860:INFO:Calculating mean and std
2023-06-12 10:41:05,861:INFO:Creating metrics dataframe
2023-06-12 10:41:05,864:INFO:Finalizing model
2023-06-12 10:41:25,809:INFO:Uploading results into container
2023-06-12 10:41:25,809:INFO:Uploading model into container now
2023-06-12 10:41:25,819:INFO:_master_model_container: 3
2023-06-12 10:41:25,819:INFO:_display_container: 4
2023-06-12 10:41:25,819:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=885, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 10:41:25,819:INFO:create_model() successfully completed......................................
2023-06-12 10:41:25,899:INFO:SubProcess create_model() end ==================================
2023-06-12 10:41:25,899:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=885, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.7059
2023-06-12 10:41:25,899:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=200, n_jobs=-1, num_leaves=8, objective=None,
               random_state=885, reg_alpha=0.4, reg_lambda=0.001, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.7077
2023-06-12 10:41:25,899:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=200, n_jobs=-1, num_leaves=8, objective=None,
               random_state=885, reg_alpha=0.4, reg_lambda=0.001, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-06-12 10:41:25,899:INFO:choose_better completed
2023-06-12 10:41:25,899:INFO:Creating Dashboard logs
2023-06-12 10:41:25,904:INFO:Model: Light Gradient Boosting Machine
2023-06-12 10:41:25,990:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 91, 'min_child_weight': 0.001, 'min_split_gain': 0.7, 'n_estimators': 200, 'n_jobs': -1, 'num_leaves': 8, 'objective': None, 'random_state': 885, 'reg_alpha': 0.4, 'reg_lambda': 0.001, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.6, 'bagging_freq': 2, 'bagging_fraction': 0.6}
2023-06-12 10:41:26,249:INFO:Initializing predict_model()
2023-06-12 10:41:26,249:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8541C5DE0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=200, n_jobs=-1, num_leaves=8, objective=None,
               random_state=885, reg_alpha=0.4, reg_lambda=0.001, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D86ABA5090>)
2023-06-12 10:41:26,249:INFO:Checking exceptions
2023-06-12 10:41:26,249:INFO:Preloading libraries
2023-06-12 10:41:42,726:INFO:_master_model_container: 3
2023-06-12 10:41:42,726:INFO:_display_container: 3
2023-06-12 10:41:42,726:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=200, n_jobs=-1, num_leaves=8, objective=None,
               random_state=885, reg_alpha=0.4, reg_lambda=0.001, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 10:41:42,726:INFO:tune_model() successfully completed......................................
2023-06-12 10:41:58,059:INFO:Initializing finalize_model()
2023-06-12 10:41:58,060:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8541C5DE0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=200, n_jobs=-1, num_leaves=8, objective=None,
               random_state=885, reg_alpha=0.4, reg_lambda=0.001, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-12 10:41:58,063:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=200, n_jobs=-1, num_leaves=8, objective=None,
               random_state=885, reg_alpha=0.4, reg_lambda=0.001, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 10:41:58,094:INFO:Initializing create_model()
2023-06-12 10:41:58,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8541C5DE0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=200, n_jobs=-1, num_leaves=8, objective=None,
               random_state=885, reg_alpha=0.4, reg_lambda=0.001, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-12 10:41:58,094:INFO:Checking exceptions
2023-06-12 10:41:58,097:INFO:Importing libraries
2023-06-12 10:41:58,097:INFO:Copying training dataset
2023-06-12 10:41:58,100:INFO:Defining folds
2023-06-12 10:41:58,100:INFO:Declaring metric variables
2023-06-12 10:41:58,101:INFO:Importing untrained model
2023-06-12 10:41:58,101:INFO:Declaring custom model
2023-06-12 10:41:58,102:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 10:41:58,105:INFO:Cross validation set to False
2023-06-12 10:41:58,105:INFO:Fitting Model
2023-06-12 10:42:02,597:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2023-06-12 10:42:02,597:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-06-12 10:42:02,597:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-06-12 10:42:04,505:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=200, n_jobs=-1, num_leaves=8,
                                objective=None, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 10:42:04,505:INFO:create_model() successfully completed......................................
2023-06-12 10:42:04,595:INFO:Creating Dashboard logs
2023-06-12 10:42:04,595:INFO:Model: Light Gradient Boosting Machine
2023-06-12 10:42:04,715:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 91, 'min_child_weight': 0.001, 'min_split_gain': 0.7, 'n_estimators': 200, 'n_jobs': -1, 'num_leaves': 8, 'objective': None, 'random_state': 885, 'reg_alpha': 0.4, 'reg_lambda': 0.001, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.6, 'bagging_freq': 2, 'bagging_fraction': 0.6}
2023-06-12 10:42:05,116:INFO:_master_model_container: 3
2023-06-12 10:42:05,116:INFO:_display_container: 3
2023-06-12 10:42:05,137:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=200, n_jobs=-1, num_leaves=8,
                                objective=None, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 10:42:05,137:INFO:finalize_model() successfully completed......................................
2023-06-12 10:42:05,268:INFO:Initializing save_model()
2023-06-12 10:42:05,268:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=200, n_jobs=-1, num_leaves=8,
                                objective=None, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=bs_predictor, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 10:42:05,268:INFO:Adding model into prep_pipe
2023-06-12 10:42:05,268:WARNING:Only Model saved as it was a pipeline.
2023-06-12 10:42:05,304:INFO:bs_predictor.pkl saved in current working directory
2023-06-12 10:42:05,322:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=200, n_jobs=-1, num_leaves=8,
                                objective=None, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 10:42:05,322:INFO:save_model() successfully completed......................................
2023-06-12 10:42:05,492:INFO:Initializing predict_model()
2023-06-12 10:42:05,493:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8541C5DE0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=200, n_jobs=-1, num_leaves=8,
                                objective=None, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D800137B50>)
2023-06-12 10:42:05,493:INFO:Checking exceptions
2023-06-12 10:42:05,493:INFO:Preloading libraries
2023-06-12 10:42:05,496:INFO:Set up data.
2023-06-12 10:42:05,528:INFO:Set up index.
2023-06-12 12:35:39,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 12:35:39,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 12:35:39,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 12:35:39,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 12:35:43,936:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-12 12:37:14,336:INFO:Initializing load_model()
2023-06-12 12:37:14,337:INFO:load_model(model_name=models/bs_predictor, platform=None, authentication=None, verbose=True)
2023-06-12 12:37:15,125:INFO:Initializing predict_model()
2023-06-12 12:37:15,125:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0047D0F0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['barriers', 'barriers_center',
                                             'bushes', 'bushes_center',
                                             'waterProp',
                                             'avg_brawler_Range_Num_diff',
                                             'avg_brawler_trophies_diff',
                                             'avg_brawler_...
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=4813))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('feature_selection',
                 TransformerWrapper(exclude=[],
                                    transformer=SelectFromModel(estimator=LGBMClassifier(),
                                                                max_features=13,
                                                                threshold=-inf))),
                ('actual_estimator', LGBMClassifier(random_state=4813))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F00291630>)
2023-06-12 12:37:15,125:INFO:Checking exceptions
2023-06-12 12:37:15,125:INFO:Preloading libraries
2023-06-12 12:37:53,454:INFO:Initializing predict_model()
2023-06-12 12:37:53,455:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F002DCC70>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['barriers', 'barriers_center',
                                             'bushes', 'bushes_center',
                                             'waterProp',
                                             'avg_brawler_Range_Num_diff',
                                             'avg_brawler_trophies_diff',
                                             'avg_brawler_...
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=4813))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('feature_selection',
                 TransformerWrapper(exclude=[],
                                    transformer=SelectFromModel(estimator=LGBMClassifier(),
                                                                max_features=13,
                                                                threshold=-inf))),
                ('actual_estimator', LGBMClassifier(random_state=4813))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F002912D0>)
2023-06-12 12:37:53,455:INFO:Checking exceptions
2023-06-12 12:37:53,455:INFO:Preloading libraries
2023-06-12 12:37:53,456:INFO:Set up data.
2023-06-12 12:37:53,482:INFO:Set up index.
2023-06-12 12:38:24,177:INFO:Initializing predict_model()
2023-06-12 12:38:24,177:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00413E20>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['barriers', 'barriers_center',
                                             'bushes', 'bushes_center',
                                             'waterProp',
                                             'avg_brawler_Range_Num_diff',
                                             'avg_brawler_trophies_diff',
                                             'avg_brawler_...
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=4813))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('feature_selection',
                 TransformerWrapper(exclude=[],
                                    transformer=SelectFromModel(estimator=LGBMClassifier(),
                                                                max_features=13,
                                                                threshold=-inf))),
                ('actual_estimator', LGBMClassifier(random_state=4813))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F7FE17EB0>)
2023-06-12 12:38:24,177:INFO:Checking exceptions
2023-06-12 12:38:24,177:INFO:Preloading libraries
2023-06-12 12:38:24,178:INFO:Set up data.
2023-06-12 12:38:24,199:INFO:Set up index.
2023-06-12 12:38:40,025:INFO:Initializing load_model()
2023-06-12 12:38:40,025:INFO:load_model(model_name=models/bs_predictor, platform=None, authentication=None, verbose=True)
2023-06-12 12:38:40,110:INFO:Initializing predict_model()
2023-06-12 12:38:40,110:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00413BE0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F004F60E0>)
2023-06-12 12:38:40,110:INFO:Checking exceptions
2023-06-12 12:38:40,111:INFO:Preloading libraries
2023-06-12 12:38:40,111:INFO:Set up data.
2023-06-12 12:38:40,143:INFO:Set up index.
2023-06-12 12:41:05,545:INFO:Initializing predict_model()
2023-06-12 12:41:05,545:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0517FE20>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F047AF640>)
2023-06-12 12:41:05,546:INFO:Checking exceptions
2023-06-12 12:41:05,546:INFO:Preloading libraries
2023-06-12 12:41:05,547:INFO:Set up data.
2023-06-12 12:41:05,573:INFO:Set up index.
2023-06-12 12:41:19,881:INFO:Initializing predict_model()
2023-06-12 12:41:19,881:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F7FEB1B10>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F047AE320>)
2023-06-12 12:41:19,881:INFO:Checking exceptions
2023-06-12 12:41:19,881:INFO:Preloading libraries
2023-06-12 12:41:19,882:INFO:Set up data.
2023-06-12 12:41:19,899:INFO:Set up index.
2023-06-12 12:41:40,942:INFO:Initializing predict_model()
2023-06-12 12:41:40,942:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0044AE00>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F047AE710>)
2023-06-12 12:41:40,942:INFO:Checking exceptions
2023-06-12 12:41:40,942:INFO:Preloading libraries
2023-06-12 12:41:40,957:INFO:Set up data.
2023-06-12 12:41:40,988:INFO:Set up index.
2023-06-12 12:41:51,775:INFO:Initializing predict_model()
2023-06-12 12:41:51,775:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F004130D0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F002903A0>)
2023-06-12 12:41:51,775:INFO:Checking exceptions
2023-06-12 12:41:51,775:INFO:Preloading libraries
2023-06-12 12:41:51,775:INFO:Set up data.
2023-06-12 12:41:51,840:INFO:Set up index.
2023-06-12 12:44:10,907:INFO:Initializing predict_model()
2023-06-12 12:44:10,907:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F002DEDD0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F047AF880>)
2023-06-12 12:44:10,909:INFO:Checking exceptions
2023-06-12 12:44:10,910:INFO:Preloading libraries
2023-06-12 12:44:10,910:INFO:Set up data.
2023-06-12 12:44:10,940:INFO:Set up index.
2023-06-12 12:44:24,576:INFO:Initializing predict_model()
2023-06-12 12:44:24,577:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F7FEB27D0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F002920E0>)
2023-06-12 12:44:24,577:INFO:Checking exceptions
2023-06-12 12:44:24,577:INFO:Preloading libraries
2023-06-12 12:44:24,578:INFO:Set up data.
2023-06-12 12:44:24,600:INFO:Set up index.
2023-06-12 12:44:34,940:INFO:Initializing predict_model()
2023-06-12 12:44:34,940:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F7FE43670>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F002920E0>)
2023-06-12 12:44:34,940:INFO:Checking exceptions
2023-06-12 12:44:34,940:INFO:Preloading libraries
2023-06-12 12:44:34,940:INFO:Set up data.
2023-06-12 12:44:34,971:INFO:Set up index.
2023-06-12 12:44:43,979:INFO:Initializing predict_model()
2023-06-12 12:44:43,979:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00338130>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F002912D0>)
2023-06-12 12:44:43,979:INFO:Checking exceptions
2023-06-12 12:44:43,979:INFO:Preloading libraries
2023-06-12 12:44:43,979:INFO:Set up data.
2023-06-12 12:44:44,001:INFO:Set up index.
2023-06-12 12:44:49,078:INFO:Initializing predict_model()
2023-06-12 12:44:49,089:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F002D80D0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F71ABBB50>)
2023-06-12 12:44:49,089:INFO:Checking exceptions
2023-06-12 12:44:49,089:INFO:Preloading libraries
2023-06-12 12:44:49,089:INFO:Set up data.
2023-06-12 12:44:49,115:INFO:Set up index.
2023-06-12 12:44:58,953:INFO:Initializing predict_model()
2023-06-12 12:44:58,953:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00339900>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F00292290>)
2023-06-12 12:44:58,953:INFO:Checking exceptions
2023-06-12 12:44:58,953:INFO:Preloading libraries
2023-06-12 12:44:58,954:INFO:Set up data.
2023-06-12 12:44:58,976:INFO:Set up index.
2023-06-12 12:46:07,475:INFO:Initializing predict_model()
2023-06-12 12:46:07,476:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00338AF0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F00291F30>)
2023-06-12 12:46:07,476:INFO:Checking exceptions
2023-06-12 12:46:07,476:INFO:Preloading libraries
2023-06-12 12:46:07,477:INFO:Set up data.
2023-06-12 12:46:07,505:INFO:Set up index.
2023-06-12 12:46:20,952:INFO:Initializing predict_model()
2023-06-12 12:46:20,953:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F002DED10>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F71B1C550>)
2023-06-12 12:46:20,953:INFO:Checking exceptions
2023-06-12 12:46:20,953:INFO:Preloading libraries
2023-06-12 12:46:20,955:INFO:Set up data.
2023-06-12 12:46:20,984:INFO:Set up index.
2023-06-12 12:48:47,013:INFO:Initializing predict_model()
2023-06-12 12:48:47,013:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F004499F0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F00291D80>)
2023-06-12 12:48:47,014:INFO:Checking exceptions
2023-06-12 12:48:47,014:INFO:Preloading libraries
2023-06-12 12:48:47,015:INFO:Set up data.
2023-06-12 12:48:47,034:INFO:Set up index.
2023-06-12 12:52:43,786:INFO:Initializing predict_model()
2023-06-12 12:52:43,786:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F002DFDF0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F002903A0>)
2023-06-12 12:52:43,786:INFO:Checking exceptions
2023-06-12 12:52:43,787:INFO:Preloading libraries
2023-06-12 12:52:43,787:INFO:Set up data.
2023-06-12 12:52:43,863:INFO:Set up index.
2023-06-12 12:53:06,015:INFO:Initializing predict_model()
2023-06-12 12:53:06,016:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F002DD750>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04880F70>)
2023-06-12 12:53:06,016:INFO:Checking exceptions
2023-06-12 12:53:06,016:INFO:Preloading libraries
2023-06-12 12:53:06,018:INFO:Set up data.
2023-06-12 12:53:06,040:INFO:Set up index.
2023-06-12 12:53:40,765:INFO:Initializing predict_model()
2023-06-12 12:53:40,767:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F7FEB3220>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04881900>)
2023-06-12 12:53:40,767:INFO:Checking exceptions
2023-06-12 12:53:40,767:INFO:Preloading libraries
2023-06-12 12:53:40,767:INFO:Set up data.
2023-06-12 12:53:40,794:INFO:Set up index.
2023-06-12 12:54:49,535:INFO:Initializing predict_model()
2023-06-12 12:54:49,536:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F71AB2650>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F048812D0>)
2023-06-12 12:54:49,537:INFO:Checking exceptions
2023-06-12 12:54:49,537:INFO:Preloading libraries
2023-06-12 12:54:49,538:INFO:Set up data.
2023-06-12 12:54:49,572:INFO:Set up index.
2023-06-12 12:56:37,843:INFO:Initializing predict_model()
2023-06-12 12:56:37,848:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F004127D0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04881BD0>)
2023-06-12 12:56:37,848:INFO:Checking exceptions
2023-06-12 12:56:37,849:INFO:Preloading libraries
2023-06-12 12:56:37,849:INFO:Set up data.
2023-06-12 12:56:37,869:INFO:Set up index.
2023-06-12 12:58:05,860:INFO:Initializing predict_model()
2023-06-12 12:58:05,862:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F71AB2170>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F047AEA70>)
2023-06-12 12:58:05,862:INFO:Checking exceptions
2023-06-12 12:58:05,862:INFO:Preloading libraries
2023-06-12 12:58:05,863:INFO:Set up data.
2023-06-12 12:58:05,906:INFO:Set up index.
2023-06-12 12:58:56,457:INFO:Initializing predict_model()
2023-06-12 12:58:56,457:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0047C2B0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F00291B40>)
2023-06-12 12:58:56,457:INFO:Checking exceptions
2023-06-12 12:58:56,457:INFO:Preloading libraries
2023-06-12 12:58:56,458:INFO:Set up data.
2023-06-12 12:58:56,475:INFO:Set up index.
2023-06-12 12:59:38,740:INFO:Initializing predict_model()
2023-06-12 12:59:38,740:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0517ED10>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F048830A0>)
2023-06-12 12:59:38,740:INFO:Checking exceptions
2023-06-12 12:59:38,741:INFO:Preloading libraries
2023-06-12 12:59:38,741:INFO:Set up data.
2023-06-12 12:59:38,760:INFO:Set up index.
2023-06-12 13:00:54,493:INFO:Initializing predict_model()
2023-06-12 13:00:54,493:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0044AC50>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04883250>)
2023-06-12 13:00:54,493:INFO:Checking exceptions
2023-06-12 13:00:54,493:INFO:Preloading libraries
2023-06-12 13:00:54,493:INFO:Set up data.
2023-06-12 13:00:54,522:INFO:Set up index.
2023-06-12 13:01:06,350:INFO:Initializing predict_model()
2023-06-12 13:01:06,351:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0517E200>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04883D00>)
2023-06-12 13:01:06,352:INFO:Checking exceptions
2023-06-12 13:01:06,352:INFO:Preloading libraries
2023-06-12 13:01:06,353:INFO:Set up data.
2023-06-12 13:01:06,370:INFO:Set up index.
2023-06-12 13:01:22,882:INFO:Initializing predict_model()
2023-06-12 13:01:22,882:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F003CD210>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04882170>)
2023-06-12 13:01:22,882:INFO:Checking exceptions
2023-06-12 13:01:22,882:INFO:Preloading libraries
2023-06-12 13:01:22,882:INFO:Set up data.
2023-06-12 13:01:22,901:INFO:Set up index.
2023-06-12 13:01:31,907:INFO:Initializing predict_model()
2023-06-12 13:01:31,908:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0033B6A0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04881870>)
2023-06-12 13:01:31,908:INFO:Checking exceptions
2023-06-12 13:01:31,908:INFO:Preloading libraries
2023-06-12 13:01:31,909:INFO:Set up data.
2023-06-12 13:01:31,925:INFO:Set up index.
2023-06-12 13:01:38,311:INFO:Initializing predict_model()
2023-06-12 13:01:38,311:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0044B490>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04883B50>)
2023-06-12 13:01:38,311:INFO:Checking exceptions
2023-06-12 13:01:38,311:INFO:Preloading libraries
2023-06-12 13:01:38,312:INFO:Set up data.
2023-06-12 13:01:38,328:INFO:Set up index.
2023-06-12 13:01:42,973:INFO:Initializing predict_model()
2023-06-12 13:01:42,974:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0033B970>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04882F80>)
2023-06-12 13:01:42,974:INFO:Checking exceptions
2023-06-12 13:01:42,974:INFO:Preloading libraries
2023-06-12 13:01:42,974:INFO:Set up data.
2023-06-12 13:01:42,988:INFO:Set up index.
2023-06-12 13:01:52,819:INFO:Initializing predict_model()
2023-06-12 13:01:52,820:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0517FC10>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F048830A0>)
2023-06-12 13:01:52,820:INFO:Checking exceptions
2023-06-12 13:01:52,820:INFO:Preloading libraries
2023-06-12 13:01:52,821:INFO:Set up data.
2023-06-12 13:01:52,843:INFO:Set up index.
2023-06-12 13:06:46,985:INFO:PyCaret ClassificationExperiment
2023-06-12 13:06:46,985:INFO:Logging name: clf-default-name
2023-06-12 13:06:46,985:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 13:06:46,985:INFO:version 3.0.2
2023-06-12 13:06:46,985:INFO:Initializing setup()
2023-06-12 13:06:46,986:INFO:self.USI: 654c
2023-06-12 13:06:46,986:INFO:self._variable_keys: {'X_train', 'is_multiclass', '_available_plots', 'USI', 'memory', 'X_test', 'y', 'pipeline', 'fold_shuffle_param', 'idx', 'y_train', 'log_plots_param', '_ml_usecase', 'fold_generator', 'exp_name_log', 'exp_id', 'html_param', 'data', 'y_test', 'fold_groups_param', 'fix_imbalance', 'target_param', 'logging_param', 'gpu_n_jobs_param', 'n_jobs_param', 'seed', 'X', 'gpu_param'}
2023-06-12 13:06:46,986:INFO:Checking environment
2023-06-12 13:06:46,986:INFO:python_version: 3.10.10
2023-06-12 13:06:46,986:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 13:06:46,986:INFO:machine: AMD64
2023-06-12 13:06:46,986:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 13:06:46,989:INFO:Memory: svmem(total=17034072064, available=7429492736, percent=56.4, used=9604579328, free=7429492736)
2023-06-12 13:06:46,990:INFO:Physical Core: 2
2023-06-12 13:06:46,990:INFO:Logical Core: 4
2023-06-12 13:06:46,990:INFO:Checking libraries
2023-06-12 13:06:46,990:INFO:System:
2023-06-12 13:06:46,990:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 13:06:46,990:INFO:executable: c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 13:06:46,990:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 13:06:46,990:INFO:PyCaret required dependencies:
2023-06-12 13:06:46,990:INFO:                 pip: 23.1.2
2023-06-12 13:06:46,990:INFO:          setuptools: 65.5.0
2023-06-12 13:06:46,990:INFO:             pycaret: 3.0.2
2023-06-12 13:06:46,990:INFO:             IPython: 8.14.0
2023-06-12 13:06:46,990:INFO:          ipywidgets: 8.0.6
2023-06-12 13:06:46,990:INFO:                tqdm: 4.65.0
2023-06-12 13:06:46,991:INFO:               numpy: 1.23.5
2023-06-12 13:06:46,991:INFO:              pandas: 1.5.3
2023-06-12 13:06:46,991:INFO:              jinja2: 3.1.2
2023-06-12 13:06:46,991:INFO:               scipy: 1.10.1
2023-06-12 13:06:46,991:INFO:              joblib: 1.2.0
2023-06-12 13:06:46,991:INFO:             sklearn: 1.2.2
2023-06-12 13:06:46,991:INFO:                pyod: 1.0.9
2023-06-12 13:06:46,991:INFO:            imblearn: 0.10.1
2023-06-12 13:06:46,991:INFO:   category_encoders: 2.6.1
2023-06-12 13:06:46,991:INFO:            lightgbm: 3.3.5
2023-06-12 13:06:46,991:INFO:               numba: 0.57.0
2023-06-12 13:06:46,991:INFO:            requests: 2.31.0
2023-06-12 13:06:46,991:INFO:          matplotlib: 3.7.1
2023-06-12 13:06:46,991:INFO:          scikitplot: 0.3.7
2023-06-12 13:06:46,991:INFO:         yellowbrick: 1.5
2023-06-12 13:06:46,991:INFO:              plotly: 5.15.0
2023-06-12 13:06:46,991:INFO:             kaleido: 0.2.1
2023-06-12 13:06:46,991:INFO:         statsmodels: 0.14.0
2023-06-12 13:06:46,991:INFO:              sktime: 0.17.0
2023-06-12 13:06:46,991:INFO:               tbats: 1.1.3
2023-06-12 13:06:46,991:INFO:            pmdarima: 2.0.3
2023-06-12 13:06:46,991:INFO:              psutil: 5.9.5
2023-06-12 13:06:46,991:INFO:PyCaret optional dependencies:
2023-06-12 13:06:46,992:INFO:                shap: Not installed
2023-06-12 13:06:46,992:INFO:           interpret: Not installed
2023-06-12 13:06:46,992:INFO:                umap: Not installed
2023-06-12 13:06:46,992:INFO:    pandas_profiling: Not installed
2023-06-12 13:06:46,992:INFO:  explainerdashboard: Not installed
2023-06-12 13:06:46,992:INFO:             autoviz: Not installed
2023-06-12 13:06:46,992:INFO:           fairlearn: Not installed
2023-06-12 13:06:46,992:INFO:             xgboost: Not installed
2023-06-12 13:06:46,992:INFO:            catboost: Not installed
2023-06-12 13:06:46,992:INFO:              kmodes: Not installed
2023-06-12 13:06:46,992:INFO:             mlxtend: Not installed
2023-06-12 13:06:46,992:INFO:       statsforecast: Not installed
2023-06-12 13:06:46,992:INFO:        tune_sklearn: Not installed
2023-06-12 13:06:46,992:INFO:                 ray: Not installed
2023-06-12 13:06:46,992:INFO:            hyperopt: Not installed
2023-06-12 13:06:46,992:INFO:              optuna: Not installed
2023-06-12 13:06:46,992:INFO:               skopt: Not installed
2023-06-12 13:06:46,992:INFO:              mlflow: 2.4.1
2023-06-12 13:06:46,992:INFO:              gradio: Not installed
2023-06-12 13:06:46,992:INFO:             fastapi: Not installed
2023-06-12 13:06:46,993:INFO:             uvicorn: Not installed
2023-06-12 13:06:46,993:INFO:              m2cgen: Not installed
2023-06-12 13:06:46,993:INFO:           evidently: Not installed
2023-06-12 13:06:46,993:INFO:               fugue: Not installed
2023-06-12 13:06:46,993:INFO:           streamlit: 1.23.1
2023-06-12 13:06:46,993:INFO:             prophet: Not installed
2023-06-12 13:06:46,993:INFO:None
2023-06-12 13:06:46,993:INFO:Set up data.
2023-06-12 13:06:47,007:INFO:Set up train/test split.
2023-06-12 13:06:47,050:INFO:Set up index.
2023-06-12 13:06:47,052:INFO:Set up folding strategy.
2023-06-12 13:06:47,053:INFO:Assigning column types.
2023-06-12 13:06:47,063:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 13:06:47,110:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 13:06:47,112:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 13:06:47,141:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,141:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,188:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 13:06:47,190:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 13:06:47,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,217:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,217:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 13:06:47,264:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 13:06:47,295:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,345:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 13:06:47,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,374:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 13:06:47,454:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,531:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,533:INFO:Preparing preprocessing pipeline...
2023-06-12 13:06:47,536:INFO:Set up label encoding.
2023-06-12 13:06:47,536:INFO:Set up simple imputation.
2023-06-12 13:06:47,550:INFO:Set up encoding of categorical features.
2023-06-12 13:06:49,253:INFO:Finished creating preprocessing pipeline.
2023-06-12 13:06:49,262:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 13:06:49,262:INFO:Creating final display dataframe.
2023-06-12 13:06:53,012:INFO:Setup _display_container:                     Description             Value
0                    Session id              7261
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape       (96892, 13)
5        Transformed data shape      (96892, 454)
6   Transformed train set shape      (67824, 454)
7    Transformed test set shape      (29068, 454)
8              Numeric features                 4
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              654c
2023-06-12 13:06:53,163:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:53,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:53,259:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:53,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:53,261:INFO:Logging experiment in loggers
2023-06-12 13:06:53,882:INFO:SubProcess save_model() called ==================================
2023-06-12 13:06:53,897:INFO:Initializing save_model()
2023-06-12 13:06:53,898:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmp8ffs2lfh\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 13:06:53,898:INFO:Adding model into prep_pipe
2023-06-12 13:06:53,898:WARNING:Only Model saved as it was a pipeline.
2023-06-12 13:06:53,911:INFO:C:\Users\alniquia\AppData\Local\Temp\tmp8ffs2lfh\Transformation Pipeline.pkl saved in current working directory
2023-06-12 13:06:53,917:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 13:06:53,917:INFO:save_model() successfully completed......................................
2023-06-12 13:06:54,229:INFO:SubProcess save_model() end ==================================
2023-06-12 13:06:54,249:INFO:setup() successfully completed in 23.38s...............
2023-06-12 13:07:10,514:INFO:Initializing create_model()
2023-06-12 13:07:10,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D86AB63A00>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 13:07:10,514:INFO:Checking exceptions
2023-06-12 13:07:10,546:INFO:Importing libraries
2023-06-12 13:07:10,546:INFO:Copying training dataset
2023-06-12 13:07:10,595:INFO:Defining folds
2023-06-12 13:07:10,595:INFO:Declaring metric variables
2023-06-12 13:07:10,602:INFO:Importing untrained model
2023-06-12 13:07:10,607:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 13:07:10,622:INFO:Starting cross validation
2023-06-12 13:07:10,626:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 13:08:21,962:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:08:21,993:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:08:22,438:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:08:22,485:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:08:59,654:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 13:09:10,312:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:09:11,508:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:09:44,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 13:09:44,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 13:09:44,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 13:09:44,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 13:09:46,375:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-12 13:10:09,155:INFO:PyCaret ClassificationExperiment
2023-06-12 13:10:09,155:INFO:Logging name: clf-default-name
2023-06-12 13:10:09,155:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 13:10:09,155:INFO:version 3.0.2
2023-06-12 13:10:09,156:INFO:Initializing setup()
2023-06-12 13:10:09,156:INFO:self.USI: b30b
2023-06-12 13:10:09,156:INFO:self._variable_keys: {'html_param', 'seed', 'gpu_n_jobs_param', 'X_train', 'exp_id', 'fix_imbalance', 'is_multiclass', 'USI', 'y_train', 'fold_shuffle_param', 'logging_param', 'gpu_param', 'y', 'fold_groups_param', 'target_param', 'X', 'idx', 'exp_name_log', '_available_plots', 'fold_generator', 'log_plots_param', 'pipeline', 'n_jobs_param', 'memory', 'X_test', '_ml_usecase', 'data', 'y_test'}
2023-06-12 13:10:09,156:INFO:Checking environment
2023-06-12 13:10:09,156:INFO:python_version: 3.10.10
2023-06-12 13:10:09,156:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 13:10:09,156:INFO:machine: AMD64
2023-06-12 13:10:09,156:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 13:10:09,160:INFO:Memory: svmem(total=17034072064, available=7098417152, percent=58.3, used=9935654912, free=7098417152)
2023-06-12 13:10:09,160:INFO:Physical Core: 2
2023-06-12 13:10:09,160:INFO:Logical Core: 4
2023-06-12 13:10:09,160:INFO:Checking libraries
2023-06-12 13:10:09,160:INFO:System:
2023-06-12 13:10:09,160:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 13:10:09,160:INFO:executable: c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 13:10:09,160:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 13:10:09,160:INFO:PyCaret required dependencies:
2023-06-12 13:10:09,160:INFO:                 pip: 23.1.2
2023-06-12 13:10:09,161:INFO:          setuptools: 65.5.0
2023-06-12 13:10:09,161:INFO:             pycaret: 3.0.2
2023-06-12 13:10:09,161:INFO:             IPython: 8.14.0
2023-06-12 13:10:09,161:INFO:          ipywidgets: 8.0.6
2023-06-12 13:10:09,161:INFO:                tqdm: 4.65.0
2023-06-12 13:10:09,161:INFO:               numpy: 1.23.5
2023-06-12 13:10:09,161:INFO:              pandas: 1.5.3
2023-06-12 13:10:09,161:INFO:              jinja2: 3.1.2
2023-06-12 13:10:09,161:INFO:               scipy: 1.10.1
2023-06-12 13:10:09,161:INFO:              joblib: 1.2.0
2023-06-12 13:10:09,161:INFO:             sklearn: 1.2.2
2023-06-12 13:10:09,161:INFO:                pyod: 1.0.9
2023-06-12 13:10:09,161:INFO:            imblearn: 0.10.1
2023-06-12 13:10:09,161:INFO:   category_encoders: 2.6.1
2023-06-12 13:10:09,161:INFO:            lightgbm: 3.3.5
2023-06-12 13:10:09,161:INFO:               numba: 0.57.0
2023-06-12 13:10:09,161:INFO:            requests: 2.31.0
2023-06-12 13:10:09,161:INFO:          matplotlib: 3.7.1
2023-06-12 13:10:09,161:INFO:          scikitplot: 0.3.7
2023-06-12 13:10:09,161:INFO:         yellowbrick: 1.5
2023-06-12 13:10:09,161:INFO:              plotly: 5.15.0
2023-06-12 13:10:09,162:INFO:             kaleido: 0.2.1
2023-06-12 13:10:09,162:INFO:         statsmodels: 0.14.0
2023-06-12 13:10:09,162:INFO:              sktime: 0.17.0
2023-06-12 13:10:09,162:INFO:               tbats: 1.1.3
2023-06-12 13:10:09,162:INFO:            pmdarima: 2.0.3
2023-06-12 13:10:09,162:INFO:              psutil: 5.9.5
2023-06-12 13:10:09,162:INFO:PyCaret optional dependencies:
2023-06-12 13:10:09,314:INFO:                shap: Not installed
2023-06-12 13:10:09,314:INFO:           interpret: Not installed
2023-06-12 13:10:09,314:INFO:                umap: Not installed
2023-06-12 13:10:09,314:INFO:    pandas_profiling: Not installed
2023-06-12 13:10:09,314:INFO:  explainerdashboard: Not installed
2023-06-12 13:10:09,326:INFO:             autoviz: Not installed
2023-06-12 13:10:09,326:INFO:           fairlearn: Not installed
2023-06-12 13:10:09,326:INFO:             xgboost: Not installed
2023-06-12 13:10:09,327:INFO:            catboost: Not installed
2023-06-12 13:10:09,327:INFO:              kmodes: Not installed
2023-06-12 13:10:09,327:INFO:             mlxtend: Not installed
2023-06-12 13:10:09,327:INFO:       statsforecast: Not installed
2023-06-12 13:10:09,327:INFO:        tune_sklearn: Not installed
2023-06-12 13:10:09,327:INFO:                 ray: Not installed
2023-06-12 13:10:09,327:INFO:            hyperopt: Not installed
2023-06-12 13:10:09,327:INFO:              optuna: Not installed
2023-06-12 13:10:09,328:INFO:               skopt: Not installed
2023-06-12 13:10:09,328:INFO:              mlflow: 2.4.1
2023-06-12 13:10:09,328:INFO:              gradio: Not installed
2023-06-12 13:10:09,328:INFO:             fastapi: Not installed
2023-06-12 13:10:09,328:INFO:             uvicorn: Not installed
2023-06-12 13:10:09,328:INFO:              m2cgen: Not installed
2023-06-12 13:10:09,328:INFO:           evidently: Not installed
2023-06-12 13:10:09,328:INFO:               fugue: Not installed
2023-06-12 13:10:09,328:INFO:           streamlit: 1.23.1
2023-06-12 13:10:09,328:INFO:             prophet: Not installed
2023-06-12 13:10:09,328:INFO:None
2023-06-12 13:10:09,328:INFO:Set up data.
2023-06-12 13:10:09,358:INFO:Set up train/test split.
2023-06-12 13:10:09,427:INFO:Set up index.
2023-06-12 13:10:09,429:INFO:Set up folding strategy.
2023-06-12 13:10:09,429:INFO:Assigning column types.
2023-06-12 13:10:09,441:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 13:10:09,560:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 13:10:09,577:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 13:10:09,686:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:09,735:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:09,783:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 13:10:09,784:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 13:10:09,811:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:09,812:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:09,812:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 13:10:09,859:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 13:10:09,890:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:09,890:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:09,939:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 13:10:09,969:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:09,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:09,970:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 13:10:10,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:10,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:10,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:10,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:10,160:INFO:Preparing preprocessing pipeline...
2023-06-12 13:10:10,163:INFO:Set up label encoding.
2023-06-12 13:10:10,163:INFO:Set up simple imputation.
2023-06-12 13:10:10,186:INFO:Set up encoding of categorical features.
2023-06-12 13:10:11,574:INFO:Finished creating preprocessing pipeline.
2023-06-12 13:10:11,580:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 13:10:11,580:INFO:Creating final display dataframe.
2023-06-12 13:10:14,255:INFO:Setup _display_container:                     Description             Value
0                    Session id              6999
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape       (62905, 12)
5        Transformed data shape      (62905, 418)
6   Transformed train set shape      (44033, 418)
7    Transformed test set shape      (18872, 418)
8              Numeric features                 4
9          Categorical features                 7
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              b30b
2023-06-12 13:10:14,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:14,352:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:14,428:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:14,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:14,429:INFO:Logging experiment in loggers
2023-06-12 13:10:15,099:INFO:SubProcess save_model() called ==================================
2023-06-12 13:10:15,128:INFO:Initializing save_model()
2023-06-12 13:10:15,128:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmp1kz_58q0\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 13:10:15,128:INFO:Adding model into prep_pipe
2023-06-12 13:10:15,128:WARNING:Only Model saved as it was a pipeline.
2023-06-12 13:10:15,144:INFO:C:\Users\alniquia\AppData\Local\Temp\tmp1kz_58q0\Transformation Pipeline.pkl saved in current working directory
2023-06-12 13:10:15,155:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 13:10:15,155:INFO:save_model() successfully completed......................................
2023-06-12 13:10:15,252:INFO:SubProcess save_model() end ==================================
2023-06-12 13:10:15,284:INFO:setup() successfully completed in 24.9s...............
2023-06-12 13:10:15,393:INFO:Initializing create_model()
2023-06-12 13:10:15,393:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016217B6FB80>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 13:10:15,393:INFO:Checking exceptions
2023-06-12 13:10:15,451:INFO:Importing libraries
2023-06-12 13:10:15,452:INFO:Copying training dataset
2023-06-12 13:10:15,473:INFO:Defining folds
2023-06-12 13:10:15,473:INFO:Declaring metric variables
2023-06-12 13:10:15,477:INFO:Importing untrained model
2023-06-12 13:10:15,483:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 13:10:15,493:INFO:Starting cross validation
2023-06-12 13:10:15,496:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 13:10:34,718:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:10:34,760:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:10:34,776:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:10:34,793:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:11:14,693:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:12:05,616:INFO:Initializing load_model()
2023-06-12 13:12:05,617:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-12 13:12:53,139:INFO:Initializing load_model()
2023-06-12 13:12:53,139:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-12 13:14:05,172:INFO:Calculating mean and std
2023-06-12 13:14:05,174:INFO:Creating metrics dataframe
2023-06-12 13:14:05,184:INFO:Finalizing model
2023-06-12 13:14:26,838:INFO:Creating Dashboard logs
2023-06-12 13:14:26,844:INFO:Model: Light Gradient Boosting Machine
2023-06-12 13:14:26,938:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6999, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 13:14:27,147:INFO:Initializing predict_model()
2023-06-12 13:14:27,147:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016217B6FB80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000162328DA200>)
2023-06-12 13:14:27,147:INFO:Checking exceptions
2023-06-12 13:14:27,147:INFO:Preloading libraries
2023-06-12 13:14:27,970:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-06-12 13:14:44,767:INFO:Uploading results into container
2023-06-12 13:14:44,768:INFO:Uploading model into container now
2023-06-12 13:14:44,780:INFO:_master_model_container: 1
2023-06-12 13:14:44,780:INFO:_display_container: 2
2023-06-12 13:14:44,781:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 13:14:44,781:INFO:create_model() successfully completed......................................
2023-06-12 13:14:44,966:INFO:Initializing tune_model()
2023-06-12 13:14:44,966:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016217B6FB80>)
2023-06-12 13:14:44,966:INFO:Checking exceptions
2023-06-12 13:14:45,013:INFO:Copying training dataset
2023-06-12 13:14:45,035:INFO:Checking base model
2023-06-12 13:14:45,035:INFO:Base model : Light Gradient Boosting Machine
2023-06-12 13:14:45,044:INFO:Declaring metric variables
2023-06-12 13:14:45,054:INFO:Defining Hyperparameters
2023-06-12 13:14:45,210:INFO:Tuning with n_jobs=-1
2023-06-12 13:14:45,210:INFO:Initializing RandomizedSearchCV
2023-06-12 13:19:41,140:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:19:43,727:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:20:04,550:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:20:07,765:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:20:26,193:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:20:29,987:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:20:47,712:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:20:51,686:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:21:13,996:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:21:17,627:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:21:29,970:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:21:33,625:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:21:53,559:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:21:56,984:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:22:12,146:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:22:15,701:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:22:33,772:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:22:37,486:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:22:53,609:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:22:57,170:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:27:17,879:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:45:33,421:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.3, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 31, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 0.5}
2023-06-12 13:45:33,422:INFO:Hyperparameter search completed
2023-06-12 13:45:33,423:INFO:SubProcess create_model() called ==================================
2023-06-12 13:45:33,423:INFO:Initializing create_model()
2023-06-12 13:45:33,424:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016217B6FB80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622DA62230>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.3, 'num_leaves': 30, 'n_estimators': 150, 'min_split_gain': 0.2, 'min_child_samples': 31, 'learning_rate': 0.1, 'feature_fraction': 0.8, 'bagging_freq': 5, 'bagging_fraction': 0.5})
2023-06-12 13:45:33,424:INFO:Checking exceptions
2023-06-12 13:45:33,424:INFO:Importing libraries
2023-06-12 13:45:33,424:INFO:Copying training dataset
2023-06-12 13:45:33,440:INFO:Defining folds
2023-06-12 13:45:33,441:INFO:Declaring metric variables
2023-06-12 13:45:33,445:INFO:Importing untrained model
2023-06-12 13:45:33,445:INFO:Declaring custom model
2023-06-12 13:45:33,450:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 13:45:33,458:INFO:Starting cross validation
2023-06-12 13:45:33,461:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 13:48:21,762:INFO:Calculating mean and std
2023-06-12 13:48:21,764:INFO:Creating metrics dataframe
2023-06-12 13:48:21,772:INFO:Finalizing model
2023-06-12 13:48:22,376:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-06-12 13:48:22,376:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2023-06-12 13:48:22,376:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2023-06-12 13:48:40,380:INFO:Uploading results into container
2023-06-12 13:48:40,382:INFO:Uploading model into container now
2023-06-12 13:48:40,382:INFO:_master_model_container: 2
2023-06-12 13:48:40,383:INFO:_display_container: 3
2023-06-12 13:48:40,383:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=150, n_jobs=-1, num_leaves=30, objective=None,
               random_state=6999, reg_alpha=0.3, reg_lambda=0.0005,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-06-12 13:48:40,384:INFO:create_model() successfully completed......................................
2023-06-12 13:48:40,487:INFO:SubProcess create_model() end ==================================
2023-06-12 13:48:40,487:INFO:choose_better activated
2023-06-12 13:48:40,492:INFO:SubProcess create_model() called ==================================
2023-06-12 13:48:40,493:INFO:Initializing create_model()
2023-06-12 13:48:40,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016217B6FB80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 13:48:40,493:INFO:Checking exceptions
2023-06-12 13:48:40,496:INFO:Importing libraries
2023-06-12 13:48:40,497:INFO:Copying training dataset
2023-06-12 13:48:40,524:INFO:Defining folds
2023-06-12 13:48:40,524:INFO:Declaring metric variables
2023-06-12 13:48:40,524:INFO:Importing untrained model
2023-06-12 13:48:40,524:INFO:Declaring custom model
2023-06-12 13:48:40,525:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 13:48:40,525:INFO:Starting cross validation
2023-06-12 13:48:40,527:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 13:51:32,093:INFO:Calculating mean and std
2023-06-12 13:51:32,094:INFO:Creating metrics dataframe
2023-06-12 13:51:32,096:INFO:Finalizing model
2023-06-12 13:51:51,081:INFO:Uploading results into container
2023-06-12 13:51:51,082:INFO:Uploading model into container now
2023-06-12 13:51:51,082:INFO:_master_model_container: 3
2023-06-12 13:51:51,082:INFO:_display_container: 4
2023-06-12 13:51:51,083:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 13:51:51,083:INFO:create_model() successfully completed......................................
2023-06-12 13:51:51,173:INFO:SubProcess create_model() end ==================================
2023-06-12 13:51:51,174:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.686
2023-06-12 13:51:51,175:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=150, n_jobs=-1, num_leaves=30, objective=None,
               random_state=6999, reg_alpha=0.3, reg_lambda=0.0005,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) result for F1 is 0.6855
2023-06-12 13:51:51,175:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-06-12 13:51:51,175:INFO:choose_better completed
2023-06-12 13:51:51,176:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-12 13:51:51,176:INFO:Creating Dashboard logs
2023-06-12 13:51:51,183:INFO:Model: Light Gradient Boosting Machine
2023-06-12 13:51:51,284:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6999, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 13:51:51,521:INFO:Initializing predict_model()
2023-06-12 13:51:51,521:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016217B6FB80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000162328D9E10>)
2023-06-12 13:51:51,522:INFO:Checking exceptions
2023-06-12 13:51:51,522:INFO:Preloading libraries
2023-06-12 13:52:07,196:INFO:_master_model_container: 3
2023-06-12 13:52:07,197:INFO:_display_container: 3
2023-06-12 13:52:07,197:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 13:52:07,197:INFO:tune_model() successfully completed......................................
2023-06-12 13:52:22,228:INFO:Initializing finalize_model()
2023-06-12 13:52:22,228:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016217B6FB80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-12 13:52:22,229:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 13:52:22,237:INFO:Initializing create_model()
2023-06-12 13:52:22,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016217B6FB80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-12 13:52:22,238:INFO:Checking exceptions
2023-06-12 13:52:22,240:INFO:Importing libraries
2023-06-12 13:52:22,240:INFO:Copying training dataset
2023-06-12 13:52:22,241:INFO:Defining folds
2023-06-12 13:52:22,241:INFO:Declaring metric variables
2023-06-12 13:52:22,241:INFO:Importing untrained model
2023-06-12 13:52:22,241:INFO:Declaring custom model
2023-06-12 13:52:22,242:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 13:52:22,245:INFO:Cross validation set to False
2023-06-12 13:52:22,245:INFO:Fitting Model
2023-06-12 13:52:26,027:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 13:52:26,027:INFO:create_model() successfully completed......................................
2023-06-12 13:52:26,135:INFO:Creating Dashboard logs
2023-06-12 13:52:26,136:INFO:Model: Light Gradient Boosting Machine
2023-06-12 13:52:26,246:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6999, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 13:52:26,660:INFO:_master_model_container: 3
2023-06-12 13:52:26,661:INFO:_display_container: 3
2023-06-12 13:52:26,671:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 13:52:26,671:INFO:finalize_model() successfully completed......................................
2023-06-12 13:52:26,830:INFO:Initializing save_model()
2023-06-12 13:52:26,830:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=bs_predictor_brawlBall, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 13:52:26,830:INFO:Adding model into prep_pipe
2023-06-12 13:52:26,830:WARNING:Only Model saved as it was a pipeline.
2023-06-12 13:52:26,869:INFO:bs_predictor_brawlBall.pkl saved in current working directory
2023-06-12 13:52:26,887:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 13:52:26,888:INFO:save_model() successfully completed......................................
2023-06-12 13:52:27,055:INFO:Initializing predict_model()
2023-06-12 13:52:27,055:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016217B6FB80>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001622A5A9E10>)
2023-06-12 13:52:27,055:INFO:Checking exceptions
2023-06-12 13:52:27,055:INFO:Preloading libraries
2023-06-12 13:52:27,059:INFO:Set up data.
2023-06-12 13:52:27,076:INFO:Set up index.
2023-06-12 14:07:21,286:INFO:Initializing load_model()
2023-06-12 14:07:21,287:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-12 14:07:23,438:INFO:Initializing load_model()
2023-06-12 14:07:23,438:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-12 14:07:44,031:INFO:Initializing save_model()
2023-06-12 14:07:44,032:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=models/bs_predictor_brawlBall, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 14:07:44,032:INFO:Adding model into prep_pipe
2023-06-12 14:07:44,032:WARNING:Only Model saved as it was a pipeline.
2023-06-12 14:07:44,089:INFO:models/bs_predictor_brawlBall.pkl saved in current working directory
2023-06-12 14:07:44,117:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 14:07:44,118:INFO:save_model() successfully completed......................................
2023-06-12 14:07:52,807:INFO:Initializing load_model()
2023-06-12 14:07:52,807:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-12 14:08:10,751:INFO:Initializing predict_model()
2023-06-12 14:08:10,751:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0044B280>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                    transformer=OneHotEncoder(cols=['event_map',
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator', LGBMClassifier(random_state=6999))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04883130>)
2023-06-12 14:08:10,751:INFO:Checking exceptions
2023-06-12 14:08:10,751:INFO:Preloading libraries
2023-06-12 14:08:10,752:INFO:Set up data.
2023-06-12 14:08:10,768:INFO:Set up index.
2023-06-12 14:08:35,311:INFO:Initializing predict_model()
2023-06-12 14:08:35,311:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0517F670>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                    transformer=OneHotEncoder(cols=['event_map',
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator', LGBMClassifier(random_state=6999))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F05188EE0>)
2023-06-12 14:08:35,312:INFO:Checking exceptions
2023-06-12 14:08:35,312:INFO:Preloading libraries
2023-06-12 14:08:35,312:INFO:Set up data.
2023-06-12 14:08:35,328:INFO:Set up index.
