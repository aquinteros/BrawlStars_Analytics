2023-06-10 21:23:09,609:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:23:09,610:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:23:09,610:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:23:09,610:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:23:10,828:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-10 21:27:02,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:27:02,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:27:02,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:27:02,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:27:04,249:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-10 21:28:47,089:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:28:47,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:28:47,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:28:47,090:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-10 21:28:48,925:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-11 20:53:15,586:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 20:53:15,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 20:53:15,592:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 20:53:15,593:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 20:53:19,763:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-11 20:53:35,707:INFO:Initializing load_model()
2023-06-11 20:53:35,708:INFO:load_model(model_name=bs_predictor, platform=None, authentication=None, verbose=True)
2023-06-11 20:53:57,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 20:53:57,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 20:53:57,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 20:53:57,692:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 20:53:58,770:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-11 20:54:06,229:INFO:Initializing load_model()
2023-06-11 20:54:06,230:INFO:load_model(model_name=bs_predictor, platform=None, authentication=None, verbose=True)
2023-06-11 20:54:07,977:INFO:Initializing predict_model()
2023-06-11 20:54:07,977:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216F2B781C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['barriers', 'barriers_center',
                                             'bushes', 'bushes_center',
                                             'waterProp',
                                             'avg_brawler_Range_Num_diff',
                                             'avg_brawler_trophies_diff',
                                             'avg_brawler_...
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=4813))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('feature_selection',
                 TransformerWrapper(exclude=[],
                                    transformer=SelectFromModel(estimator=LGBMClassifier(),
                                                                max_features=13,
                                                                threshold=-inf))),
                ('actual_estimator', LGBMClassifier(random_state=4813))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000216DBF4FB50>)
2023-06-11 20:54:07,977:INFO:Checking exceptions
2023-06-11 20:54:07,977:INFO:Preloading libraries
2023-06-11 20:54:07,977:INFO:Set up data.
2023-06-11 20:54:08,030:INFO:Set up index.
2023-06-11 20:56:26,592:INFO:Initializing predict_model()
2023-06-11 20:56:26,592:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000216F1EC4430>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['barriers', 'barriers_center',
                                             'bushes', 'bushes_center',
                                             'waterProp',
                                             'avg_brawler_Range_Num_diff',
                                             'avg_brawler_trophies_diff',
                                             'avg_brawler_...
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=4813))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('feature_selection',
                 TransformerWrapper(exclude=[],
                                    transformer=SelectFromModel(estimator=LGBMClassifier(),
                                                                max_features=13,
                                                                threshold=-inf))),
                ('actual_estimator', LGBMClassifier(random_state=4813))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000216DBF4DBD0>)
2023-06-11 20:56:26,592:INFO:Checking exceptions
2023-06-11 20:56:26,592:INFO:Preloading libraries
2023-06-11 20:56:26,593:INFO:Set up data.
2023-06-11 20:56:26,690:INFO:Set up index.
2023-06-11 21:45:05,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 21:45:05,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 21:45:05,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 21:45:05,044:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-11 21:45:09,419:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-11 21:45:31,009:INFO:Initializing load_model()
2023-06-11 21:45:31,010:INFO:load_model(model_name=models/bs_predictor, platform=None, authentication=None, verbose=True)
2023-06-11 21:56:38,042:INFO:PyCaret ClassificationExperiment
2023-06-11 21:56:38,042:INFO:Logging name: clf-default-name
2023-06-11 21:56:38,042:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-11 21:56:38,042:INFO:version 3.0.2
2023-06-11 21:56:38,043:INFO:Initializing setup()
2023-06-11 21:56:38,043:INFO:self.USI: 6e20
2023-06-11 21:56:38,043:INFO:self._variable_keys: {'X', 'fold_generator', 'is_multiclass', 'logging_param', 'fold_groups_param', 'exp_id', 'data', 'gpu_param', 'log_plots_param', 'idx', 'seed', 'memory', 'X_test', 'target_param', 'y_train', 'gpu_n_jobs_param', '_available_plots', '_ml_usecase', 'y_test', 'html_param', 'pipeline', 'exp_name_log', 'n_jobs_param', 'X_train', 'y', 'fix_imbalance', 'USI', 'fold_shuffle_param'}
2023-06-11 21:56:38,043:INFO:Checking environment
2023-06-11 21:56:38,044:INFO:python_version: 3.10.10
2023-06-11 21:56:38,044:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-11 21:56:38,044:INFO:machine: AMD64
2023-06-11 21:56:38,044:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-11 21:56:38,047:INFO:Memory: svmem(total=17034072064, available=9568903168, percent=43.8, used=7465168896, free=9568903168)
2023-06-11 21:56:38,047:INFO:Physical Core: 2
2023-06-11 21:56:38,047:INFO:Logical Core: 4
2023-06-11 21:56:38,047:INFO:Checking libraries
2023-06-11 21:56:38,047:INFO:System:
2023-06-11 21:56:38,048:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-11 21:56:38,048:INFO:executable: c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-11 21:56:38,048:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-11 21:56:38,048:INFO:PyCaret required dependencies:
2023-06-11 21:56:38,048:INFO:                 pip: 23.1.2
2023-06-11 21:56:38,048:INFO:          setuptools: 65.5.0
2023-06-11 21:56:38,048:INFO:             pycaret: 3.0.2
2023-06-11 21:56:38,049:INFO:             IPython: 8.14.0
2023-06-11 21:56:38,049:INFO:          ipywidgets: 8.0.6
2023-06-11 21:56:38,049:INFO:                tqdm: 4.65.0
2023-06-11 21:56:38,049:INFO:               numpy: 1.23.5
2023-06-11 21:56:38,049:INFO:              pandas: 1.5.3
2023-06-11 21:56:38,049:INFO:              jinja2: 3.1.2
2023-06-11 21:56:38,049:INFO:               scipy: 1.10.1
2023-06-11 21:56:38,049:INFO:              joblib: 1.2.0
2023-06-11 21:56:38,049:INFO:             sklearn: 1.2.2
2023-06-11 21:56:38,050:INFO:                pyod: 1.0.9
2023-06-11 21:56:38,050:INFO:            imblearn: 0.10.1
2023-06-11 21:56:38,050:INFO:   category_encoders: 2.6.1
2023-06-11 21:56:38,050:INFO:            lightgbm: 3.3.5
2023-06-11 21:56:38,050:INFO:               numba: 0.57.0
2023-06-11 21:56:38,050:INFO:            requests: 2.31.0
2023-06-11 21:56:38,050:INFO:          matplotlib: 3.7.1
2023-06-11 21:56:38,050:INFO:          scikitplot: 0.3.7
2023-06-11 21:56:38,050:INFO:         yellowbrick: 1.5
2023-06-11 21:56:38,050:INFO:              plotly: 5.15.0
2023-06-11 21:56:38,050:INFO:             kaleido: 0.2.1
2023-06-11 21:56:38,050:INFO:         statsmodels: 0.14.0
2023-06-11 21:56:38,050:INFO:              sktime: 0.17.0
2023-06-11 21:56:38,052:INFO:               tbats: 1.1.3
2023-06-11 21:56:38,053:INFO:            pmdarima: 2.0.3
2023-06-11 21:56:38,053:INFO:              psutil: 5.9.5
2023-06-11 21:56:38,053:INFO:PyCaret optional dependencies:
2023-06-11 21:56:38,108:INFO:                shap: Not installed
2023-06-11 21:56:38,108:INFO:           interpret: Not installed
2023-06-11 21:56:38,108:INFO:                umap: Not installed
2023-06-11 21:56:38,108:INFO:    pandas_profiling: Not installed
2023-06-11 21:56:38,108:INFO:  explainerdashboard: Not installed
2023-06-11 21:56:38,108:INFO:             autoviz: Not installed
2023-06-11 21:56:38,108:INFO:           fairlearn: Not installed
2023-06-11 21:56:38,108:INFO:             xgboost: Not installed
2023-06-11 21:56:38,108:INFO:            catboost: Not installed
2023-06-11 21:56:38,108:INFO:              kmodes: Not installed
2023-06-11 21:56:38,108:INFO:             mlxtend: Not installed
2023-06-11 21:56:38,109:INFO:       statsforecast: Not installed
2023-06-11 21:56:38,109:INFO:        tune_sklearn: Not installed
2023-06-11 21:56:38,109:INFO:                 ray: Not installed
2023-06-11 21:56:38,109:INFO:            hyperopt: Not installed
2023-06-11 21:56:38,109:INFO:              optuna: Not installed
2023-06-11 21:56:38,109:INFO:               skopt: Not installed
2023-06-11 21:56:38,109:INFO:              mlflow: 2.4.1
2023-06-11 21:56:38,109:INFO:              gradio: Not installed
2023-06-11 21:56:38,109:INFO:             fastapi: Not installed
2023-06-11 21:56:38,109:INFO:             uvicorn: Not installed
2023-06-11 21:56:38,109:INFO:              m2cgen: Not installed
2023-06-11 21:56:38,109:INFO:           evidently: Not installed
2023-06-11 21:56:38,109:INFO:               fugue: Not installed
2023-06-11 21:56:38,109:INFO:           streamlit: 1.23.1
2023-06-11 21:56:38,109:INFO:             prophet: Not installed
2023-06-11 21:56:38,109:INFO:None
2023-06-11 21:56:38,109:INFO:Set up data.
2023-06-11 21:56:38,144:INFO:Set up train/test split.
2023-06-11 21:56:38,237:INFO:Set up index.
2023-06-11 21:56:38,241:INFO:Set up folding strategy.
2023-06-11 21:56:38,241:INFO:Assigning column types.
2023-06-11 21:56:38,265:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-11 21:56:38,335:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-11 21:56:38,349:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-11 21:56:38,447:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,508:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-11 21:56:38,510:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-11 21:56:38,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,547:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-11 21:56:38,603:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-11 21:56:38,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,691:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-11 21:56:38,724:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,725:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-11 21:56:38,809:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,809:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,889:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,890:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,893:INFO:Preparing preprocessing pipeline...
2023-06-11 21:56:38,898:INFO:Set up label encoding.
2023-06-11 21:56:38,898:INFO:Set up simple imputation.
2023-06-11 21:56:38,921:INFO:Set up encoding of categorical features.
2023-06-11 21:56:38,922:INFO:Set up removing outliers.
2023-06-11 21:56:38,922:INFO:Set up imbalanced handling.
2023-06-11 21:56:38,922:INFO:Set up feature selection.
2023-06-11 21:56:38,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:38,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:56:43,515:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 21:57:25,505:INFO:Finished creating preprocessing pipeline.
2023-06-11 21:57:25,545:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2023-06-11 21:57:25,546:INFO:Creating final display dataframe.
2023-06-11 21:57:26,563:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 21:58:06,730:INFO:Setup _display_container:                     Description             Value
0                    Session id              5999
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape       (96892, 22)
5        Transformed data shape        (94490, 5)
6   Transformed train set shape        (65422, 5)
7    Transformed test set shape        (29068, 5)
8              Numeric features                13
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               100
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20            Feature selection              True
21     Feature selection method           classic
22  Feature selection estimator          lightgbm
23  Number of features selected               0.2
24               Fold Generator   StratifiedKFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment      MlflowLogger
29              Experiment Name  clf-default-name
30                          USI              6e20
2023-06-11 21:58:06,887:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:58:06,887:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:58:06,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:58:06,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-11 21:58:06,969:INFO:Logging experiment in loggers
2023-06-11 21:58:07,812:INFO:SubProcess save_model() called ==================================
2023-06-11 21:58:07,902:INFO:Initializing save_model()
2023-06-11 21:58:07,902:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmpktfyjipa\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-11 21:58:07,903:INFO:Adding model into prep_pipe
2023-06-11 21:58:07,903:WARNING:Only Model saved as it was a pipeline.
2023-06-11 21:58:08,084:INFO:C:\Users\alniquia\AppData\Local\Temp\tmpktfyjipa\Transformation Pipeline.pkl saved in current working directory
2023-06-11 21:58:08,127:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2023-06-11 21:58:08,128:INFO:save_model() successfully completed......................................
2023-06-11 21:58:08,300:INFO:SubProcess save_model() end ==================================
2023-06-11 21:58:08,400:INFO:setup() successfully completed in 107.96s...............
2023-06-11 21:59:30,778:INFO:Initializing create_model()
2023-06-11 21:59:30,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC8970CEE0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-11 21:59:30,779:INFO:Checking exceptions
2023-06-11 21:59:30,811:INFO:Importing libraries
2023-06-11 21:59:30,811:INFO:Copying training dataset
2023-06-11 21:59:30,878:INFO:Defining folds
2023-06-11 21:59:30,878:INFO:Declaring metric variables
2023-06-11 21:59:30,889:INFO:Importing untrained model
2023-06-11 21:59:30,899:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-11 21:59:30,917:INFO:Starting cross validation
2023-06-11 21:59:31,026:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-11 21:59:48,829:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 21:59:49,073:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 21:59:49,091:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 22:00:40,313:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:00:40,822:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:00:40,880:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:00:40,920:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:00:41,742:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-11 22:00:41,756:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-11 22:01:48,678:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:01:49,267:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-11 22:01:50,491:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-11 22:01:50,693:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-11 22:01:51,636:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:01:52,519:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:01:53,823:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:01:54,694:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:01:54,896:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:02:37,524:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-11 22:02:38,150:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-11 22:02:39,004:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 22:02:39,087:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 22:02:39,131:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 22:02:39,481:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 22:03:28,208:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:03:28,430:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:03:28,718:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:03:29,446:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:03:29,528:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-11 22:03:30,340:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-11 22:04:47,389:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:04:50,705:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:05:25,440:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 22:05:25,922:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 22:07:27,263:INFO:Calculating mean and std
2023-06-11 22:07:27,266:INFO:Creating metrics dataframe
2023-06-11 22:07:27,278:INFO:Finalizing model
2023-06-11 22:07:56,699:INFO:Creating Dashboard logs
2023-06-11 22:07:56,706:INFO:Model: Light Gradient Boosting Machine
2023-06-11 22:07:56,835:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5999, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-11 22:07:57,121:INFO:Initializing predict_model()
2023-06-11 22:07:57,121:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC8970CEE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EC89A1DF30>)
2023-06-11 22:07:57,121:INFO:Checking exceptions
2023-06-11 22:07:57,121:INFO:Preloading libraries
2023-06-11 22:07:58,047:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-06-11 22:08:16,383:INFO:Uploading results into container
2023-06-11 22:08:16,386:INFO:Uploading model into container now
2023-06-11 22:08:16,417:INFO:_master_model_container: 1
2023-06-11 22:08:16,418:INFO:_display_container: 2
2023-06-11 22:08:16,419:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-11 22:08:16,419:INFO:create_model() successfully completed......................................
2023-06-11 22:08:16,635:INFO:Initializing tune_model()
2023-06-11 22:08:16,636:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC8970CEE0>)
2023-06-11 22:08:16,636:INFO:Checking exceptions
2023-06-11 22:08:16,709:INFO:Copying training dataset
2023-06-11 22:08:16,768:INFO:Checking base model
2023-06-11 22:08:16,769:INFO:Base model : Light Gradient Boosting Machine
2023-06-11 22:08:16,779:INFO:Declaring metric variables
2023-06-11 22:08:16,785:INFO:Defining Hyperparameters
2023-06-11 22:08:17,069:INFO:Tuning with n_jobs=-1
2023-06-11 22:08:17,069:INFO:Initializing RandomizedSearchCV
2023-06-11 22:08:27,900:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:08:29,845:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:08:30,500:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:08:35,837:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:08:35,858:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:08:35,972:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:08:39,380:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:08:39,604:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:08:39,665:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:09:12,947:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:09:19,558:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:09:23,226:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.45s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:09:24,173:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:09:24,715:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:09:24,988:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:09:30,839:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:09:31,320:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.14s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:09:31,732:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:09:34,840:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:09:35,199:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:09:35,579:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:10:10,050:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:10:15,081:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:10:15,552:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:10:18,213:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.03s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:10:20,658:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:10:23,814:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:10:25,457:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:11:48,870:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-11 22:12:14,095:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:12:39,641:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:28:33,517:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-11 22:39:54,476:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-11 22:47:53,392:INFO:best_params: {'actual_estimator__reg_lambda': 10, 'actual_estimator__reg_alpha': 1e-07, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 290, 'actual_estimator__min_split_gain': 0.3, 'actual_estimator__min_child_samples': 21, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 0, 'actual_estimator__bagging_fraction': 0.6}
2023-06-11 22:47:53,394:INFO:Hyperparameter search completed
2023-06-11 22:47:53,394:INFO:SubProcess create_model() called ==================================
2023-06-11 22:47:53,396:INFO:Initializing create_model()
2023-06-11 22:47:53,396:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC8970CEE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001EC8C624DC0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 10, 'reg_alpha': 1e-07, 'num_leaves': 30, 'n_estimators': 290, 'min_split_gain': 0.3, 'min_child_samples': 21, 'learning_rate': 0.001, 'feature_fraction': 0.4, 'bagging_freq': 0, 'bagging_fraction': 0.6})
2023-06-11 22:47:53,397:INFO:Checking exceptions
2023-06-11 22:47:53,398:INFO:Importing libraries
2023-06-11 22:47:53,398:INFO:Copying training dataset
2023-06-11 22:47:53,464:INFO:Defining folds
2023-06-11 22:47:53,464:INFO:Declaring metric variables
2023-06-11 22:47:53,471:INFO:Importing untrained model
2023-06-11 22:47:53,472:INFO:Declaring custom model
2023-06-11 22:47:53,479:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-11 22:47:53,494:INFO:Starting cross validation
2023-06-11 22:47:53,580:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-11 22:51:51,852:INFO:Calculating mean and std
2023-06-11 22:51:51,853:INFO:Creating metrics dataframe
2023-06-11 22:51:51,873:INFO:Finalizing model
2023-06-11 22:51:55,691:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-06-11 22:51:55,692:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-06-11 22:51:55,692:INFO:[LightGBM] [Warning] bagging_freq is set=0, subsample_freq=0 will be ignored. Current value: bagging_freq=0
2023-06-11 22:52:21,855:INFO:Uploading results into container
2023-06-11 22:52:21,856:INFO:Uploading model into container now
2023-06-11 22:52:21,858:INFO:_master_model_container: 2
2023-06-11 22:52:21,858:INFO:_display_container: 3
2023-06-11 22:52:21,859:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=290, n_jobs=-1, num_leaves=30, objective=None,
               random_state=5999, reg_alpha=1e-07, reg_lambda=10, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-11 22:52:21,860:INFO:create_model() successfully completed......................................
2023-06-11 22:52:22,046:INFO:SubProcess create_model() end ==================================
2023-06-11 22:52:22,047:INFO:choose_better activated
2023-06-11 22:52:22,052:INFO:SubProcess create_model() called ==================================
2023-06-11 22:52:22,053:INFO:Initializing create_model()
2023-06-11 22:52:22,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC8970CEE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-11 22:52:22,054:INFO:Checking exceptions
2023-06-11 22:52:22,058:INFO:Importing libraries
2023-06-11 22:52:22,058:INFO:Copying training dataset
2023-06-11 22:52:22,121:INFO:Defining folds
2023-06-11 22:52:22,121:INFO:Declaring metric variables
2023-06-11 22:52:22,121:INFO:Importing untrained model
2023-06-11 22:52:22,121:INFO:Declaring custom model
2023-06-11 22:52:22,122:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-11 22:52:22,122:INFO:Starting cross validation
2023-06-11 22:52:22,190:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-11 22:55:55,553:INFO:Calculating mean and std
2023-06-11 22:55:55,554:INFO:Creating metrics dataframe
2023-06-11 22:55:55,556:INFO:Finalizing model
2023-06-11 22:56:20,748:INFO:Uploading results into container
2023-06-11 22:56:20,762:INFO:Uploading model into container now
2023-06-11 22:56:20,762:INFO:_master_model_container: 3
2023-06-11 22:56:20,762:INFO:_display_container: 4
2023-06-11 22:56:20,763:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-11 22:56:20,763:INFO:create_model() successfully completed......................................
2023-06-11 22:56:20,879:INFO:SubProcess create_model() end ==================================
2023-06-11 22:56:20,880:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6235
2023-06-11 22:56:20,881:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=0, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=21, min_child_weight=0.001, min_split_gain=0.3,
               n_estimators=290, n_jobs=-1, num_leaves=30, objective=None,
               random_state=5999, reg_alpha=1e-07, reg_lambda=10, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6195
2023-06-11 22:56:20,881:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-06-11 22:56:20,881:INFO:choose_better completed
2023-06-11 22:56:20,881:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-11 22:56:20,882:INFO:Creating Dashboard logs
2023-06-11 22:56:20,889:INFO:Model: Light Gradient Boosting Machine
2023-06-11 22:56:25,310:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5999, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-11 22:56:26,827:INFO:Initializing predict_model()
2023-06-11 22:56:26,828:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC8970CEE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EC89A1F250>)
2023-06-11 22:56:26,828:INFO:Checking exceptions
2023-06-11 22:56:26,828:INFO:Preloading libraries
2023-06-11 22:56:51,988:INFO:_master_model_container: 3
2023-06-11 22:56:51,989:INFO:_display_container: 3
2023-06-11 22:56:51,989:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-11 22:56:51,990:INFO:tune_model() successfully completed......................................
2023-06-11 22:57:08,888:INFO:Initializing finalize_model()
2023-06-11 22:57:08,889:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC8970CEE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-11 22:57:08,890:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-11 22:57:08,909:INFO:Initializing create_model()
2023-06-11 22:57:08,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC8970CEE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-11 22:57:08,910:INFO:Checking exceptions
2023-06-11 22:57:08,913:INFO:Importing libraries
2023-06-11 22:57:08,913:INFO:Copying training dataset
2023-06-11 22:57:08,916:INFO:Defining folds
2023-06-11 22:57:08,916:INFO:Declaring metric variables
2023-06-11 22:57:08,917:INFO:Importing untrained model
2023-06-11 22:57:08,917:INFO:Declaring custom model
2023-06-11 22:57:08,919:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-11 22:57:08,995:INFO:Cross validation set to False
2023-06-11 22:57:08,995:INFO:Fitting Model
2023-06-11 22:57:14,917:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-11 22:58:30,794:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-11 22:58:30,794:INFO:create_model() successfully completed......................................
2023-06-11 22:58:30,943:INFO:Creating Dashboard logs
2023-06-11 22:58:30,944:INFO:Model: Light Gradient Boosting Machine
2023-06-11 22:58:41,034:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5999, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-11 22:58:42,428:INFO:_master_model_container: 3
2023-06-11 22:58:42,428:INFO:_display_container: 3
2023-06-11 22:58:42,451:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-11 22:58:42,451:INFO:finalize_model() successfully completed......................................
2023-06-11 22:59:02,163:INFO:Initializing save_model()
2023-06-11 22:59:02,163:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=bs_predictor, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-11 22:59:02,163:INFO:Adding model into prep_pipe
2023-06-11 22:59:02,163:WARNING:Only Model saved as it was a pipeline.
2023-06-11 22:59:02,409:INFO:bs_predictor.pkl saved in current working directory
2023-06-11 22:59:02,452:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-11 22:59:02,452:INFO:save_model() successfully completed......................................
2023-06-11 22:59:02,702:INFO:Initializing predict_model()
2023-06-11 22:59:02,703:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC8970CEE0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001EC89205A20>)
2023-06-11 22:59:02,703:INFO:Checking exceptions
2023-06-11 22:59:02,703:INFO:Preloading libraries
2023-06-11 22:59:02,707:INFO:Set up data.
2023-06-11 22:59:02,737:INFO:Set up index.
2023-06-12 09:27:56,854:INFO:PyCaret ClassificationExperiment
2023-06-12 09:27:56,855:INFO:Logging name: clf-default-name
2023-06-12 09:27:56,855:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 09:27:56,856:INFO:version 3.0.2
2023-06-12 09:27:56,856:INFO:Initializing setup()
2023-06-12 09:27:56,856:INFO:self.USI: 9de2
2023-06-12 09:27:56,857:INFO:self._variable_keys: {'X', 'fold_generator', 'is_multiclass', 'logging_param', 'fold_groups_param', 'exp_id', 'data', 'gpu_param', 'log_plots_param', 'idx', 'seed', 'memory', 'X_test', 'target_param', 'y_train', 'gpu_n_jobs_param', '_available_plots', '_ml_usecase', 'y_test', 'html_param', 'pipeline', 'exp_name_log', 'n_jobs_param', 'X_train', 'y', 'fix_imbalance', 'USI', 'fold_shuffle_param'}
2023-06-12 09:27:56,857:INFO:Checking environment
2023-06-12 09:27:56,857:INFO:python_version: 3.10.10
2023-06-12 09:27:56,857:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 09:27:56,857:INFO:machine: AMD64
2023-06-12 09:27:56,857:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 09:27:56,861:INFO:Memory: svmem(total=17034072064, available=7907196928, percent=53.6, used=9126875136, free=7907196928)
2023-06-12 09:27:56,861:INFO:Physical Core: 2
2023-06-12 09:27:56,861:INFO:Logical Core: 4
2023-06-12 09:27:56,861:INFO:Checking libraries
2023-06-12 09:27:56,861:INFO:System:
2023-06-12 09:27:56,861:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 09:27:56,861:INFO:executable: c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 09:27:56,861:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 09:27:56,861:INFO:PyCaret required dependencies:
2023-06-12 09:27:56,862:INFO:                 pip: 23.1.2
2023-06-12 09:27:56,862:INFO:          setuptools: 65.5.0
2023-06-12 09:27:56,862:INFO:             pycaret: 3.0.2
2023-06-12 09:27:56,862:INFO:             IPython: 8.14.0
2023-06-12 09:27:56,862:INFO:          ipywidgets: 8.0.6
2023-06-12 09:27:56,862:INFO:                tqdm: 4.65.0
2023-06-12 09:27:56,863:INFO:               numpy: 1.23.5
2023-06-12 09:27:56,863:INFO:              pandas: 1.5.3
2023-06-12 09:27:56,863:INFO:              jinja2: 3.1.2
2023-06-12 09:27:56,863:INFO:               scipy: 1.10.1
2023-06-12 09:27:56,863:INFO:              joblib: 1.2.0
2023-06-12 09:27:56,863:INFO:             sklearn: 1.2.2
2023-06-12 09:27:56,863:INFO:                pyod: 1.0.9
2023-06-12 09:27:56,863:INFO:            imblearn: 0.10.1
2023-06-12 09:27:56,863:INFO:   category_encoders: 2.6.1
2023-06-12 09:27:56,864:INFO:            lightgbm: 3.3.5
2023-06-12 09:27:56,864:INFO:               numba: 0.57.0
2023-06-12 09:27:56,864:INFO:            requests: 2.31.0
2023-06-12 09:27:56,864:INFO:          matplotlib: 3.7.1
2023-06-12 09:27:56,864:INFO:          scikitplot: 0.3.7
2023-06-12 09:27:56,864:INFO:         yellowbrick: 1.5
2023-06-12 09:27:56,864:INFO:              plotly: 5.15.0
2023-06-12 09:27:56,865:INFO:             kaleido: 0.2.1
2023-06-12 09:27:56,865:INFO:         statsmodels: 0.14.0
2023-06-12 09:27:56,865:INFO:              sktime: 0.17.0
2023-06-12 09:27:56,868:INFO:               tbats: 1.1.3
2023-06-12 09:27:56,868:INFO:            pmdarima: 2.0.3
2023-06-12 09:27:56,869:INFO:              psutil: 5.9.5
2023-06-12 09:27:56,869:INFO:PyCaret optional dependencies:
2023-06-12 09:27:56,869:INFO:                shap: Not installed
2023-06-12 09:27:56,870:INFO:           interpret: Not installed
2023-06-12 09:27:56,871:INFO:                umap: Not installed
2023-06-12 09:27:56,871:INFO:    pandas_profiling: Not installed
2023-06-12 09:27:56,871:INFO:  explainerdashboard: Not installed
2023-06-12 09:27:56,871:INFO:             autoviz: Not installed
2023-06-12 09:27:56,871:INFO:           fairlearn: Not installed
2023-06-12 09:27:56,872:INFO:             xgboost: Not installed
2023-06-12 09:27:56,872:INFO:            catboost: Not installed
2023-06-12 09:27:56,872:INFO:              kmodes: Not installed
2023-06-12 09:27:56,872:INFO:             mlxtend: Not installed
2023-06-12 09:27:56,873:INFO:       statsforecast: Not installed
2023-06-12 09:27:56,873:INFO:        tune_sklearn: Not installed
2023-06-12 09:27:56,873:INFO:                 ray: Not installed
2023-06-12 09:27:56,873:INFO:            hyperopt: Not installed
2023-06-12 09:27:56,874:INFO:              optuna: Not installed
2023-06-12 09:27:56,874:INFO:               skopt: Not installed
2023-06-12 09:27:56,874:INFO:              mlflow: 2.4.1
2023-06-12 09:27:56,874:INFO:              gradio: Not installed
2023-06-12 09:27:56,874:INFO:             fastapi: Not installed
2023-06-12 09:27:56,874:INFO:             uvicorn: Not installed
2023-06-12 09:27:56,874:INFO:              m2cgen: Not installed
2023-06-12 09:27:56,874:INFO:           evidently: Not installed
2023-06-12 09:27:56,875:INFO:               fugue: Not installed
2023-06-12 09:27:56,875:INFO:           streamlit: 1.23.1
2023-06-12 09:27:56,875:INFO:             prophet: Not installed
2023-06-12 09:27:56,875:INFO:None
2023-06-12 09:27:56,875:INFO:Set up data.
2023-06-12 09:27:56,920:INFO:Set up train/test split.
2023-06-12 09:27:56,995:INFO:Set up index.
2023-06-12 09:27:56,998:INFO:Set up folding strategy.
2023-06-12 09:27:56,998:INFO:Assigning column types.
2023-06-12 09:27:57,025:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 09:27:57,079:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 09:27:57,080:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:27:57,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,121:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,190:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 09:27:57,195:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:27:57,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,266:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 09:27:57,403:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:27:57,546:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,546:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,724:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:27:57,788:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,789:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 09:27:57,904:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,904:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,996:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:57,996:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:58,002:INFO:Preparing preprocessing pipeline...
2023-06-12 09:27:58,008:INFO:Set up label encoding.
2023-06-12 09:27:58,008:INFO:Set up simple imputation.
2023-06-12 09:27:58,037:INFO:Set up encoding of categorical features.
2023-06-12 09:27:58,038:INFO:Set up removing outliers.
2023-06-12 09:27:58,039:INFO:Set up imbalanced handling.
2023-06-12 09:27:58,040:INFO:Set up feature selection.
2023-06-12 09:27:58,170:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:27:58,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:28:03,289:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-12 09:28:57,802:INFO:Finished creating preprocessing pipeline.
2023-06-12 09:28:57,843:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2023-06-12 09:28:57,843:INFO:Creating final display dataframe.
2023-06-12 09:28:59,276:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-12 09:29:55,458:INFO:Setup _display_container:                     Description             Value
0                    Session id              6308
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape       (96892, 25)
5        Transformed data shape        (94668, 5)
6   Transformed train set shape        (65600, 5)
7    Transformed test set shape        (29068, 5)
8              Numeric features                16
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               100
15              Encoding method              None
16              Remove outliers              True
17           Outliers threshold              0.05
18                Fix imbalance              True
19         Fix imbalance method             SMOTE
20            Feature selection              True
21     Feature selection method           classic
22  Feature selection estimator          lightgbm
23  Number of features selected               0.2
24               Fold Generator   StratifiedKFold
25                  Fold Number                10
26                     CPU Jobs                -1
27                      Use GPU             False
28               Log Experiment      MlflowLogger
29              Experiment Name  clf-default-name
30                          USI              9de2
2023-06-12 09:29:55,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:29:55,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:29:55,715:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:29:55,716:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:29:55,716:INFO:Logging experiment in loggers
2023-06-12 09:29:55,916:INFO:SubProcess save_model() called ==================================
2023-06-12 09:29:55,977:INFO:Initializing save_model()
2023-06-12 09:29:55,978:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmpdrk257_v\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 09:29:55,978:INFO:Adding model into prep_pipe
2023-06-12 09:29:55,978:WARNING:Only Model saved as it was a pipeline.
2023-06-12 09:29:56,224:INFO:C:\Users\alniquia\AppData\Local\Temp\tmpdrk257_v\Transformation Pipeline.pkl saved in current working directory
2023-06-12 09:29:56,267:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                                         learning_rate=0.1,
                                                                                         max_depth=-1,
                                                                                         min_child_samples=20,
                                                                                         min_child_weight=0.001,
                                                                                         min_split_gain=0.0,
                                                                                         n_estimators=100,
                                                                                         n_jobs=-1,
                                                                                         num_leaves=31,
                                                                                         objective=None,
                                                                                         random_state=None,
                                                                                         reg_alpha=0.0,
                                                                                         reg_lambda=0.0,
                                                                                         silent='warn',
                                                                                         subsample=1.0,
                                                                                         subsample_for_bin=200000,
                                                                                         subsample_freq=0),
                                                                importance_getter='auto',
                                                                max_features=4,
                                                                norm_order=1,
                                                                prefit=False,
                                                                threshold=-inf)))],
         verbose=False)
2023-06-12 09:29:56,268:INFO:save_model() successfully completed......................................
2023-06-12 09:29:56,429:INFO:SubProcess save_model() end ==================================
2023-06-12 09:29:56,560:INFO:setup() successfully completed in 146.25s...............
2023-06-12 09:30:17,665:INFO:Initializing create_model()
2023-06-12 09:30:17,666:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001EC84E20FA0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 09:30:17,666:INFO:Checking exceptions
2023-06-12 09:30:17,691:INFO:Importing libraries
2023-06-12 09:30:17,692:INFO:Copying training dataset
2023-06-12 09:30:17,773:INFO:Defining folds
2023-06-12 09:30:17,774:INFO:Declaring metric variables
2023-06-12 09:30:17,784:INFO:Importing untrained model
2023-06-12 09:30:17,797:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 09:30:17,817:INFO:Starting cross validation
2023-06-12 09:30:18,011:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 09:31:00,179:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 09:31:00,192:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 09:31:00,202:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 09:31:00,279:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 09:31:02,833:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-12 09:31:02,833:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-12 09:31:02,838:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-12 09:31:02,864:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but IsolationForest was fitted with feature names
  warnings.warn(

2023-06-12 09:32:04,051:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 09:32:04,155:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 09:32:04,367:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 09:32:04,896:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 09:32:05,649:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 09:33:14,854:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 09:34:37,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 09:34:37,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 09:34:37,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 09:34:37,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 09:34:42,304:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-12 09:35:18,957:INFO:PyCaret ClassificationExperiment
2023-06-12 09:35:18,957:INFO:Logging name: clf-default-name
2023-06-12 09:35:18,957:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 09:35:18,957:INFO:version 3.0.2
2023-06-12 09:35:18,957:INFO:Initializing setup()
2023-06-12 09:35:18,957:INFO:self.USI: e806
2023-06-12 09:35:18,957:INFO:self._variable_keys: {'X_train', 'is_multiclass', '_available_plots', 'USI', 'memory', 'X_test', 'y', 'pipeline', 'fold_shuffle_param', 'idx', 'y_train', 'log_plots_param', '_ml_usecase', 'fold_generator', 'exp_name_log', 'exp_id', 'html_param', 'data', 'y_test', 'fold_groups_param', 'fix_imbalance', 'target_param', 'logging_param', 'gpu_n_jobs_param', 'n_jobs_param', 'seed', 'X', 'gpu_param'}
2023-06-12 09:35:18,957:INFO:Checking environment
2023-06-12 09:35:18,957:INFO:python_version: 3.10.10
2023-06-12 09:35:18,957:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 09:35:18,957:INFO:machine: AMD64
2023-06-12 09:35:18,957:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 09:35:18,960:INFO:Memory: svmem(total=17034072064, available=8023826432, percent=52.9, used=9010245632, free=8023826432)
2023-06-12 09:35:18,960:INFO:Physical Core: 2
2023-06-12 09:35:18,960:INFO:Logical Core: 4
2023-06-12 09:35:18,960:INFO:Checking libraries
2023-06-12 09:35:18,960:INFO:System:
2023-06-12 09:35:18,960:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 09:35:18,960:INFO:executable: c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 09:35:18,960:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 09:35:18,960:INFO:PyCaret required dependencies:
2023-06-12 09:35:18,960:INFO:                 pip: 23.1.2
2023-06-12 09:35:18,961:INFO:          setuptools: 65.5.0
2023-06-12 09:35:18,961:INFO:             pycaret: 3.0.2
2023-06-12 09:35:18,961:INFO:             IPython: 8.14.0
2023-06-12 09:35:18,961:INFO:          ipywidgets: 8.0.6
2023-06-12 09:35:18,961:INFO:                tqdm: 4.65.0
2023-06-12 09:35:18,961:INFO:               numpy: 1.23.5
2023-06-12 09:35:18,961:INFO:              pandas: 1.5.3
2023-06-12 09:35:18,961:INFO:              jinja2: 3.1.2
2023-06-12 09:35:18,961:INFO:               scipy: 1.10.1
2023-06-12 09:35:18,961:INFO:              joblib: 1.2.0
2023-06-12 09:35:18,962:INFO:             sklearn: 1.2.2
2023-06-12 09:35:18,962:INFO:                pyod: 1.0.9
2023-06-12 09:35:18,962:INFO:            imblearn: 0.10.1
2023-06-12 09:35:18,962:INFO:   category_encoders: 2.6.1
2023-06-12 09:35:18,962:INFO:            lightgbm: 3.3.5
2023-06-12 09:35:18,962:INFO:               numba: 0.57.0
2023-06-12 09:35:18,962:INFO:            requests: 2.31.0
2023-06-12 09:35:18,962:INFO:          matplotlib: 3.7.1
2023-06-12 09:35:18,962:INFO:          scikitplot: 0.3.7
2023-06-12 09:35:18,962:INFO:         yellowbrick: 1.5
2023-06-12 09:35:18,963:INFO:              plotly: 5.15.0
2023-06-12 09:35:18,963:INFO:             kaleido: 0.2.1
2023-06-12 09:35:18,963:INFO:         statsmodels: 0.14.0
2023-06-12 09:35:18,963:INFO:              sktime: 0.17.0
2023-06-12 09:35:18,963:INFO:               tbats: 1.1.3
2023-06-12 09:35:18,963:INFO:            pmdarima: 2.0.3
2023-06-12 09:35:18,963:INFO:              psutil: 5.9.5
2023-06-12 09:35:18,963:INFO:PyCaret optional dependencies:
2023-06-12 09:35:19,019:INFO:                shap: Not installed
2023-06-12 09:35:19,019:INFO:           interpret: Not installed
2023-06-12 09:35:19,019:INFO:                umap: Not installed
2023-06-12 09:35:19,019:INFO:    pandas_profiling: Not installed
2023-06-12 09:35:19,019:INFO:  explainerdashboard: Not installed
2023-06-12 09:35:19,020:INFO:             autoviz: Not installed
2023-06-12 09:35:19,020:INFO:           fairlearn: Not installed
2023-06-12 09:35:19,020:INFO:             xgboost: Not installed
2023-06-12 09:35:19,020:INFO:            catboost: Not installed
2023-06-12 09:35:19,020:INFO:              kmodes: Not installed
2023-06-12 09:35:19,020:INFO:             mlxtend: Not installed
2023-06-12 09:35:19,020:INFO:       statsforecast: Not installed
2023-06-12 09:35:19,020:INFO:        tune_sklearn: Not installed
2023-06-12 09:35:19,021:INFO:                 ray: Not installed
2023-06-12 09:35:19,021:INFO:            hyperopt: Not installed
2023-06-12 09:35:19,021:INFO:              optuna: Not installed
2023-06-12 09:35:19,021:INFO:               skopt: Not installed
2023-06-12 09:35:19,021:INFO:              mlflow: 2.4.1
2023-06-12 09:35:19,021:INFO:              gradio: Not installed
2023-06-12 09:35:19,021:INFO:             fastapi: Not installed
2023-06-12 09:35:19,021:INFO:             uvicorn: Not installed
2023-06-12 09:35:19,021:INFO:              m2cgen: Not installed
2023-06-12 09:35:19,021:INFO:           evidently: Not installed
2023-06-12 09:35:19,021:INFO:               fugue: Not installed
2023-06-12 09:35:19,021:INFO:           streamlit: 1.23.1
2023-06-12 09:35:19,021:INFO:             prophet: Not installed
2023-06-12 09:35:19,021:INFO:None
2023-06-12 09:35:19,022:INFO:Set up data.
2023-06-12 09:35:19,060:INFO:Set up train/test split.
2023-06-12 09:35:19,129:INFO:Set up index.
2023-06-12 09:35:19,132:INFO:Set up folding strategy.
2023-06-12 09:35:19,132:INFO:Assigning column types.
2023-06-12 09:35:19,157:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 09:35:19,208:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 09:35:19,222:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:35:19,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,416:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 09:35:19,417:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:35:19,450:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,453:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 09:35:19,505:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:35:19,539:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,590:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:35:19,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,623:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 09:35:19,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,710:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,796:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:19,800:INFO:Preparing preprocessing pipeline...
2023-06-12 09:35:19,807:INFO:Set up label encoding.
2023-06-12 09:35:19,807:INFO:Set up simple imputation.
2023-06-12 09:35:19,825:INFO:Set up encoding of categorical features.
2023-06-12 09:35:21,489:INFO:Finished creating preprocessing pipeline.
2023-06-12 09:35:21,499:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 09:35:21,499:INFO:Creating final display dataframe.
2023-06-12 09:35:26,211:INFO:Setup _display_container:                     Description             Value
0                    Session id              3366
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape       (96892, 25)
5        Transformed data shape      (96892, 468)
6   Transformed train set shape      (67824, 468)
7    Transformed test set shape      (29068, 468)
8              Numeric features                16
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               100
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              e806
2023-06-12 09:35:26,363:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:26,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:26,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:26,490:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:35:26,491:INFO:Logging experiment in loggers
2023-06-12 09:35:28,789:INFO:SubProcess save_model() called ==================================
2023-06-12 09:35:28,805:INFO:Initializing save_model()
2023-06-12 09:35:28,805:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmpx3ldrp17\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 09:35:28,805:INFO:Adding model into prep_pipe
2023-06-12 09:35:28,806:WARNING:Only Model saved as it was a pipeline.
2023-06-12 09:35:28,833:INFO:C:\Users\alniquia\AppData\Local\Temp\tmpx3ldrp17\Transformation Pipeline.pkl saved in current working directory
2023-06-12 09:35:28,840:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 09:35:28,840:INFO:save_model() successfully completed......................................
2023-06-12 09:35:28,928:INFO:SubProcess save_model() end ==================================
2023-06-12 09:35:28,958:INFO:setup() successfully completed in 27.11s...............
2023-06-12 09:36:45,382:INFO:PyCaret ClassificationExperiment
2023-06-12 09:36:45,382:INFO:Logging name: clf-default-name
2023-06-12 09:36:45,382:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 09:36:45,382:INFO:version 3.0.2
2023-06-12 09:36:45,382:INFO:Initializing setup()
2023-06-12 09:36:45,382:INFO:self.USI: 9d66
2023-06-12 09:36:45,382:INFO:self._variable_keys: {'X_train', 'is_multiclass', '_available_plots', 'USI', 'memory', 'X_test', 'y', 'pipeline', 'fold_shuffle_param', 'idx', 'y_train', 'log_plots_param', '_ml_usecase', 'fold_generator', 'exp_name_log', 'exp_id', 'html_param', 'data', 'y_test', 'fold_groups_param', 'fix_imbalance', 'target_param', 'logging_param', 'gpu_n_jobs_param', 'n_jobs_param', 'seed', 'X', 'gpu_param'}
2023-06-12 09:36:45,382:INFO:Checking environment
2023-06-12 09:36:45,382:INFO:python_version: 3.10.10
2023-06-12 09:36:45,382:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 09:36:45,382:INFO:machine: AMD64
2023-06-12 09:36:45,382:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 09:36:45,385:INFO:Memory: svmem(total=17034072064, available=7893180416, percent=53.7, used=9140891648, free=7893180416)
2023-06-12 09:36:45,385:INFO:Physical Core: 2
2023-06-12 09:36:45,386:INFO:Logical Core: 4
2023-06-12 09:36:45,386:INFO:Checking libraries
2023-06-12 09:36:45,386:INFO:System:
2023-06-12 09:36:45,386:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 09:36:45,386:INFO:executable: c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 09:36:45,386:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 09:36:45,386:INFO:PyCaret required dependencies:
2023-06-12 09:36:45,386:INFO:                 pip: 23.1.2
2023-06-12 09:36:45,386:INFO:          setuptools: 65.5.0
2023-06-12 09:36:45,386:INFO:             pycaret: 3.0.2
2023-06-12 09:36:45,386:INFO:             IPython: 8.14.0
2023-06-12 09:36:45,386:INFO:          ipywidgets: 8.0.6
2023-06-12 09:36:45,386:INFO:                tqdm: 4.65.0
2023-06-12 09:36:45,386:INFO:               numpy: 1.23.5
2023-06-12 09:36:45,386:INFO:              pandas: 1.5.3
2023-06-12 09:36:45,386:INFO:              jinja2: 3.1.2
2023-06-12 09:36:45,387:INFO:               scipy: 1.10.1
2023-06-12 09:36:45,387:INFO:              joblib: 1.2.0
2023-06-12 09:36:45,387:INFO:             sklearn: 1.2.2
2023-06-12 09:36:45,387:INFO:                pyod: 1.0.9
2023-06-12 09:36:45,387:INFO:            imblearn: 0.10.1
2023-06-12 09:36:45,387:INFO:   category_encoders: 2.6.1
2023-06-12 09:36:45,387:INFO:            lightgbm: 3.3.5
2023-06-12 09:36:45,387:INFO:               numba: 0.57.0
2023-06-12 09:36:45,387:INFO:            requests: 2.31.0
2023-06-12 09:36:45,387:INFO:          matplotlib: 3.7.1
2023-06-12 09:36:45,387:INFO:          scikitplot: 0.3.7
2023-06-12 09:36:45,387:INFO:         yellowbrick: 1.5
2023-06-12 09:36:45,387:INFO:              plotly: 5.15.0
2023-06-12 09:36:45,387:INFO:             kaleido: 0.2.1
2023-06-12 09:36:45,387:INFO:         statsmodels: 0.14.0
2023-06-12 09:36:45,387:INFO:              sktime: 0.17.0
2023-06-12 09:36:45,387:INFO:               tbats: 1.1.3
2023-06-12 09:36:45,387:INFO:            pmdarima: 2.0.3
2023-06-12 09:36:45,387:INFO:              psutil: 5.9.5
2023-06-12 09:36:45,387:INFO:PyCaret optional dependencies:
2023-06-12 09:36:45,387:INFO:                shap: Not installed
2023-06-12 09:36:45,387:INFO:           interpret: Not installed
2023-06-12 09:36:45,388:INFO:                umap: Not installed
2023-06-12 09:36:45,388:INFO:    pandas_profiling: Not installed
2023-06-12 09:36:45,388:INFO:  explainerdashboard: Not installed
2023-06-12 09:36:45,388:INFO:             autoviz: Not installed
2023-06-12 09:36:45,388:INFO:           fairlearn: Not installed
2023-06-12 09:36:45,388:INFO:             xgboost: Not installed
2023-06-12 09:36:45,388:INFO:            catboost: Not installed
2023-06-12 09:36:45,388:INFO:              kmodes: Not installed
2023-06-12 09:36:45,388:INFO:             mlxtend: Not installed
2023-06-12 09:36:45,388:INFO:       statsforecast: Not installed
2023-06-12 09:36:45,388:INFO:        tune_sklearn: Not installed
2023-06-12 09:36:45,388:INFO:                 ray: Not installed
2023-06-12 09:36:45,388:INFO:            hyperopt: Not installed
2023-06-12 09:36:45,388:INFO:              optuna: Not installed
2023-06-12 09:36:45,389:INFO:               skopt: Not installed
2023-06-12 09:36:45,389:INFO:              mlflow: 2.4.1
2023-06-12 09:36:45,389:INFO:              gradio: Not installed
2023-06-12 09:36:45,389:INFO:             fastapi: Not installed
2023-06-12 09:36:45,389:INFO:             uvicorn: Not installed
2023-06-12 09:36:45,389:INFO:              m2cgen: Not installed
2023-06-12 09:36:45,389:INFO:           evidently: Not installed
2023-06-12 09:36:45,389:INFO:               fugue: Not installed
2023-06-12 09:36:45,389:INFO:           streamlit: 1.23.1
2023-06-12 09:36:45,389:INFO:             prophet: Not installed
2023-06-12 09:36:45,389:INFO:None
2023-06-12 09:36:45,394:INFO:Set up data.
2023-06-12 09:36:45,454:INFO:Set up train/test split.
2023-06-12 09:36:45,548:INFO:Set up index.
2023-06-12 09:36:45,551:INFO:Set up folding strategy.
2023-06-12 09:36:45,551:INFO:Assigning column types.
2023-06-12 09:36:45,585:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 09:36:45,686:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 09:36:45,687:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:36:45,751:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:45,751:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:45,832:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 09:36:45,833:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:36:45,869:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:45,870:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:45,870:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 09:36:45,929:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:36:45,967:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:45,967:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:46,028:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 09:36:46,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:46,068:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:46,068:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 09:36:46,166:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:46,166:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:46,264:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:46,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:46,265:INFO:Preparing preprocessing pipeline...
2023-06-12 09:36:46,269:INFO:Set up label encoding.
2023-06-12 09:36:46,269:INFO:Set up simple imputation.
2023-06-12 09:36:46,297:INFO:Set up encoding of categorical features.
2023-06-12 09:36:48,262:INFO:Finished creating preprocessing pipeline.
2023-06-12 09:36:48,270:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 09:36:48,270:INFO:Creating final display dataframe.
2023-06-12 09:36:54,414:INFO:Setup _display_container:                     Description             Value
0                    Session id               885
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape       (96892, 25)
5        Transformed data shape      (96892, 467)
6   Transformed train set shape      (67824, 467)
7    Transformed test set shape      (29068, 467)
8              Numeric features                16
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              9d66
2023-06-12 09:36:54,555:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:54,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:54,663:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:54,663:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 09:36:54,664:INFO:Logging experiment in loggers
2023-06-12 09:36:54,916:INFO:SubProcess save_model() called ==================================
2023-06-12 09:36:54,934:INFO:Initializing save_model()
2023-06-12 09:36:54,934:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmpema9ouf4\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 09:36:54,934:INFO:Adding model into prep_pipe
2023-06-12 09:36:54,934:WARNING:Only Model saved as it was a pipeline.
2023-06-12 09:36:54,956:INFO:C:\Users\alniquia\AppData\Local\Temp\tmpema9ouf4\Transformation Pipeline.pkl saved in current working directory
2023-06-12 09:36:54,967:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 09:36:54,967:INFO:save_model() successfully completed......................................
2023-06-12 09:36:55,116:INFO:SubProcess save_model() end ==================================
2023-06-12 09:36:55,183:INFO:setup() successfully completed in 32.44s...............
2023-06-12 09:37:35,612:INFO:Initializing create_model()
2023-06-12 09:37:35,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8541C5DE0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 09:37:35,612:INFO:Checking exceptions
2023-06-12 09:37:35,655:INFO:Importing libraries
2023-06-12 09:37:35,656:INFO:Copying training dataset
2023-06-12 09:37:35,777:INFO:Defining folds
2023-06-12 09:37:35,777:INFO:Declaring metric variables
2023-06-12 09:37:35,790:INFO:Importing untrained model
2023-06-12 09:37:35,801:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 09:37:35,855:INFO:Starting cross validation
2023-06-12 09:37:35,861:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 09:39:12,745:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:39:12,811:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:39:12,878:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:39:13,413:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:40:10,309:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:40:11,098:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:42:42,590:INFO:Calculating mean and std
2023-06-12 09:42:42,592:INFO:Creating metrics dataframe
2023-06-12 09:42:42,599:INFO:Finalizing model
2023-06-12 09:43:09,611:INFO:Creating Dashboard logs
2023-06-12 09:43:09,616:INFO:Model: Light Gradient Boosting Machine
2023-06-12 09:43:09,731:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 885, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 09:43:09,981:INFO:Initializing predict_model()
2023-06-12 09:43:09,981:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8541C5DE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=885, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D86ABA48B0>)
2023-06-12 09:43:09,981:INFO:Checking exceptions
2023-06-12 09:43:09,981:INFO:Preloading libraries
2023-06-12 09:43:11,219:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-06-12 09:43:31,922:INFO:Uploading results into container
2023-06-12 09:43:31,923:INFO:Uploading model into container now
2023-06-12 09:43:31,939:INFO:_master_model_container: 1
2023-06-12 09:43:31,939:INFO:_display_container: 2
2023-06-12 09:43:31,939:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=885, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 09:43:31,939:INFO:create_model() successfully completed......................................
2023-06-12 09:43:43,096:INFO:Initializing tune_model()
2023-06-12 09:43:43,097:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=885, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8541C5DE0>)
2023-06-12 09:43:43,097:INFO:Checking exceptions
2023-06-12 09:43:43,171:INFO:Copying training dataset
2023-06-12 09:43:43,229:INFO:Checking base model
2023-06-12 09:43:43,229:INFO:Base model : Light Gradient Boosting Machine
2023-06-12 09:43:43,237:INFO:Declaring metric variables
2023-06-12 09:43:43,247:INFO:Defining Hyperparameters
2023-06-12 09:43:43,405:INFO:Tuning with n_jobs=-1
2023-06-12 09:43:43,406:INFO:Initializing RandomizedSearchCV
2023-06-12 09:44:47,819:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:44:48,062:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:44:48,103:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:44:48,111:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:45:47,840:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 09:45:55,698:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:45:56,629:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:46:43,067:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:47:21,286:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:47:22,730:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 09:47:57,611:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:47:59,083:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 09:48:50,107:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:49:19,211:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 09:50:07,332:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:50:47,831:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:51:54,082:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:56:49,322:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.80s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:56:50,555:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 09:57:21,293:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.01s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:57:22,648:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 09:57:51,224:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:57:53,037:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 09:58:23,427:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:58:25,459:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 09:58:53,838:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:58:55,777:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 09:59:46,930:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 09:59:50,823:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:00:42,054:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:00:45,766:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:01:39,950:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:01:43,075:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.47s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:02:36,276:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:02:38,329:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:03:10,114:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:03:11,980:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:03:34,820:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:03:36,216:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:04:01,672:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:04:04,160:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:04:27,805:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:04:30,127:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.09s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:04:55,733:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:04:57,083:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:05:21,570:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:05:22,776:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:05:51,434:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:05:53,109:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:06:19,318:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:06:20,899:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:06:45,753:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.91s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:06:47,999:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:07:12,020:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.17s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:07:13,888:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:07:41,349:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:08:23,092:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:09:00,247:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:12:06,911:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:12:07,906:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:12:41,543:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:15:32,526:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:21:35,520:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:22:14,826:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:22:16,577:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:22:50,509:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.11s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:22:52,106:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:23:21,325:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:23:24,326:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:23:53,328:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:23:55,992:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:24:29,937:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 2.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:24:33,356:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.46s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:25:00,881:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:25:03,793:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:25:32,142:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.43s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:25:34,836:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:26:00,686:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:26:04,106:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:26:30,790:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:26:34,063:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:27:05,182:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:27:08,076:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.42s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:27:30,789:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:27:32,383:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:27:54,721:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:27:56,533:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:28:17,659:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:28:19,531:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.00s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:28:40,812:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:28:42,468:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:29:05,574:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:29:08,211:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:29:31,891:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.99s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:29:33,881:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:29:58,682:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:30:01,103:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:30:25,454:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:30:27,273:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.89s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:30:56,525:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:30:59,393:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:31:28,087:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 10:31:30,486:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.22s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:34:25,552:INFO:best_params: {'actual_estimator__reg_lambda': 0.001, 'actual_estimator__reg_alpha': 0.4, 'actual_estimator__num_leaves': 8, 'actual_estimator__n_estimators': 200, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 91, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2023-06-12 10:34:25,556:INFO:Hyperparameter search completed
2023-06-12 10:34:25,556:INFO:SubProcess create_model() called ==================================
2023-06-12 10:34:25,558:INFO:Initializing create_model()
2023-06-12 10:34:25,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8541C5DE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=885, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001D8682C9990>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.001, 'reg_alpha': 0.4, 'num_leaves': 8, 'n_estimators': 200, 'min_split_gain': 0.7, 'min_child_samples': 91, 'learning_rate': 0.1, 'feature_fraction': 0.6, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2023-06-12 10:34:25,558:INFO:Checking exceptions
2023-06-12 10:34:25,558:INFO:Importing libraries
2023-06-12 10:34:25,558:INFO:Copying training dataset
2023-06-12 10:34:25,624:INFO:Defining folds
2023-06-12 10:34:25,625:INFO:Declaring metric variables
2023-06-12 10:34:25,633:INFO:Importing untrained model
2023-06-12 10:34:25,633:INFO:Declaring custom model
2023-06-12 10:34:25,641:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 10:34:25,652:INFO:Starting cross validation
2023-06-12 10:34:25,657:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 10:35:28,405:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 10:37:37,886:INFO:Calculating mean and std
2023-06-12 10:37:37,890:INFO:Creating metrics dataframe
2023-06-12 10:37:37,903:INFO:Finalizing model
2023-06-12 10:37:39,712:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2023-06-12 10:37:39,712:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-06-12 10:37:39,713:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-06-12 10:38:08,621:INFO:Uploading results into container
2023-06-12 10:38:08,621:INFO:Uploading model into container now
2023-06-12 10:38:08,621:INFO:_master_model_container: 2
2023-06-12 10:38:08,621:INFO:_display_container: 3
2023-06-12 10:38:08,621:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=200, n_jobs=-1, num_leaves=8, objective=None,
               random_state=885, reg_alpha=0.4, reg_lambda=0.001, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 10:38:08,621:INFO:create_model() successfully completed......................................
2023-06-12 10:38:08,706:INFO:SubProcess create_model() end ==================================
2023-06-12 10:38:08,706:INFO:choose_better activated
2023-06-12 10:38:08,710:INFO:SubProcess create_model() called ==================================
2023-06-12 10:38:08,711:INFO:Initializing create_model()
2023-06-12 10:38:08,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8541C5DE0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=885, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 10:38:08,711:INFO:Checking exceptions
2023-06-12 10:38:08,713:INFO:Importing libraries
2023-06-12 10:38:08,713:INFO:Copying training dataset
2023-06-12 10:38:08,751:INFO:Defining folds
2023-06-12 10:38:08,751:INFO:Declaring metric variables
2023-06-12 10:38:08,751:INFO:Importing untrained model
2023-06-12 10:38:08,751:INFO:Declaring custom model
2023-06-12 10:38:08,752:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 10:38:08,752:INFO:Starting cross validation
2023-06-12 10:38:08,755:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 10:41:05,860:INFO:Calculating mean and std
2023-06-12 10:41:05,861:INFO:Creating metrics dataframe
2023-06-12 10:41:05,864:INFO:Finalizing model
2023-06-12 10:41:25,809:INFO:Uploading results into container
2023-06-12 10:41:25,809:INFO:Uploading model into container now
2023-06-12 10:41:25,819:INFO:_master_model_container: 3
2023-06-12 10:41:25,819:INFO:_display_container: 4
2023-06-12 10:41:25,819:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=885, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 10:41:25,819:INFO:create_model() successfully completed......................................
2023-06-12 10:41:25,899:INFO:SubProcess create_model() end ==================================
2023-06-12 10:41:25,899:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=885, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.7059
2023-06-12 10:41:25,899:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=200, n_jobs=-1, num_leaves=8, objective=None,
               random_state=885, reg_alpha=0.4, reg_lambda=0.001, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.7077
2023-06-12 10:41:25,899:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=200, n_jobs=-1, num_leaves=8, objective=None,
               random_state=885, reg_alpha=0.4, reg_lambda=0.001, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-06-12 10:41:25,899:INFO:choose_better completed
2023-06-12 10:41:25,899:INFO:Creating Dashboard logs
2023-06-12 10:41:25,904:INFO:Model: Light Gradient Boosting Machine
2023-06-12 10:41:25,990:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 91, 'min_child_weight': 0.001, 'min_split_gain': 0.7, 'n_estimators': 200, 'n_jobs': -1, 'num_leaves': 8, 'objective': None, 'random_state': 885, 'reg_alpha': 0.4, 'reg_lambda': 0.001, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.6, 'bagging_freq': 2, 'bagging_fraction': 0.6}
2023-06-12 10:41:26,249:INFO:Initializing predict_model()
2023-06-12 10:41:26,249:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8541C5DE0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=200, n_jobs=-1, num_leaves=8, objective=None,
               random_state=885, reg_alpha=0.4, reg_lambda=0.001, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D86ABA5090>)
2023-06-12 10:41:26,249:INFO:Checking exceptions
2023-06-12 10:41:26,249:INFO:Preloading libraries
2023-06-12 10:41:42,726:INFO:_master_model_container: 3
2023-06-12 10:41:42,726:INFO:_display_container: 3
2023-06-12 10:41:42,726:INFO:LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=200, n_jobs=-1, num_leaves=8, objective=None,
               random_state=885, reg_alpha=0.4, reg_lambda=0.001, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 10:41:42,726:INFO:tune_model() successfully completed......................................
2023-06-12 10:41:58,059:INFO:Initializing finalize_model()
2023-06-12 10:41:58,060:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8541C5DE0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=200, n_jobs=-1, num_leaves=8, objective=None,
               random_state=885, reg_alpha=0.4, reg_lambda=0.001, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-12 10:41:58,063:INFO:Finalizing LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=200, n_jobs=-1, num_leaves=8, objective=None,
               random_state=885, reg_alpha=0.4, reg_lambda=0.001, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 10:41:58,094:INFO:Initializing create_model()
2023-06-12 10:41:58,094:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8541C5DE0>, estimator=LGBMClassifier(bagging_fraction=0.6, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=91, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=200, n_jobs=-1, num_leaves=8, objective=None,
               random_state=885, reg_alpha=0.4, reg_lambda=0.001, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-12 10:41:58,094:INFO:Checking exceptions
2023-06-12 10:41:58,097:INFO:Importing libraries
2023-06-12 10:41:58,097:INFO:Copying training dataset
2023-06-12 10:41:58,100:INFO:Defining folds
2023-06-12 10:41:58,100:INFO:Declaring metric variables
2023-06-12 10:41:58,101:INFO:Importing untrained model
2023-06-12 10:41:58,101:INFO:Declaring custom model
2023-06-12 10:41:58,102:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 10:41:58,105:INFO:Cross validation set to False
2023-06-12 10:41:58,105:INFO:Fitting Model
2023-06-12 10:42:02,597:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2023-06-12 10:42:02,597:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2023-06-12 10:42:02,597:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-06-12 10:42:04,505:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=200, n_jobs=-1, num_leaves=8,
                                objective=None, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 10:42:04,505:INFO:create_model() successfully completed......................................
2023-06-12 10:42:04,595:INFO:Creating Dashboard logs
2023-06-12 10:42:04,595:INFO:Model: Light Gradient Boosting Machine
2023-06-12 10:42:04,715:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 91, 'min_child_weight': 0.001, 'min_split_gain': 0.7, 'n_estimators': 200, 'n_jobs': -1, 'num_leaves': 8, 'objective': None, 'random_state': 885, 'reg_alpha': 0.4, 'reg_lambda': 0.001, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.6, 'bagging_freq': 2, 'bagging_fraction': 0.6}
2023-06-12 10:42:05,116:INFO:_master_model_container: 3
2023-06-12 10:42:05,116:INFO:_display_container: 3
2023-06-12 10:42:05,137:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=200, n_jobs=-1, num_leaves=8,
                                objective=None, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 10:42:05,137:INFO:finalize_model() successfully completed......................................
2023-06-12 10:42:05,268:INFO:Initializing save_model()
2023-06-12 10:42:05,268:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=200, n_jobs=-1, num_leaves=8,
                                objective=None, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=bs_predictor, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 10:42:05,268:INFO:Adding model into prep_pipe
2023-06-12 10:42:05,268:WARNING:Only Model saved as it was a pipeline.
2023-06-12 10:42:05,304:INFO:bs_predictor.pkl saved in current working directory
2023-06-12 10:42:05,322:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=200, n_jobs=-1, num_leaves=8,
                                objective=None, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 10:42:05,322:INFO:save_model() successfully completed......................................
2023-06-12 10:42:05,492:INFO:Initializing predict_model()
2023-06-12 10:42:05,493:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D8541C5DE0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_di...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=91,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=200, n_jobs=-1, num_leaves=8,
                                objective=None, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D800137B50>)
2023-06-12 10:42:05,493:INFO:Checking exceptions
2023-06-12 10:42:05,493:INFO:Preloading libraries
2023-06-12 10:42:05,496:INFO:Set up data.
2023-06-12 10:42:05,528:INFO:Set up index.
2023-06-12 12:35:39,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 12:35:39,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 12:35:39,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 12:35:39,466:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 12:35:43,936:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-12 12:37:14,336:INFO:Initializing load_model()
2023-06-12 12:37:14,337:INFO:load_model(model_name=models/bs_predictor, platform=None, authentication=None, verbose=True)
2023-06-12 12:37:15,125:INFO:Initializing predict_model()
2023-06-12 12:37:15,125:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0047D0F0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['barriers', 'barriers_center',
                                             'bushes', 'bushes_center',
                                             'waterProp',
                                             'avg_brawler_Range_Num_diff',
                                             'avg_brawler_trophies_diff',
                                             'avg_brawler_...
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=4813))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('feature_selection',
                 TransformerWrapper(exclude=[],
                                    transformer=SelectFromModel(estimator=LGBMClassifier(),
                                                                max_features=13,
                                                                threshold=-inf))),
                ('actual_estimator', LGBMClassifier(random_state=4813))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F00291630>)
2023-06-12 12:37:15,125:INFO:Checking exceptions
2023-06-12 12:37:15,125:INFO:Preloading libraries
2023-06-12 12:37:53,454:INFO:Initializing predict_model()
2023-06-12 12:37:53,455:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F002DCC70>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['barriers', 'barriers_center',
                                             'bushes', 'bushes_center',
                                             'waterProp',
                                             'avg_brawler_Range_Num_diff',
                                             'avg_brawler_trophies_diff',
                                             'avg_brawler_...
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=4813))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('feature_selection',
                 TransformerWrapper(exclude=[],
                                    transformer=SelectFromModel(estimator=LGBMClassifier(),
                                                                max_features=13,
                                                                threshold=-inf))),
                ('actual_estimator', LGBMClassifier(random_state=4813))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F002912D0>)
2023-06-12 12:37:53,455:INFO:Checking exceptions
2023-06-12 12:37:53,455:INFO:Preloading libraries
2023-06-12 12:37:53,456:INFO:Set up data.
2023-06-12 12:37:53,482:INFO:Set up index.
2023-06-12 12:38:24,177:INFO:Initializing predict_model()
2023-06-12 12:38:24,177:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00413E20>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['barriers', 'barriers_center',
                                             'bushes', 'bushes_center',
                                             'waterProp',
                                             'avg_brawler_Range_Num_diff',
                                             'avg_brawler_trophies_diff',
                                             'avg_brawler_...
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=4813))),
                ('balance',
                 TransformerWrapper(transformer=FixImbalancer(estimator=SMOTE()))),
                ('feature_selection',
                 TransformerWrapper(exclude=[],
                                    transformer=SelectFromModel(estimator=LGBMClassifier(),
                                                                max_features=13,
                                                                threshold=-inf))),
                ('actual_estimator', LGBMClassifier(random_state=4813))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F7FE17EB0>)
2023-06-12 12:38:24,177:INFO:Checking exceptions
2023-06-12 12:38:24,177:INFO:Preloading libraries
2023-06-12 12:38:24,178:INFO:Set up data.
2023-06-12 12:38:24,199:INFO:Set up index.
2023-06-12 12:38:40,025:INFO:Initializing load_model()
2023-06-12 12:38:40,025:INFO:load_model(model_name=models/bs_predictor, platform=None, authentication=None, verbose=True)
2023-06-12 12:38:40,110:INFO:Initializing predict_model()
2023-06-12 12:38:40,110:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00413BE0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F004F60E0>)
2023-06-12 12:38:40,110:INFO:Checking exceptions
2023-06-12 12:38:40,111:INFO:Preloading libraries
2023-06-12 12:38:40,111:INFO:Set up data.
2023-06-12 12:38:40,143:INFO:Set up index.
2023-06-12 12:41:05,545:INFO:Initializing predict_model()
2023-06-12 12:41:05,545:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0517FE20>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F047AF640>)
2023-06-12 12:41:05,546:INFO:Checking exceptions
2023-06-12 12:41:05,546:INFO:Preloading libraries
2023-06-12 12:41:05,547:INFO:Set up data.
2023-06-12 12:41:05,573:INFO:Set up index.
2023-06-12 12:41:19,881:INFO:Initializing predict_model()
2023-06-12 12:41:19,881:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F7FEB1B10>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F047AE320>)
2023-06-12 12:41:19,881:INFO:Checking exceptions
2023-06-12 12:41:19,881:INFO:Preloading libraries
2023-06-12 12:41:19,882:INFO:Set up data.
2023-06-12 12:41:19,899:INFO:Set up index.
2023-06-12 12:41:40,942:INFO:Initializing predict_model()
2023-06-12 12:41:40,942:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0044AE00>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F047AE710>)
2023-06-12 12:41:40,942:INFO:Checking exceptions
2023-06-12 12:41:40,942:INFO:Preloading libraries
2023-06-12 12:41:40,957:INFO:Set up data.
2023-06-12 12:41:40,988:INFO:Set up index.
2023-06-12 12:41:51,775:INFO:Initializing predict_model()
2023-06-12 12:41:51,775:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F004130D0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F002903A0>)
2023-06-12 12:41:51,775:INFO:Checking exceptions
2023-06-12 12:41:51,775:INFO:Preloading libraries
2023-06-12 12:41:51,775:INFO:Set up data.
2023-06-12 12:41:51,840:INFO:Set up index.
2023-06-12 12:44:10,907:INFO:Initializing predict_model()
2023-06-12 12:44:10,907:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F002DEDD0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F047AF880>)
2023-06-12 12:44:10,909:INFO:Checking exceptions
2023-06-12 12:44:10,910:INFO:Preloading libraries
2023-06-12 12:44:10,910:INFO:Set up data.
2023-06-12 12:44:10,940:INFO:Set up index.
2023-06-12 12:44:24,576:INFO:Initializing predict_model()
2023-06-12 12:44:24,577:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F7FEB27D0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F002920E0>)
2023-06-12 12:44:24,577:INFO:Checking exceptions
2023-06-12 12:44:24,577:INFO:Preloading libraries
2023-06-12 12:44:24,578:INFO:Set up data.
2023-06-12 12:44:24,600:INFO:Set up index.
2023-06-12 12:44:34,940:INFO:Initializing predict_model()
2023-06-12 12:44:34,940:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F7FE43670>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F002920E0>)
2023-06-12 12:44:34,940:INFO:Checking exceptions
2023-06-12 12:44:34,940:INFO:Preloading libraries
2023-06-12 12:44:34,940:INFO:Set up data.
2023-06-12 12:44:34,971:INFO:Set up index.
2023-06-12 12:44:43,979:INFO:Initializing predict_model()
2023-06-12 12:44:43,979:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00338130>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F002912D0>)
2023-06-12 12:44:43,979:INFO:Checking exceptions
2023-06-12 12:44:43,979:INFO:Preloading libraries
2023-06-12 12:44:43,979:INFO:Set up data.
2023-06-12 12:44:44,001:INFO:Set up index.
2023-06-12 12:44:49,078:INFO:Initializing predict_model()
2023-06-12 12:44:49,089:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F002D80D0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F71ABBB50>)
2023-06-12 12:44:49,089:INFO:Checking exceptions
2023-06-12 12:44:49,089:INFO:Preloading libraries
2023-06-12 12:44:49,089:INFO:Set up data.
2023-06-12 12:44:49,115:INFO:Set up index.
2023-06-12 12:44:58,953:INFO:Initializing predict_model()
2023-06-12 12:44:58,953:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00339900>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F00292290>)
2023-06-12 12:44:58,953:INFO:Checking exceptions
2023-06-12 12:44:58,953:INFO:Preloading libraries
2023-06-12 12:44:58,954:INFO:Set up data.
2023-06-12 12:44:58,976:INFO:Set up index.
2023-06-12 12:46:07,475:INFO:Initializing predict_model()
2023-06-12 12:46:07,476:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00338AF0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F00291F30>)
2023-06-12 12:46:07,476:INFO:Checking exceptions
2023-06-12 12:46:07,476:INFO:Preloading libraries
2023-06-12 12:46:07,477:INFO:Set up data.
2023-06-12 12:46:07,505:INFO:Set up index.
2023-06-12 12:46:20,952:INFO:Initializing predict_model()
2023-06-12 12:46:20,953:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F002DED10>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F71B1C550>)
2023-06-12 12:46:20,953:INFO:Checking exceptions
2023-06-12 12:46:20,953:INFO:Preloading libraries
2023-06-12 12:46:20,955:INFO:Set up data.
2023-06-12 12:46:20,984:INFO:Set up index.
2023-06-12 12:48:47,013:INFO:Initializing predict_model()
2023-06-12 12:48:47,013:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F004499F0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F00291D80>)
2023-06-12 12:48:47,014:INFO:Checking exceptions
2023-06-12 12:48:47,014:INFO:Preloading libraries
2023-06-12 12:48:47,015:INFO:Set up data.
2023-06-12 12:48:47,034:INFO:Set up index.
2023-06-12 12:52:43,786:INFO:Initializing predict_model()
2023-06-12 12:52:43,786:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F002DFDF0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F002903A0>)
2023-06-12 12:52:43,786:INFO:Checking exceptions
2023-06-12 12:52:43,787:INFO:Preloading libraries
2023-06-12 12:52:43,787:INFO:Set up data.
2023-06-12 12:52:43,863:INFO:Set up index.
2023-06-12 12:53:06,015:INFO:Initializing predict_model()
2023-06-12 12:53:06,016:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F002DD750>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04880F70>)
2023-06-12 12:53:06,016:INFO:Checking exceptions
2023-06-12 12:53:06,016:INFO:Preloading libraries
2023-06-12 12:53:06,018:INFO:Set up data.
2023-06-12 12:53:06,040:INFO:Set up index.
2023-06-12 12:53:40,765:INFO:Initializing predict_model()
2023-06-12 12:53:40,767:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F7FEB3220>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04881900>)
2023-06-12 12:53:40,767:INFO:Checking exceptions
2023-06-12 12:53:40,767:INFO:Preloading libraries
2023-06-12 12:53:40,767:INFO:Set up data.
2023-06-12 12:53:40,794:INFO:Set up index.
2023-06-12 12:54:49,535:INFO:Initializing predict_model()
2023-06-12 12:54:49,536:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F71AB2650>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F048812D0>)
2023-06-12 12:54:49,537:INFO:Checking exceptions
2023-06-12 12:54:49,537:INFO:Preloading libraries
2023-06-12 12:54:49,538:INFO:Set up data.
2023-06-12 12:54:49,572:INFO:Set up index.
2023-06-12 12:56:37,843:INFO:Initializing predict_model()
2023-06-12 12:56:37,848:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F004127D0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04881BD0>)
2023-06-12 12:56:37,848:INFO:Checking exceptions
2023-06-12 12:56:37,849:INFO:Preloading libraries
2023-06-12 12:56:37,849:INFO:Set up data.
2023-06-12 12:56:37,869:INFO:Set up index.
2023-06-12 12:58:05,860:INFO:Initializing predict_model()
2023-06-12 12:58:05,862:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F71AB2170>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F047AEA70>)
2023-06-12 12:58:05,862:INFO:Checking exceptions
2023-06-12 12:58:05,862:INFO:Preloading libraries
2023-06-12 12:58:05,863:INFO:Set up data.
2023-06-12 12:58:05,906:INFO:Set up index.
2023-06-12 12:58:56,457:INFO:Initializing predict_model()
2023-06-12 12:58:56,457:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0047C2B0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F00291B40>)
2023-06-12 12:58:56,457:INFO:Checking exceptions
2023-06-12 12:58:56,457:INFO:Preloading libraries
2023-06-12 12:58:56,458:INFO:Set up data.
2023-06-12 12:58:56,475:INFO:Set up index.
2023-06-12 12:59:38,740:INFO:Initializing predict_model()
2023-06-12 12:59:38,740:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0517ED10>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F048830A0>)
2023-06-12 12:59:38,740:INFO:Checking exceptions
2023-06-12 12:59:38,741:INFO:Preloading libraries
2023-06-12 12:59:38,741:INFO:Set up data.
2023-06-12 12:59:38,760:INFO:Set up index.
2023-06-12 13:00:54,493:INFO:Initializing predict_model()
2023-06-12 13:00:54,493:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0044AC50>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04883250>)
2023-06-12 13:00:54,493:INFO:Checking exceptions
2023-06-12 13:00:54,493:INFO:Preloading libraries
2023-06-12 13:00:54,493:INFO:Set up data.
2023-06-12 13:00:54,522:INFO:Set up index.
2023-06-12 13:01:06,350:INFO:Initializing predict_model()
2023-06-12 13:01:06,351:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0517E200>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04883D00>)
2023-06-12 13:01:06,352:INFO:Checking exceptions
2023-06-12 13:01:06,352:INFO:Preloading libraries
2023-06-12 13:01:06,353:INFO:Set up data.
2023-06-12 13:01:06,370:INFO:Set up index.
2023-06-12 13:01:22,882:INFO:Initializing predict_model()
2023-06-12 13:01:22,882:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F003CD210>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04882170>)
2023-06-12 13:01:22,882:INFO:Checking exceptions
2023-06-12 13:01:22,882:INFO:Preloading libraries
2023-06-12 13:01:22,882:INFO:Set up data.
2023-06-12 13:01:22,901:INFO:Set up index.
2023-06-12 13:01:31,907:INFO:Initializing predict_model()
2023-06-12 13:01:31,908:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0033B6A0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04881870>)
2023-06-12 13:01:31,908:INFO:Checking exceptions
2023-06-12 13:01:31,908:INFO:Preloading libraries
2023-06-12 13:01:31,909:INFO:Set up data.
2023-06-12 13:01:31,925:INFO:Set up index.
2023-06-12 13:01:38,311:INFO:Initializing predict_model()
2023-06-12 13:01:38,311:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0044B490>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04883B50>)
2023-06-12 13:01:38,311:INFO:Checking exceptions
2023-06-12 13:01:38,311:INFO:Preloading libraries
2023-06-12 13:01:38,312:INFO:Set up data.
2023-06-12 13:01:38,328:INFO:Set up index.
2023-06-12 13:01:42,973:INFO:Initializing predict_model()
2023-06-12 13:01:42,974:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0033B970>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04882F80>)
2023-06-12 13:01:42,974:INFO:Checking exceptions
2023-06-12 13:01:42,974:INFO:Preloading libraries
2023-06-12 13:01:42,974:INFO:Set up data.
2023-06-12 13:01:42,988:INFO:Set up index.
2023-06-12 13:01:52,819:INFO:Initializing predict_model()
2023-06-12 13:01:52,820:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0517FC10>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'avg_highestTrophies_diff',
                                             'avg_trophies_diff',
                                             'avg_team_victories_diff',
                                             'avg_expPoints_diff',
                                             'max_brawler_t...
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.6, bagging_freq=2,
                                feature_fraction=0.6, min_child_samples=91,
                                min_split_gain=0.7, n_estimators=200,
                                num_leaves=8, random_state=885, reg_alpha=0.4,
                                reg_lambda=0.001))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F048830A0>)
2023-06-12 13:01:52,820:INFO:Checking exceptions
2023-06-12 13:01:52,820:INFO:Preloading libraries
2023-06-12 13:01:52,821:INFO:Set up data.
2023-06-12 13:01:52,843:INFO:Set up index.
2023-06-12 13:06:46,985:INFO:PyCaret ClassificationExperiment
2023-06-12 13:06:46,985:INFO:Logging name: clf-default-name
2023-06-12 13:06:46,985:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 13:06:46,985:INFO:version 3.0.2
2023-06-12 13:06:46,985:INFO:Initializing setup()
2023-06-12 13:06:46,986:INFO:self.USI: 654c
2023-06-12 13:06:46,986:INFO:self._variable_keys: {'X_train', 'is_multiclass', '_available_plots', 'USI', 'memory', 'X_test', 'y', 'pipeline', 'fold_shuffle_param', 'idx', 'y_train', 'log_plots_param', '_ml_usecase', 'fold_generator', 'exp_name_log', 'exp_id', 'html_param', 'data', 'y_test', 'fold_groups_param', 'fix_imbalance', 'target_param', 'logging_param', 'gpu_n_jobs_param', 'n_jobs_param', 'seed', 'X', 'gpu_param'}
2023-06-12 13:06:46,986:INFO:Checking environment
2023-06-12 13:06:46,986:INFO:python_version: 3.10.10
2023-06-12 13:06:46,986:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 13:06:46,986:INFO:machine: AMD64
2023-06-12 13:06:46,986:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 13:06:46,989:INFO:Memory: svmem(total=17034072064, available=7429492736, percent=56.4, used=9604579328, free=7429492736)
2023-06-12 13:06:46,990:INFO:Physical Core: 2
2023-06-12 13:06:46,990:INFO:Logical Core: 4
2023-06-12 13:06:46,990:INFO:Checking libraries
2023-06-12 13:06:46,990:INFO:System:
2023-06-12 13:06:46,990:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 13:06:46,990:INFO:executable: c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 13:06:46,990:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 13:06:46,990:INFO:PyCaret required dependencies:
2023-06-12 13:06:46,990:INFO:                 pip: 23.1.2
2023-06-12 13:06:46,990:INFO:          setuptools: 65.5.0
2023-06-12 13:06:46,990:INFO:             pycaret: 3.0.2
2023-06-12 13:06:46,990:INFO:             IPython: 8.14.0
2023-06-12 13:06:46,990:INFO:          ipywidgets: 8.0.6
2023-06-12 13:06:46,990:INFO:                tqdm: 4.65.0
2023-06-12 13:06:46,991:INFO:               numpy: 1.23.5
2023-06-12 13:06:46,991:INFO:              pandas: 1.5.3
2023-06-12 13:06:46,991:INFO:              jinja2: 3.1.2
2023-06-12 13:06:46,991:INFO:               scipy: 1.10.1
2023-06-12 13:06:46,991:INFO:              joblib: 1.2.0
2023-06-12 13:06:46,991:INFO:             sklearn: 1.2.2
2023-06-12 13:06:46,991:INFO:                pyod: 1.0.9
2023-06-12 13:06:46,991:INFO:            imblearn: 0.10.1
2023-06-12 13:06:46,991:INFO:   category_encoders: 2.6.1
2023-06-12 13:06:46,991:INFO:            lightgbm: 3.3.5
2023-06-12 13:06:46,991:INFO:               numba: 0.57.0
2023-06-12 13:06:46,991:INFO:            requests: 2.31.0
2023-06-12 13:06:46,991:INFO:          matplotlib: 3.7.1
2023-06-12 13:06:46,991:INFO:          scikitplot: 0.3.7
2023-06-12 13:06:46,991:INFO:         yellowbrick: 1.5
2023-06-12 13:06:46,991:INFO:              plotly: 5.15.0
2023-06-12 13:06:46,991:INFO:             kaleido: 0.2.1
2023-06-12 13:06:46,991:INFO:         statsmodels: 0.14.0
2023-06-12 13:06:46,991:INFO:              sktime: 0.17.0
2023-06-12 13:06:46,991:INFO:               tbats: 1.1.3
2023-06-12 13:06:46,991:INFO:            pmdarima: 2.0.3
2023-06-12 13:06:46,991:INFO:              psutil: 5.9.5
2023-06-12 13:06:46,991:INFO:PyCaret optional dependencies:
2023-06-12 13:06:46,992:INFO:                shap: Not installed
2023-06-12 13:06:46,992:INFO:           interpret: Not installed
2023-06-12 13:06:46,992:INFO:                umap: Not installed
2023-06-12 13:06:46,992:INFO:    pandas_profiling: Not installed
2023-06-12 13:06:46,992:INFO:  explainerdashboard: Not installed
2023-06-12 13:06:46,992:INFO:             autoviz: Not installed
2023-06-12 13:06:46,992:INFO:           fairlearn: Not installed
2023-06-12 13:06:46,992:INFO:             xgboost: Not installed
2023-06-12 13:06:46,992:INFO:            catboost: Not installed
2023-06-12 13:06:46,992:INFO:              kmodes: Not installed
2023-06-12 13:06:46,992:INFO:             mlxtend: Not installed
2023-06-12 13:06:46,992:INFO:       statsforecast: Not installed
2023-06-12 13:06:46,992:INFO:        tune_sklearn: Not installed
2023-06-12 13:06:46,992:INFO:                 ray: Not installed
2023-06-12 13:06:46,992:INFO:            hyperopt: Not installed
2023-06-12 13:06:46,992:INFO:              optuna: Not installed
2023-06-12 13:06:46,992:INFO:               skopt: Not installed
2023-06-12 13:06:46,992:INFO:              mlflow: 2.4.1
2023-06-12 13:06:46,992:INFO:              gradio: Not installed
2023-06-12 13:06:46,992:INFO:             fastapi: Not installed
2023-06-12 13:06:46,993:INFO:             uvicorn: Not installed
2023-06-12 13:06:46,993:INFO:              m2cgen: Not installed
2023-06-12 13:06:46,993:INFO:           evidently: Not installed
2023-06-12 13:06:46,993:INFO:               fugue: Not installed
2023-06-12 13:06:46,993:INFO:           streamlit: 1.23.1
2023-06-12 13:06:46,993:INFO:             prophet: Not installed
2023-06-12 13:06:46,993:INFO:None
2023-06-12 13:06:46,993:INFO:Set up data.
2023-06-12 13:06:47,007:INFO:Set up train/test split.
2023-06-12 13:06:47,050:INFO:Set up index.
2023-06-12 13:06:47,052:INFO:Set up folding strategy.
2023-06-12 13:06:47,053:INFO:Assigning column types.
2023-06-12 13:06:47,063:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 13:06:47,110:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 13:06:47,112:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 13:06:47,141:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,141:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,188:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 13:06:47,190:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 13:06:47,216:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,217:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,217:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 13:06:47,264:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 13:06:47,295:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,295:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,345:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 13:06:47,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,374:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 13:06:47,454:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,531:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,531:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:47,533:INFO:Preparing preprocessing pipeline...
2023-06-12 13:06:47,536:INFO:Set up label encoding.
2023-06-12 13:06:47,536:INFO:Set up simple imputation.
2023-06-12 13:06:47,550:INFO:Set up encoding of categorical features.
2023-06-12 13:06:49,253:INFO:Finished creating preprocessing pipeline.
2023-06-12 13:06:49,262:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 13:06:49,262:INFO:Creating final display dataframe.
2023-06-12 13:06:53,012:INFO:Setup _display_container:                     Description             Value
0                    Session id              7261
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape       (96892, 13)
5        Transformed data shape      (96892, 454)
6   Transformed train set shape      (67824, 454)
7    Transformed test set shape      (29068, 454)
8              Numeric features                 4
9          Categorical features                 8
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              654c
2023-06-12 13:06:53,163:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:53,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:53,259:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:53,259:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:06:53,261:INFO:Logging experiment in loggers
2023-06-12 13:06:53,882:INFO:SubProcess save_model() called ==================================
2023-06-12 13:06:53,897:INFO:Initializing save_model()
2023-06-12 13:06:53,898:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmp8ffs2lfh\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 13:06:53,898:INFO:Adding model into prep_pipe
2023-06-12 13:06:53,898:WARNING:Only Model saved as it was a pipeline.
2023-06-12 13:06:53,911:INFO:C:\Users\alniquia\AppData\Local\Temp\tmp8ffs2lfh\Transformation Pipeline.pkl saved in current working directory
2023-06-12 13:06:53,917:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 13:06:53,917:INFO:save_model() successfully completed......................................
2023-06-12 13:06:54,229:INFO:SubProcess save_model() end ==================================
2023-06-12 13:06:54,249:INFO:setup() successfully completed in 23.38s...............
2023-06-12 13:07:10,514:INFO:Initializing create_model()
2023-06-12 13:07:10,514:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D86AB63A00>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 13:07:10,514:INFO:Checking exceptions
2023-06-12 13:07:10,546:INFO:Importing libraries
2023-06-12 13:07:10,546:INFO:Copying training dataset
2023-06-12 13:07:10,595:INFO:Defining folds
2023-06-12 13:07:10,595:INFO:Declaring metric variables
2023-06-12 13:07:10,602:INFO:Importing untrained model
2023-06-12 13:07:10,607:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 13:07:10,622:INFO:Starting cross validation
2023-06-12 13:07:10,626:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 13:08:21,962:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:08:21,993:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:08:22,438:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:08:22,485:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:08:59,654:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 13:09:10,312:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:09:11,508:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:09:44,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 13:09:44,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 13:09:44,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 13:09:44,942:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 13:09:46,375:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-12 13:10:09,155:INFO:PyCaret ClassificationExperiment
2023-06-12 13:10:09,155:INFO:Logging name: clf-default-name
2023-06-12 13:10:09,155:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 13:10:09,155:INFO:version 3.0.2
2023-06-12 13:10:09,156:INFO:Initializing setup()
2023-06-12 13:10:09,156:INFO:self.USI: b30b
2023-06-12 13:10:09,156:INFO:self._variable_keys: {'html_param', 'seed', 'gpu_n_jobs_param', 'X_train', 'exp_id', 'fix_imbalance', 'is_multiclass', 'USI', 'y_train', 'fold_shuffle_param', 'logging_param', 'gpu_param', 'y', 'fold_groups_param', 'target_param', 'X', 'idx', 'exp_name_log', '_available_plots', 'fold_generator', 'log_plots_param', 'pipeline', 'n_jobs_param', 'memory', 'X_test', '_ml_usecase', 'data', 'y_test'}
2023-06-12 13:10:09,156:INFO:Checking environment
2023-06-12 13:10:09,156:INFO:python_version: 3.10.10
2023-06-12 13:10:09,156:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 13:10:09,156:INFO:machine: AMD64
2023-06-12 13:10:09,156:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 13:10:09,160:INFO:Memory: svmem(total=17034072064, available=7098417152, percent=58.3, used=9935654912, free=7098417152)
2023-06-12 13:10:09,160:INFO:Physical Core: 2
2023-06-12 13:10:09,160:INFO:Logical Core: 4
2023-06-12 13:10:09,160:INFO:Checking libraries
2023-06-12 13:10:09,160:INFO:System:
2023-06-12 13:10:09,160:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 13:10:09,160:INFO:executable: c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 13:10:09,160:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 13:10:09,160:INFO:PyCaret required dependencies:
2023-06-12 13:10:09,160:INFO:                 pip: 23.1.2
2023-06-12 13:10:09,161:INFO:          setuptools: 65.5.0
2023-06-12 13:10:09,161:INFO:             pycaret: 3.0.2
2023-06-12 13:10:09,161:INFO:             IPython: 8.14.0
2023-06-12 13:10:09,161:INFO:          ipywidgets: 8.0.6
2023-06-12 13:10:09,161:INFO:                tqdm: 4.65.0
2023-06-12 13:10:09,161:INFO:               numpy: 1.23.5
2023-06-12 13:10:09,161:INFO:              pandas: 1.5.3
2023-06-12 13:10:09,161:INFO:              jinja2: 3.1.2
2023-06-12 13:10:09,161:INFO:               scipy: 1.10.1
2023-06-12 13:10:09,161:INFO:              joblib: 1.2.0
2023-06-12 13:10:09,161:INFO:             sklearn: 1.2.2
2023-06-12 13:10:09,161:INFO:                pyod: 1.0.9
2023-06-12 13:10:09,161:INFO:            imblearn: 0.10.1
2023-06-12 13:10:09,161:INFO:   category_encoders: 2.6.1
2023-06-12 13:10:09,161:INFO:            lightgbm: 3.3.5
2023-06-12 13:10:09,161:INFO:               numba: 0.57.0
2023-06-12 13:10:09,161:INFO:            requests: 2.31.0
2023-06-12 13:10:09,161:INFO:          matplotlib: 3.7.1
2023-06-12 13:10:09,161:INFO:          scikitplot: 0.3.7
2023-06-12 13:10:09,161:INFO:         yellowbrick: 1.5
2023-06-12 13:10:09,161:INFO:              plotly: 5.15.0
2023-06-12 13:10:09,162:INFO:             kaleido: 0.2.1
2023-06-12 13:10:09,162:INFO:         statsmodels: 0.14.0
2023-06-12 13:10:09,162:INFO:              sktime: 0.17.0
2023-06-12 13:10:09,162:INFO:               tbats: 1.1.3
2023-06-12 13:10:09,162:INFO:            pmdarima: 2.0.3
2023-06-12 13:10:09,162:INFO:              psutil: 5.9.5
2023-06-12 13:10:09,162:INFO:PyCaret optional dependencies:
2023-06-12 13:10:09,314:INFO:                shap: Not installed
2023-06-12 13:10:09,314:INFO:           interpret: Not installed
2023-06-12 13:10:09,314:INFO:                umap: Not installed
2023-06-12 13:10:09,314:INFO:    pandas_profiling: Not installed
2023-06-12 13:10:09,314:INFO:  explainerdashboard: Not installed
2023-06-12 13:10:09,326:INFO:             autoviz: Not installed
2023-06-12 13:10:09,326:INFO:           fairlearn: Not installed
2023-06-12 13:10:09,326:INFO:             xgboost: Not installed
2023-06-12 13:10:09,327:INFO:            catboost: Not installed
2023-06-12 13:10:09,327:INFO:              kmodes: Not installed
2023-06-12 13:10:09,327:INFO:             mlxtend: Not installed
2023-06-12 13:10:09,327:INFO:       statsforecast: Not installed
2023-06-12 13:10:09,327:INFO:        tune_sklearn: Not installed
2023-06-12 13:10:09,327:INFO:                 ray: Not installed
2023-06-12 13:10:09,327:INFO:            hyperopt: Not installed
2023-06-12 13:10:09,327:INFO:              optuna: Not installed
2023-06-12 13:10:09,328:INFO:               skopt: Not installed
2023-06-12 13:10:09,328:INFO:              mlflow: 2.4.1
2023-06-12 13:10:09,328:INFO:              gradio: Not installed
2023-06-12 13:10:09,328:INFO:             fastapi: Not installed
2023-06-12 13:10:09,328:INFO:             uvicorn: Not installed
2023-06-12 13:10:09,328:INFO:              m2cgen: Not installed
2023-06-12 13:10:09,328:INFO:           evidently: Not installed
2023-06-12 13:10:09,328:INFO:               fugue: Not installed
2023-06-12 13:10:09,328:INFO:           streamlit: 1.23.1
2023-06-12 13:10:09,328:INFO:             prophet: Not installed
2023-06-12 13:10:09,328:INFO:None
2023-06-12 13:10:09,328:INFO:Set up data.
2023-06-12 13:10:09,358:INFO:Set up train/test split.
2023-06-12 13:10:09,427:INFO:Set up index.
2023-06-12 13:10:09,429:INFO:Set up folding strategy.
2023-06-12 13:10:09,429:INFO:Assigning column types.
2023-06-12 13:10:09,441:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 13:10:09,560:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 13:10:09,577:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 13:10:09,686:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:09,735:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:09,783:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 13:10:09,784:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 13:10:09,811:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:09,812:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:09,812:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 13:10:09,859:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 13:10:09,890:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:09,890:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:09,939:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 13:10:09,969:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:09,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:09,970:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 13:10:10,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:10,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:10,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:10,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:10,160:INFO:Preparing preprocessing pipeline...
2023-06-12 13:10:10,163:INFO:Set up label encoding.
2023-06-12 13:10:10,163:INFO:Set up simple imputation.
2023-06-12 13:10:10,186:INFO:Set up encoding of categorical features.
2023-06-12 13:10:11,574:INFO:Finished creating preprocessing pipeline.
2023-06-12 13:10:11,580:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 13:10:11,580:INFO:Creating final display dataframe.
2023-06-12 13:10:14,255:INFO:Setup _display_container:                     Description             Value
0                    Session id              6999
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape       (62905, 12)
5        Transformed data shape      (62905, 418)
6   Transformed train set shape      (44033, 418)
7    Transformed test set shape      (18872, 418)
8              Numeric features                 4
9          Categorical features                 7
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              b30b
2023-06-12 13:10:14,352:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:14,352:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:14,428:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:14,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 13:10:14,429:INFO:Logging experiment in loggers
2023-06-12 13:10:15,099:INFO:SubProcess save_model() called ==================================
2023-06-12 13:10:15,128:INFO:Initializing save_model()
2023-06-12 13:10:15,128:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmp1kz_58q0\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 13:10:15,128:INFO:Adding model into prep_pipe
2023-06-12 13:10:15,128:WARNING:Only Model saved as it was a pipeline.
2023-06-12 13:10:15,144:INFO:C:\Users\alniquia\AppData\Local\Temp\tmp1kz_58q0\Transformation Pipeline.pkl saved in current working directory
2023-06-12 13:10:15,155:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 13:10:15,155:INFO:save_model() successfully completed......................................
2023-06-12 13:10:15,252:INFO:SubProcess save_model() end ==================================
2023-06-12 13:10:15,284:INFO:setup() successfully completed in 24.9s...............
2023-06-12 13:10:15,393:INFO:Initializing create_model()
2023-06-12 13:10:15,393:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016217B6FB80>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 13:10:15,393:INFO:Checking exceptions
2023-06-12 13:10:15,451:INFO:Importing libraries
2023-06-12 13:10:15,452:INFO:Copying training dataset
2023-06-12 13:10:15,473:INFO:Defining folds
2023-06-12 13:10:15,473:INFO:Declaring metric variables
2023-06-12 13:10:15,477:INFO:Importing untrained model
2023-06-12 13:10:15,483:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 13:10:15,493:INFO:Starting cross validation
2023-06-12 13:10:15,496:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 13:10:34,718:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:10:34,760:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:10:34,776:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:10:34,793:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:11:14,693:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:12:05,616:INFO:Initializing load_model()
2023-06-12 13:12:05,617:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-12 13:12:53,139:INFO:Initializing load_model()
2023-06-12 13:12:53,139:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-12 13:14:05,172:INFO:Calculating mean and std
2023-06-12 13:14:05,174:INFO:Creating metrics dataframe
2023-06-12 13:14:05,184:INFO:Finalizing model
2023-06-12 13:14:26,838:INFO:Creating Dashboard logs
2023-06-12 13:14:26,844:INFO:Model: Light Gradient Boosting Machine
2023-06-12 13:14:26,938:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6999, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 13:14:27,147:INFO:Initializing predict_model()
2023-06-12 13:14:27,147:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016217B6FB80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000162328DA200>)
2023-06-12 13:14:27,147:INFO:Checking exceptions
2023-06-12 13:14:27,147:INFO:Preloading libraries
2023-06-12 13:14:27,970:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-06-12 13:14:44,767:INFO:Uploading results into container
2023-06-12 13:14:44,768:INFO:Uploading model into container now
2023-06-12 13:14:44,780:INFO:_master_model_container: 1
2023-06-12 13:14:44,780:INFO:_display_container: 2
2023-06-12 13:14:44,781:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 13:14:44,781:INFO:create_model() successfully completed......................................
2023-06-12 13:14:44,966:INFO:Initializing tune_model()
2023-06-12 13:14:44,966:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016217B6FB80>)
2023-06-12 13:14:44,966:INFO:Checking exceptions
2023-06-12 13:14:45,013:INFO:Copying training dataset
2023-06-12 13:14:45,035:INFO:Checking base model
2023-06-12 13:14:45,035:INFO:Base model : Light Gradient Boosting Machine
2023-06-12 13:14:45,044:INFO:Declaring metric variables
2023-06-12 13:14:45,054:INFO:Defining Hyperparameters
2023-06-12 13:14:45,210:INFO:Tuning with n_jobs=-1
2023-06-12 13:14:45,210:INFO:Initializing RandomizedSearchCV
2023-06-12 13:19:41,140:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:19:43,727:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:20:04,550:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:20:07,765:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:20:26,193:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:20:29,987:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:20:47,712:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.35s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:20:51,686:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:21:13,996:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.29s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:21:17,627:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:21:29,970:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:21:33,625:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.28s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:21:53,559:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.34s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:21:56,984:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.04s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:22:12,146:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.38s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:22:15,701:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:22:33,772:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.39s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:22:37,486:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:22:53,609:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.37s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:22:57,170:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.15s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 13:27:17,879:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 13:45:33,421:INFO:best_params: {'actual_estimator__reg_lambda': 0.0005, 'actual_estimator__reg_alpha': 0.3, 'actual_estimator__num_leaves': 30, 'actual_estimator__n_estimators': 150, 'actual_estimator__min_split_gain': 0.2, 'actual_estimator__min_child_samples': 31, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.8, 'actual_estimator__bagging_freq': 5, 'actual_estimator__bagging_fraction': 0.5}
2023-06-12 13:45:33,422:INFO:Hyperparameter search completed
2023-06-12 13:45:33,423:INFO:SubProcess create_model() called ==================================
2023-06-12 13:45:33,423:INFO:Initializing create_model()
2023-06-12 13:45:33,424:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016217B6FB80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622DA62230>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.0005, 'reg_alpha': 0.3, 'num_leaves': 30, 'n_estimators': 150, 'min_split_gain': 0.2, 'min_child_samples': 31, 'learning_rate': 0.1, 'feature_fraction': 0.8, 'bagging_freq': 5, 'bagging_fraction': 0.5})
2023-06-12 13:45:33,424:INFO:Checking exceptions
2023-06-12 13:45:33,424:INFO:Importing libraries
2023-06-12 13:45:33,424:INFO:Copying training dataset
2023-06-12 13:45:33,440:INFO:Defining folds
2023-06-12 13:45:33,441:INFO:Declaring metric variables
2023-06-12 13:45:33,445:INFO:Importing untrained model
2023-06-12 13:45:33,445:INFO:Declaring custom model
2023-06-12 13:45:33,450:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 13:45:33,458:INFO:Starting cross validation
2023-06-12 13:45:33,461:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 13:48:21,762:INFO:Calculating mean and std
2023-06-12 13:48:21,764:INFO:Creating metrics dataframe
2023-06-12 13:48:21,772:INFO:Finalizing model
2023-06-12 13:48:22,376:INFO:[LightGBM] [Warning] feature_fraction is set=0.8, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8
2023-06-12 13:48:22,376:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2023-06-12 13:48:22,376:INFO:[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5
2023-06-12 13:48:40,380:INFO:Uploading results into container
2023-06-12 13:48:40,382:INFO:Uploading model into container now
2023-06-12 13:48:40,382:INFO:_master_model_container: 2
2023-06-12 13:48:40,383:INFO:_display_container: 3
2023-06-12 13:48:40,383:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=150, n_jobs=-1, num_leaves=30, objective=None,
               random_state=6999, reg_alpha=0.3, reg_lambda=0.0005,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-06-12 13:48:40,384:INFO:create_model() successfully completed......................................
2023-06-12 13:48:40,487:INFO:SubProcess create_model() end ==================================
2023-06-12 13:48:40,487:INFO:choose_better activated
2023-06-12 13:48:40,492:INFO:SubProcess create_model() called ==================================
2023-06-12 13:48:40,493:INFO:Initializing create_model()
2023-06-12 13:48:40,493:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016217B6FB80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 13:48:40,493:INFO:Checking exceptions
2023-06-12 13:48:40,496:INFO:Importing libraries
2023-06-12 13:48:40,497:INFO:Copying training dataset
2023-06-12 13:48:40,524:INFO:Defining folds
2023-06-12 13:48:40,524:INFO:Declaring metric variables
2023-06-12 13:48:40,524:INFO:Importing untrained model
2023-06-12 13:48:40,524:INFO:Declaring custom model
2023-06-12 13:48:40,525:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 13:48:40,525:INFO:Starting cross validation
2023-06-12 13:48:40,527:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 13:51:32,093:INFO:Calculating mean and std
2023-06-12 13:51:32,094:INFO:Creating metrics dataframe
2023-06-12 13:51:32,096:INFO:Finalizing model
2023-06-12 13:51:51,081:INFO:Uploading results into container
2023-06-12 13:51:51,082:INFO:Uploading model into container now
2023-06-12 13:51:51,082:INFO:_master_model_container: 3
2023-06-12 13:51:51,082:INFO:_display_container: 4
2023-06-12 13:51:51,083:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 13:51:51,083:INFO:create_model() successfully completed......................................
2023-06-12 13:51:51,173:INFO:SubProcess create_model() end ==================================
2023-06-12 13:51:51,174:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.686
2023-06-12 13:51:51,175:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=5, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.8,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=31, min_child_weight=0.001, min_split_gain=0.2,
               n_estimators=150, n_jobs=-1, num_leaves=30, objective=None,
               random_state=6999, reg_alpha=0.3, reg_lambda=0.0005,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) result for F1 is 0.6855
2023-06-12 13:51:51,175:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-06-12 13:51:51,175:INFO:choose_better completed
2023-06-12 13:51:51,176:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-12 13:51:51,176:INFO:Creating Dashboard logs
2023-06-12 13:51:51,183:INFO:Model: Light Gradient Boosting Machine
2023-06-12 13:51:51,284:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6999, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 13:51:51,521:INFO:Initializing predict_model()
2023-06-12 13:51:51,521:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016217B6FB80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000162328D9E10>)
2023-06-12 13:51:51,522:INFO:Checking exceptions
2023-06-12 13:51:51,522:INFO:Preloading libraries
2023-06-12 13:52:07,196:INFO:_master_model_container: 3
2023-06-12 13:52:07,197:INFO:_display_container: 3
2023-06-12 13:52:07,197:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 13:52:07,197:INFO:tune_model() successfully completed......................................
2023-06-12 13:52:22,228:INFO:Initializing finalize_model()
2023-06-12 13:52:22,228:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016217B6FB80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-12 13:52:22,229:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 13:52:22,237:INFO:Initializing create_model()
2023-06-12 13:52:22,237:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016217B6FB80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6999, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-12 13:52:22,238:INFO:Checking exceptions
2023-06-12 13:52:22,240:INFO:Importing libraries
2023-06-12 13:52:22,240:INFO:Copying training dataset
2023-06-12 13:52:22,241:INFO:Defining folds
2023-06-12 13:52:22,241:INFO:Declaring metric variables
2023-06-12 13:52:22,241:INFO:Importing untrained model
2023-06-12 13:52:22,241:INFO:Declaring custom model
2023-06-12 13:52:22,242:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 13:52:22,245:INFO:Cross validation set to False
2023-06-12 13:52:22,245:INFO:Fitting Model
2023-06-12 13:52:26,027:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 13:52:26,027:INFO:create_model() successfully completed......................................
2023-06-12 13:52:26,135:INFO:Creating Dashboard logs
2023-06-12 13:52:26,136:INFO:Model: Light Gradient Boosting Machine
2023-06-12 13:52:26,246:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6999, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 13:52:26,660:INFO:_master_model_container: 3
2023-06-12 13:52:26,661:INFO:_display_container: 3
2023-06-12 13:52:26,671:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 13:52:26,671:INFO:finalize_model() successfully completed......................................
2023-06-12 13:52:26,830:INFO:Initializing save_model()
2023-06-12 13:52:26,830:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=bs_predictor_brawlBall, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 13:52:26,830:INFO:Adding model into prep_pipe
2023-06-12 13:52:26,830:WARNING:Only Model saved as it was a pipeline.
2023-06-12 13:52:26,869:INFO:bs_predictor_brawlBall.pkl saved in current working directory
2023-06-12 13:52:26,887:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 13:52:26,888:INFO:save_model() successfully completed......................................
2023-06-12 13:52:27,055:INFO:Initializing predict_model()
2023-06-12 13:52:27,055:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000016217B6FB80>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001622A5A9E10>)
2023-06-12 13:52:27,055:INFO:Checking exceptions
2023-06-12 13:52:27,055:INFO:Preloading libraries
2023-06-12 13:52:27,059:INFO:Set up data.
2023-06-12 13:52:27,076:INFO:Set up index.
2023-06-12 14:07:21,286:INFO:Initializing load_model()
2023-06-12 14:07:21,287:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-12 14:07:23,438:INFO:Initializing load_model()
2023-06-12 14:07:23,438:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-12 14:07:44,031:INFO:Initializing save_model()
2023-06-12 14:07:44,032:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=models/bs_predictor_brawlBall, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 14:07:44,032:INFO:Adding model into prep_pipe
2023-06-12 14:07:44,032:WARNING:Only Model saved as it was a pipeline.
2023-06-12 14:07:44,089:INFO:models/bs_predictor_brawlBall.pkl saved in current working directory
2023-06-12 14:07:44,117:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6999, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 14:07:44,118:INFO:save_model() successfully completed......................................
2023-06-12 14:07:52,807:INFO:Initializing load_model()
2023-06-12 14:07:52,807:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-12 14:08:10,751:INFO:Initializing predict_model()
2023-06-12 14:08:10,751:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0044B280>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                    transformer=OneHotEncoder(cols=['event_map',
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator', LGBMClassifier(random_state=6999))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04883130>)
2023-06-12 14:08:10,751:INFO:Checking exceptions
2023-06-12 14:08:10,751:INFO:Preloading libraries
2023-06-12 14:08:10,752:INFO:Set up data.
2023-06-12 14:08:10,768:INFO:Set up index.
2023-06-12 14:08:35,311:INFO:Initializing predict_model()
2023-06-12 14:08:35,311:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0517F670>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                    transformer=OneHotEncoder(cols=['event_map',
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator', LGBMClassifier(random_state=6999))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F05188EE0>)
2023-06-12 14:08:35,312:INFO:Checking exceptions
2023-06-12 14:08:35,312:INFO:Preloading libraries
2023-06-12 14:08:35,312:INFO:Set up data.
2023-06-12 14:08:35,328:INFO:Set up index.
2023-06-12 14:27:33,967:INFO:PyCaret ClassificationExperiment
2023-06-12 14:27:33,967:INFO:Logging name: clf-default-name
2023-06-12 14:27:33,967:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 14:27:33,967:INFO:version 3.0.2
2023-06-12 14:27:33,967:INFO:Initializing setup()
2023-06-12 14:27:33,968:INFO:self.USI: 531e
2023-06-12 14:27:33,968:INFO:self._variable_keys: {'html_param', 'seed', 'gpu_n_jobs_param', 'X_train', 'exp_id', 'fix_imbalance', 'is_multiclass', 'USI', 'y_train', 'fold_shuffle_param', 'logging_param', 'gpu_param', 'y', 'fold_groups_param', 'target_param', 'X', 'idx', 'exp_name_log', '_available_plots', 'fold_generator', 'log_plots_param', 'pipeline', 'n_jobs_param', 'memory', 'X_test', '_ml_usecase', 'data', 'y_test'}
2023-06-12 14:27:33,968:INFO:Checking environment
2023-06-12 14:27:33,968:INFO:python_version: 3.10.10
2023-06-12 14:27:33,968:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 14:27:33,968:INFO:machine: AMD64
2023-06-12 14:27:33,968:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 14:27:33,972:INFO:Memory: svmem(total=17034072064, available=6915411968, percent=59.4, used=10118660096, free=6915411968)
2023-06-12 14:27:33,973:INFO:Physical Core: 2
2023-06-12 14:27:33,973:INFO:Logical Core: 4
2023-06-12 14:27:33,973:INFO:Checking libraries
2023-06-12 14:27:33,973:INFO:System:
2023-06-12 14:27:33,973:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 14:27:33,973:INFO:executable: c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 14:27:33,973:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 14:27:33,973:INFO:PyCaret required dependencies:
2023-06-12 14:27:33,974:INFO:                 pip: 23.1.2
2023-06-12 14:27:33,974:INFO:          setuptools: 65.5.0
2023-06-12 14:27:33,974:INFO:             pycaret: 3.0.2
2023-06-12 14:27:33,974:INFO:             IPython: 8.14.0
2023-06-12 14:27:33,974:INFO:          ipywidgets: 8.0.6
2023-06-12 14:27:33,974:INFO:                tqdm: 4.65.0
2023-06-12 14:27:33,974:INFO:               numpy: 1.23.5
2023-06-12 14:27:33,975:INFO:              pandas: 1.5.3
2023-06-12 14:27:33,975:INFO:              jinja2: 3.1.2
2023-06-12 14:27:33,975:INFO:               scipy: 1.10.1
2023-06-12 14:27:33,975:INFO:              joblib: 1.2.0
2023-06-12 14:27:33,975:INFO:             sklearn: 1.2.2
2023-06-12 14:27:33,975:INFO:                pyod: 1.0.9
2023-06-12 14:27:33,975:INFO:            imblearn: 0.10.1
2023-06-12 14:27:33,976:INFO:   category_encoders: 2.6.1
2023-06-12 14:27:33,976:INFO:            lightgbm: 3.3.5
2023-06-12 14:27:33,976:INFO:               numba: 0.57.0
2023-06-12 14:27:33,976:INFO:            requests: 2.31.0
2023-06-12 14:27:33,976:INFO:          matplotlib: 3.7.1
2023-06-12 14:27:33,976:INFO:          scikitplot: 0.3.7
2023-06-12 14:27:33,976:INFO:         yellowbrick: 1.5
2023-06-12 14:27:33,977:INFO:              plotly: 5.15.0
2023-06-12 14:27:33,977:INFO:             kaleido: 0.2.1
2023-06-12 14:27:33,977:INFO:         statsmodels: 0.14.0
2023-06-12 14:27:33,977:INFO:              sktime: 0.17.0
2023-06-12 14:27:33,977:INFO:               tbats: 1.1.3
2023-06-12 14:27:33,977:INFO:            pmdarima: 2.0.3
2023-06-12 14:27:33,977:INFO:              psutil: 5.9.5
2023-06-12 14:27:33,977:INFO:PyCaret optional dependencies:
2023-06-12 14:27:33,978:INFO:                shap: Not installed
2023-06-12 14:27:33,978:INFO:           interpret: Not installed
2023-06-12 14:27:33,978:INFO:                umap: Not installed
2023-06-12 14:27:33,978:INFO:    pandas_profiling: Not installed
2023-06-12 14:27:33,978:INFO:  explainerdashboard: Not installed
2023-06-12 14:27:33,978:INFO:             autoviz: Not installed
2023-06-12 14:27:33,978:INFO:           fairlearn: Not installed
2023-06-12 14:27:33,978:INFO:             xgboost: Not installed
2023-06-12 14:27:33,979:INFO:            catboost: Not installed
2023-06-12 14:27:33,979:INFO:              kmodes: Not installed
2023-06-12 14:27:33,979:INFO:             mlxtend: Not installed
2023-06-12 14:27:33,979:INFO:       statsforecast: Not installed
2023-06-12 14:27:33,979:INFO:        tune_sklearn: Not installed
2023-06-12 14:27:33,979:INFO:                 ray: Not installed
2023-06-12 14:27:33,980:INFO:            hyperopt: Not installed
2023-06-12 14:27:33,980:INFO:              optuna: Not installed
2023-06-12 14:27:33,980:INFO:               skopt: Not installed
2023-06-12 14:27:33,981:INFO:              mlflow: 2.4.1
2023-06-12 14:27:33,981:INFO:              gradio: Not installed
2023-06-12 14:27:33,981:INFO:             fastapi: Not installed
2023-06-12 14:27:33,981:INFO:             uvicorn: Not installed
2023-06-12 14:27:33,981:INFO:              m2cgen: Not installed
2023-06-12 14:27:33,981:INFO:           evidently: Not installed
2023-06-12 14:27:33,981:INFO:               fugue: Not installed
2023-06-12 14:27:33,982:INFO:           streamlit: 1.23.1
2023-06-12 14:27:33,982:INFO:             prophet: Not installed
2023-06-12 14:27:33,982:INFO:None
2023-06-12 14:27:33,982:INFO:Set up data.
2023-06-12 14:27:33,994:INFO:Set up train/test split.
2023-06-12 14:27:34,004:INFO:Set up index.
2023-06-12 14:27:34,005:INFO:Set up folding strategy.
2023-06-12 14:27:34,005:INFO:Assigning column types.
2023-06-12 14:27:34,010:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 14:27:34,075:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 14:27:34,075:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 14:27:34,109:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 14:27:34,109:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 14:27:34,163:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 14:27:34,165:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 14:27:34,201:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 14:27:34,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 14:27:34,202:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 14:27:34,256:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 14:27:34,291:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 14:27:34,291:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 14:27:34,351:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 14:27:34,383:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 14:27:34,383:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 14:27:34,384:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 14:27:34,468:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 14:27:34,469:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 14:27:34,554:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 14:27:34,554:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 14:27:34,557:INFO:Preparing preprocessing pipeline...
2023-06-12 14:27:34,558:INFO:Set up label encoding.
2023-06-12 14:27:34,558:INFO:Set up simple imputation.
2023-06-12 14:27:34,562:INFO:Set up encoding of categorical features.
2023-06-12 14:27:34,939:INFO:Finished creating preprocessing pipeline.
2023-06-12 14:27:34,947:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 14:27:34,947:INFO:Creating final display dataframe.
2023-06-12 14:27:35,583:INFO:Setup _display_container:                     Description             Value
0                    Session id              1471
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape        (7656, 12)
5        Transformed data shape       (7656, 419)
6   Transformed train set shape       (5359, 419)
7    Transformed test set shape       (2297, 419)
8              Numeric features                 4
9          Categorical features                 7
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              531e
2023-06-12 14:27:35,669:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 14:27:35,669:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 14:27:35,743:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 14:27:35,743:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 14:27:35,744:INFO:Logging experiment in loggers
2023-06-12 14:27:35,909:INFO:SubProcess save_model() called ==================================
2023-06-12 14:27:35,923:INFO:Initializing save_model()
2023-06-12 14:27:35,923:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmptmmanqqs\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 14:27:35,923:INFO:Adding model into prep_pipe
2023-06-12 14:27:35,923:WARNING:Only Model saved as it was a pipeline.
2023-06-12 14:27:35,936:INFO:C:\Users\alniquia\AppData\Local\Temp\tmptmmanqqs\Transformation Pipeline.pkl saved in current working directory
2023-06-12 14:27:35,942:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 14:27:35,942:INFO:save_model() successfully completed......................................
2023-06-12 14:27:36,075:INFO:SubProcess save_model() end ==================================
2023-06-12 14:27:36,093:INFO:setup() successfully completed in 20.12s...............
2023-06-12 14:27:51,143:INFO:Initializing create_model()
2023-06-12 14:27:51,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001623028B1C0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 14:27:51,143:INFO:Checking exceptions
2023-06-12 14:27:51,169:INFO:Importing libraries
2023-06-12 14:27:51,171:INFO:Copying training dataset
2023-06-12 14:27:51,181:INFO:Defining folds
2023-06-12 14:27:51,181:INFO:Declaring metric variables
2023-06-12 14:27:51,186:INFO:Importing untrained model
2023-06-12 14:27:51,195:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 14:27:51,210:INFO:Starting cross validation
2023-06-12 14:27:51,215:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 14:31:36,385:INFO:Calculating mean and std
2023-06-12 14:31:36,388:INFO:Creating metrics dataframe
2023-06-12 14:31:36,396:INFO:Finalizing model
2023-06-12 14:31:58,551:INFO:Creating Dashboard logs
2023-06-12 14:31:58,555:INFO:Model: Light Gradient Boosting Machine
2023-06-12 14:31:58,682:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 1471, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 14:31:58,865:INFO:Initializing predict_model()
2023-06-12 14:31:58,865:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001623028B1C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1471, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001623298F130>)
2023-06-12 14:31:58,865:INFO:Checking exceptions
2023-06-12 14:31:58,865:INFO:Preloading libraries
2023-06-12 14:32:15,258:INFO:Uploading results into container
2023-06-12 14:32:15,259:INFO:Uploading model into container now
2023-06-12 14:32:15,272:INFO:_master_model_container: 1
2023-06-12 14:32:15,272:INFO:_display_container: 2
2023-06-12 14:32:15,273:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1471, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 14:32:15,274:INFO:create_model() successfully completed......................................
2023-06-12 14:32:15,445:INFO:Initializing tune_model()
2023-06-12 14:32:15,446:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1471, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001623028B1C0>)
2023-06-12 14:32:15,446:INFO:Checking exceptions
2023-06-12 14:32:15,482:INFO:Copying training dataset
2023-06-12 14:32:15,490:INFO:Checking base model
2023-06-12 14:32:15,491:INFO:Base model : Light Gradient Boosting Machine
2023-06-12 14:32:15,503:INFO:Declaring metric variables
2023-06-12 14:32:15,511:INFO:Defining Hyperparameters
2023-06-12 14:32:15,653:INFO:Tuning with n_jobs=-1
2023-06-12 14:32:15,653:INFO:Initializing RandomizedSearchCV
2023-06-12 14:32:47,631:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 14:32:47,718:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 14:32:47,861:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 14:37:18,731:INFO:Initializing load_model()
2023-06-12 14:37:18,731:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-12 14:37:18,800:INFO:Initializing load_model()
2023-06-12 14:37:18,800:INFO:load_model(model_name=models/bs_predictor_gemGrab, platform=None, authentication=None, verbose=True)
2023-06-12 14:37:50,712:INFO:Initializing load_model()
2023-06-12 14:37:50,712:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-12 14:37:50,762:INFO:Initializing load_model()
2023-06-12 14:37:50,762:INFO:load_model(model_name=models/bs_predictor_gemGrab, platform=None, authentication=None, verbose=True)
2023-06-12 15:02:56,833:INFO:best_params: {'actual_estimator__reg_lambda': 0.15, 'actual_estimator__reg_alpha': 4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 51, 'actual_estimator__learning_rate': 0.001, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.9}
2023-06-12 15:02:56,834:INFO:Hyperparameter search completed
2023-06-12 15:02:56,835:INFO:SubProcess create_model() called ==================================
2023-06-12 15:02:56,836:INFO:Initializing create_model()
2023-06-12 15:02:56,836:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001623028B1C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1471, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001623349A2F0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.15, 'reg_alpha': 4, 'num_leaves': 80, 'n_estimators': 230, 'min_split_gain': 0.4, 'min_child_samples': 51, 'learning_rate': 0.001, 'feature_fraction': 0.6, 'bagging_freq': 4, 'bagging_fraction': 0.9})
2023-06-12 15:02:56,836:INFO:Checking exceptions
2023-06-12 15:02:56,836:INFO:Importing libraries
2023-06-12 15:02:56,836:INFO:Copying training dataset
2023-06-12 15:02:56,846:INFO:Defining folds
2023-06-12 15:02:56,847:INFO:Declaring metric variables
2023-06-12 15:02:56,851:INFO:Importing untrained model
2023-06-12 15:02:56,852:INFO:Declaring custom model
2023-06-12 15:02:56,858:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 15:02:56,867:INFO:Starting cross validation
2023-06-12 15:02:56,870:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:05:56,576:INFO:Calculating mean and std
2023-06-12 15:05:56,578:INFO:Creating metrics dataframe
2023-06-12 15:05:56,586:INFO:Finalizing model
2023-06-12 15:05:56,754:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2023-06-12 15:05:56,755:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-06-12 15:05:56,755:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-06-12 15:06:16,293:INFO:Uploading results into container
2023-06-12 15:06:16,294:INFO:Uploading model into container now
2023-06-12 15:06:16,295:INFO:_master_model_container: 2
2023-06-12 15:06:16,295:INFO:_display_container: 3
2023-06-12 15:06:16,295:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=51, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=230, n_jobs=-1, num_leaves=80, objective=None,
               random_state=1471, reg_alpha=4, reg_lambda=0.15, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 15:06:16,295:INFO:create_model() successfully completed......................................
2023-06-12 15:06:16,418:INFO:SubProcess create_model() end ==================================
2023-06-12 15:06:16,418:INFO:choose_better activated
2023-06-12 15:06:16,423:INFO:SubProcess create_model() called ==================================
2023-06-12 15:06:16,424:INFO:Initializing create_model()
2023-06-12 15:06:16,424:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001623028B1C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1471, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:06:16,424:INFO:Checking exceptions
2023-06-12 15:06:16,426:INFO:Importing libraries
2023-06-12 15:06:16,427:INFO:Copying training dataset
2023-06-12 15:06:16,432:INFO:Defining folds
2023-06-12 15:06:16,432:INFO:Declaring metric variables
2023-06-12 15:06:16,432:INFO:Importing untrained model
2023-06-12 15:06:16,432:INFO:Declaring custom model
2023-06-12 15:06:16,433:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 15:06:16,433:INFO:Starting cross validation
2023-06-12 15:06:16,435:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:09:12,923:INFO:Calculating mean and std
2023-06-12 15:09:12,923:INFO:Creating metrics dataframe
2023-06-12 15:09:12,925:INFO:Finalizing model
2023-06-12 15:09:33,579:INFO:Uploading results into container
2023-06-12 15:09:33,580:INFO:Uploading model into container now
2023-06-12 15:09:33,580:INFO:_master_model_container: 3
2023-06-12 15:09:33,580:INFO:_display_container: 4
2023-06-12 15:09:33,580:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1471, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 15:09:33,581:INFO:create_model() successfully completed......................................
2023-06-12 15:09:33,706:INFO:SubProcess create_model() end ==================================
2023-06-12 15:09:33,707:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1471, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6685
2023-06-12 15:09:33,708:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=51, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=230, n_jobs=-1, num_leaves=80, objective=None,
               random_state=1471, reg_alpha=4, reg_lambda=0.15, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6952
2023-06-12 15:09:33,708:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=51, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=230, n_jobs=-1, num_leaves=80, objective=None,
               random_state=1471, reg_alpha=4, reg_lambda=0.15, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-06-12 15:09:33,708:INFO:choose_better completed
2023-06-12 15:09:33,709:INFO:Creating Dashboard logs
2023-06-12 15:09:33,713:INFO:Model: Light Gradient Boosting Machine
2023-06-12 15:09:33,796:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.001, 'max_depth': -1, 'min_child_samples': 51, 'min_child_weight': 0.001, 'min_split_gain': 0.4, 'n_estimators': 230, 'n_jobs': -1, 'num_leaves': 80, 'objective': None, 'random_state': 1471, 'reg_alpha': 4, 'reg_lambda': 0.15, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.6, 'bagging_freq': 4, 'bagging_fraction': 0.9}
2023-06-12 15:09:34,042:INFO:Initializing predict_model()
2023-06-12 15:09:34,042:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001623028B1C0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=51, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=230, n_jobs=-1, num_leaves=80, objective=None,
               random_state=1471, reg_alpha=4, reg_lambda=0.15, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016233518A60>)
2023-06-12 15:09:34,042:INFO:Checking exceptions
2023-06-12 15:09:34,042:INFO:Preloading libraries
2023-06-12 15:09:49,982:INFO:_master_model_container: 3
2023-06-12 15:09:49,982:INFO:_display_container: 3
2023-06-12 15:09:49,983:INFO:LGBMClassifier(bagging_fraction=0.9, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=51, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=230, n_jobs=-1, num_leaves=80, objective=None,
               random_state=1471, reg_alpha=4, reg_lambda=0.15, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 15:09:49,983:INFO:tune_model() successfully completed......................................
2023-06-12 15:10:05,326:INFO:Initializing finalize_model()
2023-06-12 15:10:05,326:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001623028B1C0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=51, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=230, n_jobs=-1, num_leaves=80, objective=None,
               random_state=1471, reg_alpha=4, reg_lambda=0.15, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-12 15:10:05,327:INFO:Finalizing LGBMClassifier(bagging_fraction=0.9, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=51, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=230, n_jobs=-1, num_leaves=80, objective=None,
               random_state=1471, reg_alpha=4, reg_lambda=0.15, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 15:10:05,334:INFO:Initializing create_model()
2023-06-12 15:10:05,334:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001623028B1C0>, estimator=LGBMClassifier(bagging_fraction=0.9, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.001, max_depth=-1,
               min_child_samples=51, min_child_weight=0.001, min_split_gain=0.4,
               n_estimators=230, n_jobs=-1, num_leaves=80, objective=None,
               random_state=1471, reg_alpha=4, reg_lambda=0.15, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-12 15:10:05,335:INFO:Checking exceptions
2023-06-12 15:10:05,338:INFO:Importing libraries
2023-06-12 15:10:05,338:INFO:Copying training dataset
2023-06-12 15:10:05,338:INFO:Defining folds
2023-06-12 15:10:05,338:INFO:Declaring metric variables
2023-06-12 15:10:05,339:INFO:Importing untrained model
2023-06-12 15:10:05,339:INFO:Declaring custom model
2023-06-12 15:10:05,340:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 15:10:05,344:INFO:Cross validation set to False
2023-06-12 15:10:05,344:INFO:Fitting Model
2023-06-12 15:10:05,997:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2023-06-12 15:10:05,997:INFO:[LightGBM] [Warning] bagging_fraction is set=0.9, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9
2023-06-12 15:10:05,997:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-06-12 15:10:06,586:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=51,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=230, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=1471, reg_alpha=4,
                                reg_lambda=0.15, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 15:10:06,586:INFO:create_model() successfully completed......................................
2023-06-12 15:10:06,736:INFO:Creating Dashboard logs
2023-06-12 15:10:06,737:INFO:Model: Light Gradient Boosting Machine
2023-06-12 15:10:06,823:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.001, 'max_depth': -1, 'min_child_samples': 51, 'min_child_weight': 0.001, 'min_split_gain': 0.4, 'n_estimators': 230, 'n_jobs': -1, 'num_leaves': 80, 'objective': None, 'random_state': 1471, 'reg_alpha': 4, 'reg_lambda': 0.15, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.6, 'bagging_freq': 4, 'bagging_fraction': 0.9}
2023-06-12 15:10:07,363:INFO:_master_model_container: 3
2023-06-12 15:10:07,364:INFO:_display_container: 3
2023-06-12 15:10:07,373:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=51,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=230, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=1471, reg_alpha=4,
                                reg_lambda=0.15, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 15:10:07,373:INFO:finalize_model() successfully completed......................................
2023-06-12 15:10:07,526:INFO:Initializing save_model()
2023-06-12 15:10:07,527:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=51,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=230, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=1471, reg_alpha=4,
                                reg_lambda=0.15, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=models/bs_predictor_gemGrab, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 15:10:07,527:INFO:Adding model into prep_pipe
2023-06-12 15:10:07,527:WARNING:Only Model saved as it was a pipeline.
2023-06-12 15:10:07,588:INFO:models/bs_predictor_gemGrab.pkl saved in current working directory
2023-06-12 15:10:07,612:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=51,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=230, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=1471, reg_alpha=4,
                                reg_lambda=0.15, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 15:10:07,613:INFO:save_model() successfully completed......................................
2023-06-12 15:10:07,838:INFO:Initializing predict_model()
2023-06-12 15:10:07,838:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001623028B1C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.001,
                                max_depth=-1, min_child_samples=51,
                                min_child_weight=0.001, min_split_gain=0.4,
                                n_estimators=230, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=1471, reg_alpha=4,
                                reg_lambda=0.15, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016234C76E60>)
2023-06-12 15:10:07,838:INFO:Checking exceptions
2023-06-12 15:10:07,838:INFO:Preloading libraries
2023-06-12 15:10:07,845:INFO:Set up data.
2023-06-12 15:10:07,859:INFO:Set up index.
2023-06-12 15:11:40,379:INFO:Initializing load_model()
2023-06-12 15:11:40,379:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-12 15:11:40,401:INFO:Initializing load_model()
2023-06-12 15:11:40,401:INFO:load_model(model_name=models/bs_predictor_gemGrab, platform=None, authentication=None, verbose=True)
2023-06-12 15:11:46,359:INFO:Initializing predict_model()
2023-06-12 15:11:46,359:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F002DC2E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04881FC0>)
2023-06-12 15:11:46,359:INFO:Checking exceptions
2023-06-12 15:11:46,360:INFO:Preloading libraries
2023-06-12 15:11:46,360:INFO:Set up data.
2023-06-12 15:11:46,371:INFO:Set up index.
2023-06-12 15:11:55,429:INFO:Initializing predict_model()
2023-06-12 15:11:55,429:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0517DC90>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F05189FC0>)
2023-06-12 15:11:55,430:INFO:Checking exceptions
2023-06-12 15:11:55,430:INFO:Preloading libraries
2023-06-12 15:11:55,430:INFO:Set up data.
2023-06-12 15:11:55,446:INFO:Set up index.
2023-06-12 15:12:16,829:INFO:Initializing predict_model()
2023-06-12 15:12:16,829:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00339C30>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04881BD0>)
2023-06-12 15:12:16,829:INFO:Checking exceptions
2023-06-12 15:12:16,830:INFO:Preloading libraries
2023-06-12 15:12:16,830:INFO:Set up data.
2023-06-12 15:12:16,851:INFO:Set up index.
2023-06-12 15:28:42,125:INFO:PyCaret ClassificationExperiment
2023-06-12 15:28:42,125:INFO:Logging name: clf-default-name
2023-06-12 15:28:42,125:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 15:28:42,125:INFO:version 3.0.2
2023-06-12 15:28:42,126:INFO:Initializing setup()
2023-06-12 15:28:42,126:INFO:self.USI: c95c
2023-06-12 15:28:42,126:INFO:self._variable_keys: {'html_param', 'seed', 'gpu_n_jobs_param', 'X_train', 'exp_id', 'fix_imbalance', 'is_multiclass', 'USI', 'y_train', 'fold_shuffle_param', 'logging_param', 'gpu_param', 'y', 'fold_groups_param', 'target_param', 'X', 'idx', 'exp_name_log', '_available_plots', 'fold_generator', 'log_plots_param', 'pipeline', 'n_jobs_param', 'memory', 'X_test', '_ml_usecase', 'data', 'y_test'}
2023-06-12 15:28:42,126:INFO:Checking environment
2023-06-12 15:28:42,126:INFO:python_version: 3.10.10
2023-06-12 15:28:42,126:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 15:28:42,126:INFO:machine: AMD64
2023-06-12 15:28:42,127:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 15:28:42,130:INFO:Memory: svmem(total=17034072064, available=7238217728, percent=57.5, used=9795854336, free=7238217728)
2023-06-12 15:28:42,130:INFO:Physical Core: 2
2023-06-12 15:28:42,131:INFO:Logical Core: 4
2023-06-12 15:28:42,131:INFO:Checking libraries
2023-06-12 15:28:42,131:INFO:System:
2023-06-12 15:28:42,131:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 15:28:42,131:INFO:executable: c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 15:28:42,131:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 15:28:42,131:INFO:PyCaret required dependencies:
2023-06-12 15:28:42,132:INFO:                 pip: 23.1.2
2023-06-12 15:28:42,132:INFO:          setuptools: 65.5.0
2023-06-12 15:28:42,132:INFO:             pycaret: 3.0.2
2023-06-12 15:28:42,132:INFO:             IPython: 8.14.0
2023-06-12 15:28:42,132:INFO:          ipywidgets: 8.0.6
2023-06-12 15:28:42,132:INFO:                tqdm: 4.65.0
2023-06-12 15:28:42,132:INFO:               numpy: 1.23.5
2023-06-12 15:28:42,132:INFO:              pandas: 1.5.3
2023-06-12 15:28:42,133:INFO:              jinja2: 3.1.2
2023-06-12 15:28:42,133:INFO:               scipy: 1.10.1
2023-06-12 15:28:42,133:INFO:              joblib: 1.2.0
2023-06-12 15:28:42,133:INFO:             sklearn: 1.2.2
2023-06-12 15:28:42,133:INFO:                pyod: 1.0.9
2023-06-12 15:28:42,133:INFO:            imblearn: 0.10.1
2023-06-12 15:28:42,133:INFO:   category_encoders: 2.6.1
2023-06-12 15:28:42,135:INFO:            lightgbm: 3.3.5
2023-06-12 15:28:42,135:INFO:               numba: 0.57.0
2023-06-12 15:28:42,135:INFO:            requests: 2.31.0
2023-06-12 15:28:42,135:INFO:          matplotlib: 3.7.1
2023-06-12 15:28:42,135:INFO:          scikitplot: 0.3.7
2023-06-12 15:28:42,135:INFO:         yellowbrick: 1.5
2023-06-12 15:28:42,135:INFO:              plotly: 5.15.0
2023-06-12 15:28:42,136:INFO:             kaleido: 0.2.1
2023-06-12 15:28:42,136:INFO:         statsmodels: 0.14.0
2023-06-12 15:28:42,136:INFO:              sktime: 0.17.0
2023-06-12 15:28:42,136:INFO:               tbats: 1.1.3
2023-06-12 15:28:42,136:INFO:            pmdarima: 2.0.3
2023-06-12 15:28:42,136:INFO:              psutil: 5.9.5
2023-06-12 15:28:42,136:INFO:PyCaret optional dependencies:
2023-06-12 15:28:42,136:INFO:                shap: Not installed
2023-06-12 15:28:42,136:INFO:           interpret: Not installed
2023-06-12 15:28:42,137:INFO:                umap: Not installed
2023-06-12 15:28:42,137:INFO:    pandas_profiling: Not installed
2023-06-12 15:28:42,137:INFO:  explainerdashboard: Not installed
2023-06-12 15:28:42,137:INFO:             autoviz: Not installed
2023-06-12 15:28:42,137:INFO:           fairlearn: Not installed
2023-06-12 15:28:42,137:INFO:             xgboost: Not installed
2023-06-12 15:28:42,137:INFO:            catboost: Not installed
2023-06-12 15:28:42,138:INFO:              kmodes: Not installed
2023-06-12 15:28:42,138:INFO:             mlxtend: Not installed
2023-06-12 15:28:42,138:INFO:       statsforecast: Not installed
2023-06-12 15:28:42,138:INFO:        tune_sklearn: Not installed
2023-06-12 15:28:42,138:INFO:                 ray: Not installed
2023-06-12 15:28:42,138:INFO:            hyperopt: Not installed
2023-06-12 15:28:42,138:INFO:              optuna: Not installed
2023-06-12 15:28:42,138:INFO:               skopt: Not installed
2023-06-12 15:28:42,138:INFO:              mlflow: 2.4.1
2023-06-12 15:28:42,139:INFO:              gradio: Not installed
2023-06-12 15:28:42,139:INFO:             fastapi: Not installed
2023-06-12 15:28:42,139:INFO:             uvicorn: Not installed
2023-06-12 15:28:42,139:INFO:              m2cgen: Not installed
2023-06-12 15:28:42,139:INFO:           evidently: Not installed
2023-06-12 15:28:42,139:INFO:               fugue: Not installed
2023-06-12 15:28:42,139:INFO:           streamlit: 1.23.1
2023-06-12 15:28:42,140:INFO:             prophet: Not installed
2023-06-12 15:28:42,140:INFO:None
2023-06-12 15:28:42,140:INFO:Set up data.
2023-06-12 15:28:42,152:INFO:Set up train/test split.
2023-06-12 15:28:42,160:INFO:Set up index.
2023-06-12 15:28:42,160:INFO:Set up folding strategy.
2023-06-12 15:28:42,160:INFO:Assigning column types.
2023-06-12 15:28:42,165:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 15:28:42,224:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:28:42,225:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 15:28:42,255:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:28:42,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:28:42,301:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 15:28:42,303:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 15:28:42,330:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:28:42,330:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:28:42,331:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 15:28:42,377:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 15:28:42,405:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:28:42,406:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:28:42,454:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 15:28:42,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:28:42,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:28:42,483:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 15:28:42,560:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:28:42,560:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:28:42,638:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:28:42,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:28:42,640:INFO:Preparing preprocessing pipeline...
2023-06-12 15:28:42,641:INFO:Set up label encoding.
2023-06-12 15:28:42,641:INFO:Set up simple imputation.
2023-06-12 15:28:42,644:INFO:Set up encoding of categorical features.
2023-06-12 15:28:42,954:INFO:Finished creating preprocessing pipeline.
2023-06-12 15:28:42,960:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 15:28:42,960:INFO:Creating final display dataframe.
2023-06-12 15:28:43,490:INFO:Setup _display_container:                     Description             Value
0                    Session id              7302
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape        (5783, 12)
5        Transformed data shape       (5783, 416)
6   Transformed train set shape       (4048, 416)
7    Transformed test set shape       (1735, 416)
8              Numeric features                 4
9          Categorical features                 7
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              c95c
2023-06-12 15:28:43,582:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:28:43,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:28:43,659:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:28:43,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 15:28:43,660:INFO:Logging experiment in loggers
2023-06-12 15:28:43,888:INFO:SubProcess save_model() called ==================================
2023-06-12 15:28:43,905:INFO:Initializing save_model()
2023-06-12 15:28:43,905:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmp6tlrl3fd\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 15:28:43,905:INFO:Adding model into prep_pipe
2023-06-12 15:28:43,905:WARNING:Only Model saved as it was a pipeline.
2023-06-12 15:28:43,917:INFO:C:\Users\alniquia\AppData\Local\Temp\tmp6tlrl3fd\Transformation Pipeline.pkl saved in current working directory
2023-06-12 15:28:43,925:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 15:28:43,925:INFO:save_model() successfully completed......................................
2023-06-12 15:28:44,060:INFO:SubProcess save_model() end ==================================
2023-06-12 15:28:44,083:INFO:setup() successfully completed in 16.77s...............
2023-06-12 15:28:58,935:INFO:Initializing create_model()
2023-06-12 15:28:58,935:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001623028AAA0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 15:28:58,935:INFO:Checking exceptions
2023-06-12 15:28:58,967:INFO:Importing libraries
2023-06-12 15:28:58,968:INFO:Copying training dataset
2023-06-12 15:28:58,981:INFO:Defining folds
2023-06-12 15:28:58,982:INFO:Declaring metric variables
2023-06-12 15:28:58,987:INFO:Importing untrained model
2023-06-12 15:28:58,995:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 15:28:59,009:INFO:Starting cross validation
2023-06-12 15:28:59,012:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 15:32:08,333:INFO:Calculating mean and std
2023-06-12 15:32:08,334:INFO:Creating metrics dataframe
2023-06-12 15:32:08,341:INFO:Finalizing model
2023-06-12 15:32:27,407:INFO:Creating Dashboard logs
2023-06-12 15:32:27,419:INFO:Model: Light Gradient Boosting Machine
2023-06-12 15:32:27,505:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 7302, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 15:32:27,753:INFO:Initializing predict_model()
2023-06-12 15:32:27,753:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001623028AAA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7302, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000162301EF910>)
2023-06-12 15:32:27,753:INFO:Checking exceptions
2023-06-12 15:32:27,753:INFO:Preloading libraries
2023-06-12 15:32:43,886:INFO:Uploading results into container
2023-06-12 15:32:43,887:INFO:Uploading model into container now
2023-06-12 15:32:43,903:INFO:_master_model_container: 1
2023-06-12 15:32:43,903:INFO:_display_container: 2
2023-06-12 15:32:43,904:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7302, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 15:32:43,904:INFO:create_model() successfully completed......................................
2023-06-12 15:32:44,127:INFO:Initializing tune_model()
2023-06-12 15:32:44,128:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7302, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001623028AAA0>)
2023-06-12 15:32:44,128:INFO:Checking exceptions
2023-06-12 15:32:44,167:INFO:Copying training dataset
2023-06-12 15:32:44,177:INFO:Checking base model
2023-06-12 15:32:44,178:INFO:Base model : Light Gradient Boosting Machine
2023-06-12 15:32:44,184:INFO:Declaring metric variables
2023-06-12 15:32:44,192:INFO:Defining Hyperparameters
2023-06-12 15:32:44,416:INFO:Tuning with n_jobs=-1
2023-06-12 15:32:44,416:INFO:Initializing RandomizedSearchCV
2023-06-12 15:34:15,304:INFO:Initializing predict_model()
2023-06-12 15:34:15,304:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0033A3B0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04882F80>)
2023-06-12 15:34:15,305:INFO:Checking exceptions
2023-06-12 15:34:15,305:INFO:Preloading libraries
2023-06-12 15:34:15,306:INFO:Set up data.
2023-06-12 15:34:15,324:INFO:Set up index.
2023-06-12 15:34:32,752:INFO:Initializing predict_model()
2023-06-12 15:34:32,753:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F002DC7C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04882B00>)
2023-06-12 15:34:32,753:INFO:Checking exceptions
2023-06-12 15:34:32,754:INFO:Preloading libraries
2023-06-12 15:34:32,755:INFO:Set up data.
2023-06-12 15:34:32,770:INFO:Set up index.
2023-06-12 15:34:46,149:INFO:Initializing predict_model()
2023-06-12 15:34:46,150:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F002DB9A0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F0518A3B0>)
2023-06-12 15:34:46,150:INFO:Checking exceptions
2023-06-12 15:34:46,150:INFO:Preloading libraries
2023-06-12 15:34:46,151:INFO:Set up data.
2023-06-12 15:34:46,172:INFO:Set up index.
2023-06-12 15:34:56,877:INFO:Initializing predict_model()
2023-06-12 15:34:56,877:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F002DA290>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F0518A320>)
2023-06-12 15:34:56,877:INFO:Checking exceptions
2023-06-12 15:34:56,878:INFO:Preloading libraries
2023-06-12 15:34:56,878:INFO:Set up data.
2023-06-12 15:34:56,917:INFO:Set up index.
2023-06-12 15:35:08,807:INFO:Initializing predict_model()
2023-06-12 15:35:08,807:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00504E50>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F04882680>)
2023-06-12 15:35:08,808:INFO:Checking exceptions
2023-06-12 15:35:08,808:INFO:Preloading libraries
2023-06-12 15:35:08,809:INFO:Set up data.
2023-06-12 15:35:08,829:INFO:Set up index.
2023-06-12 15:41:25,691:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 15:48:17,567:INFO:Initializing predict_model()
2023-06-12 15:48:17,567:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00507520>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F05189A20>)
2023-06-12 15:48:17,568:INFO:Checking exceptions
2023-06-12 15:48:17,568:INFO:Preloading libraries
2023-06-12 15:48:17,569:INFO:Set up data.
2023-06-12 15:48:17,585:INFO:Set up index.
2023-06-12 15:48:27,778:INFO:Initializing predict_model()
2023-06-12 15:48:27,778:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0517FFA0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F0518AD40>)
2023-06-12 15:48:27,778:INFO:Checking exceptions
2023-06-12 15:48:27,778:INFO:Preloading libraries
2023-06-12 15:48:27,779:INFO:Set up data.
2023-06-12 15:48:27,793:INFO:Set up index.
2023-06-12 15:48:36,174:INFO:Initializing predict_model()
2023-06-12 15:48:36,174:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F002D8250>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F71B1C310>)
2023-06-12 15:48:36,175:INFO:Checking exceptions
2023-06-12 15:48:36,175:INFO:Preloading libraries
2023-06-12 15:48:36,175:INFO:Set up data.
2023-06-12 15:48:36,189:INFO:Set up index.
2023-06-12 15:48:45,954:INFO:Initializing predict_model()
2023-06-12 15:48:45,955:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0517DE70>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F71B1C280>)
2023-06-12 15:48:45,955:INFO:Checking exceptions
2023-06-12 15:48:45,955:INFO:Preloading libraries
2023-06-12 15:48:45,956:INFO:Set up data.
2023-06-12 15:48:45,970:INFO:Set up index.
2023-06-12 15:48:55,944:INFO:Initializing predict_model()
2023-06-12 15:48:55,944:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F0033B0A0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F71B1C4C0>)
2023-06-12 15:48:55,944:INFO:Checking exceptions
2023-06-12 15:48:55,944:INFO:Preloading libraries
2023-06-12 15:48:55,945:INFO:Set up data.
2023-06-12 15:48:55,963:INFO:Set up index.
2023-06-12 15:49:04,446:INFO:Initializing predict_model()
2023-06-12 15:49:04,448:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00412770>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F0518B9A0>)
2023-06-12 15:49:04,448:INFO:Checking exceptions
2023-06-12 15:49:04,448:INFO:Preloading libraries
2023-06-12 15:49:04,449:INFO:Set up data.
2023-06-12 15:49:04,465:INFO:Set up index.
2023-06-12 15:49:10,953:INFO:Initializing predict_model()
2023-06-12 15:49:10,953:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F003465F0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F71B1C160>)
2023-06-12 15:49:10,960:INFO:Checking exceptions
2023-06-12 15:49:10,960:INFO:Preloading libraries
2023-06-12 15:49:10,960:INFO:Set up data.
2023-06-12 15:49:10,975:INFO:Set up index.
2023-06-12 15:49:33,519:INFO:Initializing predict_model()
2023-06-12 15:49:33,519:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00411690>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                    transformer=OneHotEncoder(cols=['event_map',
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator', LGBMClassifier(random_state=6999))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F0518B7F0>)
2023-06-12 15:49:33,519:INFO:Checking exceptions
2023-06-12 15:49:33,519:INFO:Preloading libraries
2023-06-12 15:49:33,520:INFO:Set up data.
2023-06-12 15:49:33,539:INFO:Set up index.
2023-06-12 15:49:40,886:INFO:Initializing predict_model()
2023-06-12 15:49:40,886:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00506800>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                    transformer=OneHotEncoder(cols=['event_map',
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator', LGBMClassifier(random_state=6999))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F71B1C4C0>)
2023-06-12 15:49:40,886:INFO:Checking exceptions
2023-06-12 15:49:40,887:INFO:Preloading libraries
2023-06-12 15:49:40,887:INFO:Set up data.
2023-06-12 15:49:40,905:INFO:Set up index.
2023-06-12 15:49:53,163:INFO:Initializing predict_model()
2023-06-12 15:49:53,163:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00506290>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                    transformer=OneHotEncoder(cols=['event_map',
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator', LGBMClassifier(random_state=6999))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F71B1C310>)
2023-06-12 15:49:53,163:INFO:Checking exceptions
2023-06-12 15:49:53,163:INFO:Preloading libraries
2023-06-12 15:49:53,171:INFO:Set up data.
2023-06-12 15:49:53,196:INFO:Set up index.
2023-06-12 15:50:00,375:INFO:Initializing predict_model()
2023-06-12 15:50:00,375:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00410070>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                    transformer=OneHotEncoder(cols=['event_map',
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator', LGBMClassifier(random_state=6999))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F71B1C4C0>)
2023-06-12 15:50:00,375:INFO:Checking exceptions
2023-06-12 15:50:00,376:INFO:Preloading libraries
2023-06-12 15:50:00,376:INFO:Set up data.
2023-06-12 15:50:00,409:INFO:Set up index.
2023-06-12 15:50:15,639:INFO:Initializing predict_model()
2023-06-12 15:50:15,639:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00411900>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                    transformer=OneHotEncoder(cols=['event_map',
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator', LGBMClassifier(random_state=6999))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F71B1C3A0>)
2023-06-12 15:50:15,640:INFO:Checking exceptions
2023-06-12 15:50:15,640:INFO:Preloading libraries
2023-06-12 15:50:15,641:INFO:Set up data.
2023-06-12 15:50:15,657:INFO:Set up index.
2023-06-12 15:50:20,075:INFO:Initializing predict_model()
2023-06-12 15:50:20,075:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00347EE0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                    transformer=OneHotEncoder(cols=['event_map',
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator', LGBMClassifier(random_state=6999))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F71ABBE20>)
2023-06-12 15:50:20,075:INFO:Checking exceptions
2023-06-12 15:50:20,075:INFO:Preloading libraries
2023-06-12 15:50:20,076:INFO:Set up data.
2023-06-12 15:50:20,099:INFO:Set up index.
2023-06-12 15:52:14,794:INFO:Initializing predict_model()
2023-06-12 15:52:14,794:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F005069E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                    transformer=OneHotEncoder(cols=['event_map',
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator', LGBMClassifier(random_state=6999))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F71ABBE20>)
2023-06-12 15:52:14,795:INFO:Checking exceptions
2023-06-12 15:52:14,795:INFO:Preloading libraries
2023-06-12 15:52:14,796:INFO:Set up data.
2023-06-12 15:52:14,810:INFO:Set up index.
2023-06-12 15:52:25,179:INFO:Initializing predict_model()
2023-06-12 15:52:25,180:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F7FEB2920>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                    transformer=OneHotEncoder(cols=['event_map',
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator', LGBMClassifier(random_state=6999))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F0518B880>)
2023-06-12 15:52:25,180:INFO:Checking exceptions
2023-06-12 15:52:25,180:INFO:Preloading libraries
2023-06-12 15:52:25,181:INFO:Set up data.
2023-06-12 15:52:25,196:INFO:Set up index.
2023-06-12 15:52:30,815:INFO:Initializing predict_model()
2023-06-12 15:52:30,815:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00507310>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                    transformer=OneHotEncoder(cols=['event_map',
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator', LGBMClassifier(random_state=6999))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F0518B1C0>)
2023-06-12 15:52:30,815:INFO:Checking exceptions
2023-06-12 15:52:30,818:INFO:Preloading libraries
2023-06-12 15:52:30,818:INFO:Set up data.
2023-06-12 15:52:30,833:INFO:Set up index.
2023-06-12 15:52:38,289:INFO:Initializing predict_model()
2023-06-12 15:52:38,290:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F7FEB26E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F71B1C3A0>)
2023-06-12 15:52:38,290:INFO:Checking exceptions
2023-06-12 15:52:38,290:INFO:Preloading libraries
2023-06-12 15:52:38,290:INFO:Set up data.
2023-06-12 15:52:38,307:INFO:Set up index.
2023-06-12 15:52:45,128:INFO:Initializing predict_model()
2023-06-12 15:52:45,129:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00412B60>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F0518A170>)
2023-06-12 15:52:45,129:INFO:Checking exceptions
2023-06-12 15:52:45,129:INFO:Preloading libraries
2023-06-12 15:52:45,130:INFO:Set up data.
2023-06-12 15:52:45,148:INFO:Set up index.
2023-06-12 15:52:51,992:INFO:Initializing predict_model()
2023-06-12 15:52:51,992:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00344D90>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F0518B880>)
2023-06-12 15:52:51,993:INFO:Checking exceptions
2023-06-12 15:52:51,993:INFO:Preloading libraries
2023-06-12 15:52:51,994:INFO:Set up data.
2023-06-12 15:52:52,019:INFO:Set up index.
2023-06-12 15:52:58,488:INFO:Initializing predict_model()
2023-06-12 15:52:58,489:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00506E00>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F71B1C280>)
2023-06-12 15:52:58,489:INFO:Checking exceptions
2023-06-12 15:52:58,489:INFO:Preloading libraries
2023-06-12 15:52:58,490:INFO:Set up data.
2023-06-12 15:52:58,506:INFO:Set up index.
2023-06-12 15:53:02,896:INFO:Initializing predict_model()
2023-06-12 15:53:02,896:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00344790>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F0518AD40>)
2023-06-12 15:53:02,897:INFO:Checking exceptions
2023-06-12 15:53:02,897:INFO:Preloading libraries
2023-06-12 15:53:02,898:INFO:Set up data.
2023-06-12 15:53:02,915:INFO:Set up index.
2023-06-12 15:53:12,916:INFO:Initializing predict_model()
2023-06-12 15:53:12,916:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00410550>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F0518A170>)
2023-06-12 15:53:12,916:INFO:Checking exceptions
2023-06-12 15:53:12,916:INFO:Preloading libraries
2023-06-12 15:53:12,918:INFO:Set up data.
2023-06-12 15:53:12,932:INFO:Set up index.
2023-06-12 15:53:56,035:INFO:Initializing predict_model()
2023-06-12 15:53:56,036:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00505CC0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F0518BBE0>)
2023-06-12 15:53:56,036:INFO:Checking exceptions
2023-06-12 15:53:56,036:INFO:Preloading libraries
2023-06-12 15:53:56,037:INFO:Set up data.
2023-06-12 15:53:56,053:INFO:Set up index.
2023-06-12 15:54:11,415:INFO:Initializing predict_model()
2023-06-12 15:54:11,416:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00347310>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F0518B250>)
2023-06-12 15:54:11,416:INFO:Checking exceptions
2023-06-12 15:54:11,416:INFO:Preloading libraries
2023-06-12 15:54:11,417:INFO:Set up data.
2023-06-12 15:54:11,439:INFO:Set up index.
2023-06-12 15:54:22,545:INFO:Initializing predict_model()
2023-06-12 15:54:22,545:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000020F00412770>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff'],
                                    transformer=SimpleImputer())),
                (...
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('actual_estimator',
                 LGBMClassifier(bagging_fraction=0.9, bagging_freq=4,
                                feature_fraction=0.6, learning_rate=0.001,
                                min_child_samples=51, min_split_gain=0.4,
                                n_estimators=230, num_leaves=80,
                                random_state=1471, reg_alpha=4,
                                reg_lambda=0.15))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000020F051892D0>)
2023-06-12 15:54:22,545:INFO:Checking exceptions
2023-06-12 15:54:22,546:INFO:Preloading libraries
2023-06-12 15:54:22,546:INFO:Set up data.
2023-06-12 15:54:22,562:INFO:Set up index.
2023-06-12 16:06:19,383:INFO:best_params: {'actual_estimator__reg_lambda': 0.05, 'actual_estimator__reg_alpha': 0.0001, 'actual_estimator__num_leaves': 20, 'actual_estimator__n_estimators': 210, 'actual_estimator__min_split_gain': 0.1, 'actual_estimator__min_child_samples': 26, 'actual_estimator__learning_rate': 0.0005, 'actual_estimator__feature_fraction': 0.6, 'actual_estimator__bagging_freq': 4, 'actual_estimator__bagging_fraction': 0.4}
2023-06-12 16:06:19,398:INFO:Hyperparameter search completed
2023-06-12 16:06:19,398:INFO:SubProcess create_model() called ==================================
2023-06-12 16:06:19,398:INFO:Initializing create_model()
2023-06-12 16:06:19,398:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001623028AAA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7302, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622F132FB0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 0.05, 'reg_alpha': 0.0001, 'num_leaves': 20, 'n_estimators': 210, 'min_split_gain': 0.1, 'min_child_samples': 26, 'learning_rate': 0.0005, 'feature_fraction': 0.6, 'bagging_freq': 4, 'bagging_fraction': 0.4})
2023-06-12 16:06:19,398:INFO:Checking exceptions
2023-06-12 16:06:19,398:INFO:Importing libraries
2023-06-12 16:06:19,398:INFO:Copying training dataset
2023-06-12 16:06:19,398:INFO:Defining folds
2023-06-12 16:06:19,398:INFO:Declaring metric variables
2023-06-12 16:06:19,414:INFO:Importing untrained model
2023-06-12 16:06:19,414:INFO:Declaring custom model
2023-06-12 16:06:19,414:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 16:06:19,430:INFO:Starting cross validation
2023-06-12 16:06:19,430:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 16:08:48,519:INFO:Calculating mean and std
2023-06-12 16:08:48,519:INFO:Creating metrics dataframe
2023-06-12 16:08:48,519:INFO:Finalizing model
2023-06-12 16:08:48,735:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2023-06-12 16:08:48,735:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2023-06-12 16:08:48,735:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-06-12 16:09:08,844:INFO:Uploading results into container
2023-06-12 16:09:08,845:INFO:Uploading model into container now
2023-06-12 16:09:08,845:INFO:_master_model_container: 2
2023-06-12 16:09:08,846:INFO:_display_container: 3
2023-06-12 16:09:08,846:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=26, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=210, n_jobs=-1, num_leaves=20, objective=None,
               random_state=7302, reg_alpha=0.0001, reg_lambda=0.05,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-06-12 16:09:08,846:INFO:create_model() successfully completed......................................
2023-06-12 16:09:08,972:INFO:SubProcess create_model() end ==================================
2023-06-12 16:09:08,972:INFO:choose_better activated
2023-06-12 16:09:08,972:INFO:SubProcess create_model() called ==================================
2023-06-12 16:09:08,972:INFO:Initializing create_model()
2023-06-12 16:09:08,972:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001623028AAA0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7302, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 16:09:08,972:INFO:Checking exceptions
2023-06-12 16:09:08,972:INFO:Importing libraries
2023-06-12 16:09:08,972:INFO:Copying training dataset
2023-06-12 16:09:08,991:INFO:Defining folds
2023-06-12 16:09:08,991:INFO:Declaring metric variables
2023-06-12 16:09:08,991:INFO:Importing untrained model
2023-06-12 16:09:08,991:INFO:Declaring custom model
2023-06-12 16:09:08,992:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 16:09:08,993:INFO:Starting cross validation
2023-06-12 16:09:08,994:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 16:12:01,742:INFO:Calculating mean and std
2023-06-12 16:12:01,742:INFO:Creating metrics dataframe
2023-06-12 16:12:01,745:INFO:Finalizing model
2023-06-12 16:12:22,039:INFO:Uploading results into container
2023-06-12 16:12:22,040:INFO:Uploading model into container now
2023-06-12 16:12:22,041:INFO:_master_model_container: 3
2023-06-12 16:12:22,041:INFO:_display_container: 4
2023-06-12 16:12:22,042:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7302, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 16:12:22,042:INFO:create_model() successfully completed......................................
2023-06-12 16:12:22,185:INFO:SubProcess create_model() end ==================================
2023-06-12 16:12:22,186:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7302, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6341
2023-06-12 16:12:22,188:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=26, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=210, n_jobs=-1, num_leaves=20, objective=None,
               random_state=7302, reg_alpha=0.0001, reg_lambda=0.05,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) result for F1 is 0.6751
2023-06-12 16:12:22,188:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=26, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=210, n_jobs=-1, num_leaves=20, objective=None,
               random_state=7302, reg_alpha=0.0001, reg_lambda=0.05,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0) is best model
2023-06-12 16:12:22,189:INFO:choose_better completed
2023-06-12 16:12:22,189:INFO:Creating Dashboard logs
2023-06-12 16:12:22,195:INFO:Model: Light Gradient Boosting Machine
2023-06-12 16:12:22,299:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.0005, 'max_depth': -1, 'min_child_samples': 26, 'min_child_weight': 0.001, 'min_split_gain': 0.1, 'n_estimators': 210, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 7302, 'reg_alpha': 0.0001, 'reg_lambda': 0.05, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.6, 'bagging_freq': 4, 'bagging_fraction': 0.4}
2023-06-12 16:12:22,595:INFO:Initializing predict_model()
2023-06-12 16:12:22,595:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001623028AAA0>, estimator=LGBMClassifier(bagging_fraction=0.4, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=26, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=210, n_jobs=-1, num_leaves=20, objective=None,
               random_state=7302, reg_alpha=0.0001, reg_lambda=0.05,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000162301EDCF0>)
2023-06-12 16:12:22,596:INFO:Checking exceptions
2023-06-12 16:12:22,596:INFO:Preloading libraries
2023-06-12 16:12:38,258:INFO:_master_model_container: 3
2023-06-12 16:12:38,258:INFO:_display_container: 3
2023-06-12 16:12:38,259:INFO:LGBMClassifier(bagging_fraction=0.4, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=26, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=210, n_jobs=-1, num_leaves=20, objective=None,
               random_state=7302, reg_alpha=0.0001, reg_lambda=0.05,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-06-12 16:12:38,260:INFO:tune_model() successfully completed......................................
2023-06-12 16:12:53,632:INFO:Initializing finalize_model()
2023-06-12 16:12:53,633:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001623028AAA0>, estimator=LGBMClassifier(bagging_fraction=0.4, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=26, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=210, n_jobs=-1, num_leaves=20, objective=None,
               random_state=7302, reg_alpha=0.0001, reg_lambda=0.05,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-12 16:12:53,634:INFO:Finalizing LGBMClassifier(bagging_fraction=0.4, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=26, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=210, n_jobs=-1, num_leaves=20, objective=None,
               random_state=7302, reg_alpha=0.0001, reg_lambda=0.05,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0)
2023-06-12 16:12:53,640:INFO:Initializing create_model()
2023-06-12 16:12:53,640:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001623028AAA0>, estimator=LGBMClassifier(bagging_fraction=0.4, bagging_freq=4, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.6,
               importance_type='split', learning_rate=0.0005, max_depth=-1,
               min_child_samples=26, min_child_weight=0.001, min_split_gain=0.1,
               n_estimators=210, n_jobs=-1, num_leaves=20, objective=None,
               random_state=7302, reg_alpha=0.0001, reg_lambda=0.05,
               silent='warn', subsample=1.0, subsample_for_bin=200000,
               subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-12 16:12:53,641:INFO:Checking exceptions
2023-06-12 16:12:53,643:INFO:Importing libraries
2023-06-12 16:12:53,644:INFO:Copying training dataset
2023-06-12 16:12:53,644:INFO:Defining folds
2023-06-12 16:12:53,644:INFO:Declaring metric variables
2023-06-12 16:12:53,645:INFO:Importing untrained model
2023-06-12 16:12:53,645:INFO:Declaring custom model
2023-06-12 16:12:53,646:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 16:12:53,649:INFO:Cross validation set to False
2023-06-12 16:12:53,649:INFO:Fitting Model
2023-06-12 16:12:54,354:INFO:[LightGBM] [Warning] feature_fraction is set=0.6, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6
2023-06-12 16:12:54,354:INFO:[LightGBM] [Warning] bagging_fraction is set=0.4, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4
2023-06-12 16:12:54,354:INFO:[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4
2023-06-12 16:12:54,710:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.0005,
                                max_depth=-1, min_child_samples=26,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=210, n_jobs=-1, num_leaves=20,
                                objective=None, random_state=7302,
                                reg_alpha=0.0001, reg_lambda=0.05,
                                silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 16:12:54,711:INFO:create_model() successfully completed......................................
2023-06-12 16:12:54,860:INFO:Creating Dashboard logs
2023-06-12 16:12:54,861:INFO:Model: Light Gradient Boosting Machine
2023-06-12 16:12:54,960:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.0005, 'max_depth': -1, 'min_child_samples': 26, 'min_child_weight': 0.001, 'min_split_gain': 0.1, 'n_estimators': 210, 'n_jobs': -1, 'num_leaves': 20, 'objective': None, 'random_state': 7302, 'reg_alpha': 0.0001, 'reg_lambda': 0.05, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 0.6, 'bagging_freq': 4, 'bagging_fraction': 0.4}
2023-06-12 16:12:55,383:INFO:_master_model_container: 3
2023-06-12 16:12:55,384:INFO:_display_container: 3
2023-06-12 16:12:55,394:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.0005,
                                max_depth=-1, min_child_samples=26,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=210, n_jobs=-1, num_leaves=20,
                                objective=None, random_state=7302,
                                reg_alpha=0.0001, reg_lambda=0.05,
                                silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 16:12:55,394:INFO:finalize_model() successfully completed......................................
2023-06-12 16:12:55,560:INFO:Initializing save_model()
2023-06-12 16:12:55,560:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.0005,
                                max_depth=-1, min_child_samples=26,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=210, n_jobs=-1, num_leaves=20,
                                objective=None, random_state=7302,
                                reg_alpha=0.0001, reg_lambda=0.05,
                                silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=models/bs_predictor_heist, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 16:12:55,560:INFO:Adding model into prep_pipe
2023-06-12 16:12:55,561:WARNING:Only Model saved as it was a pipeline.
2023-06-12 16:12:55,592:INFO:models/bs_predictor_heist.pkl saved in current working directory
2023-06-12 16:12:55,612:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.0005,
                                max_depth=-1, min_child_samples=26,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=210, n_jobs=-1, num_leaves=20,
                                objective=None, random_state=7302,
                                reg_alpha=0.0001, reg_lambda=0.05,
                                silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 16:12:55,613:INFO:save_model() successfully completed......................................
2023-06-12 16:12:55,839:INFO:Initializing predict_model()
2023-06-12 16:12:55,839:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001623028AAA0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                colsample_bytree=1.0, feature_fraction=0.6,
                                importance_type='split', learning_rate=0.0005,
                                max_depth=-1, min_child_samples=26,
                                min_child_weight=0.001, min_split_gain=0.1,
                                n_estimators=210, n_jobs=-1, num_leaves=20,
                                objective=None, random_state=7302,
                                reg_alpha=0.0001, reg_lambda=0.05,
                                silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000162301EE8C0>)
2023-06-12 16:12:55,839:INFO:Checking exceptions
2023-06-12 16:12:55,839:INFO:Preloading libraries
2023-06-12 16:12:55,842:INFO:Set up data.
2023-06-12 16:12:55,858:INFO:Set up index.
2023-06-12 16:16:36,239:INFO:PyCaret ClassificationExperiment
2023-06-12 16:16:36,239:INFO:Logging name: clf-default-name
2023-06-12 16:16:36,240:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 16:16:36,240:INFO:version 3.0.2
2023-06-12 16:16:36,240:INFO:Initializing setup()
2023-06-12 16:16:36,240:INFO:self.USI: 22a3
2023-06-12 16:16:36,241:INFO:self._variable_keys: {'html_param', 'seed', 'gpu_n_jobs_param', 'X_train', 'exp_id', 'fix_imbalance', 'is_multiclass', 'USI', 'y_train', 'fold_shuffle_param', 'logging_param', 'gpu_param', 'y', 'fold_groups_param', 'target_param', 'X', 'idx', 'exp_name_log', '_available_plots', 'fold_generator', 'log_plots_param', 'pipeline', 'n_jobs_param', 'memory', 'X_test', '_ml_usecase', 'data', 'y_test'}
2023-06-12 16:16:36,241:INFO:Checking environment
2023-06-12 16:16:36,241:INFO:python_version: 3.10.10
2023-06-12 16:16:36,242:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 16:16:36,242:INFO:machine: AMD64
2023-06-12 16:16:36,242:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 16:16:36,248:INFO:Memory: svmem(total=17034072064, available=7187386368, percent=57.8, used=9846685696, free=7187386368)
2023-06-12 16:16:36,248:INFO:Physical Core: 2
2023-06-12 16:16:36,248:INFO:Logical Core: 4
2023-06-12 16:16:36,248:INFO:Checking libraries
2023-06-12 16:16:36,249:INFO:System:
2023-06-12 16:16:36,249:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 16:16:36,249:INFO:executable: c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 16:16:36,249:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 16:16:36,250:INFO:PyCaret required dependencies:
2023-06-12 16:16:36,250:INFO:                 pip: 23.1.2
2023-06-12 16:16:36,250:INFO:          setuptools: 65.5.0
2023-06-12 16:16:36,250:INFO:             pycaret: 3.0.2
2023-06-12 16:16:36,250:INFO:             IPython: 8.14.0
2023-06-12 16:16:36,251:INFO:          ipywidgets: 8.0.6
2023-06-12 16:16:36,251:INFO:                tqdm: 4.65.0
2023-06-12 16:16:36,251:INFO:               numpy: 1.23.5
2023-06-12 16:16:36,251:INFO:              pandas: 1.5.3
2023-06-12 16:16:36,251:INFO:              jinja2: 3.1.2
2023-06-12 16:16:36,251:INFO:               scipy: 1.10.1
2023-06-12 16:16:36,252:INFO:              joblib: 1.2.0
2023-06-12 16:16:36,252:INFO:             sklearn: 1.2.2
2023-06-12 16:16:36,252:INFO:                pyod: 1.0.9
2023-06-12 16:16:36,252:INFO:            imblearn: 0.10.1
2023-06-12 16:16:36,252:INFO:   category_encoders: 2.6.1
2023-06-12 16:16:36,253:INFO:            lightgbm: 3.3.5
2023-06-12 16:16:36,253:INFO:               numba: 0.57.0
2023-06-12 16:16:36,253:INFO:            requests: 2.31.0
2023-06-12 16:16:36,253:INFO:          matplotlib: 3.7.1
2023-06-12 16:16:36,253:INFO:          scikitplot: 0.3.7
2023-06-12 16:16:36,253:INFO:         yellowbrick: 1.5
2023-06-12 16:16:36,253:INFO:              plotly: 5.15.0
2023-06-12 16:16:36,253:INFO:             kaleido: 0.2.1
2023-06-12 16:16:36,254:INFO:         statsmodels: 0.14.0
2023-06-12 16:16:36,254:INFO:              sktime: 0.17.0
2023-06-12 16:16:36,254:INFO:               tbats: 1.1.3
2023-06-12 16:16:36,254:INFO:            pmdarima: 2.0.3
2023-06-12 16:16:36,254:INFO:              psutil: 5.9.5
2023-06-12 16:16:36,254:INFO:PyCaret optional dependencies:
2023-06-12 16:16:36,255:INFO:                shap: Not installed
2023-06-12 16:16:36,255:INFO:           interpret: Not installed
2023-06-12 16:16:36,255:INFO:                umap: Not installed
2023-06-12 16:16:36,255:INFO:    pandas_profiling: Not installed
2023-06-12 16:16:36,255:INFO:  explainerdashboard: Not installed
2023-06-12 16:16:36,255:INFO:             autoviz: Not installed
2023-06-12 16:16:36,256:INFO:           fairlearn: Not installed
2023-06-12 16:16:36,256:INFO:             xgboost: Not installed
2023-06-12 16:16:36,256:INFO:            catboost: Not installed
2023-06-12 16:16:36,256:INFO:              kmodes: Not installed
2023-06-12 16:16:36,256:INFO:             mlxtend: Not installed
2023-06-12 16:16:36,256:INFO:       statsforecast: Not installed
2023-06-12 16:16:36,256:INFO:        tune_sklearn: Not installed
2023-06-12 16:16:36,257:INFO:                 ray: Not installed
2023-06-12 16:16:36,257:INFO:            hyperopt: Not installed
2023-06-12 16:16:36,257:INFO:              optuna: Not installed
2023-06-12 16:16:36,257:INFO:               skopt: Not installed
2023-06-12 16:16:36,257:INFO:              mlflow: 2.4.1
2023-06-12 16:16:36,257:INFO:              gradio: Not installed
2023-06-12 16:16:36,258:INFO:             fastapi: Not installed
2023-06-12 16:16:36,258:INFO:             uvicorn: Not installed
2023-06-12 16:16:36,258:INFO:              m2cgen: Not installed
2023-06-12 16:16:36,258:INFO:           evidently: Not installed
2023-06-12 16:16:36,258:INFO:               fugue: Not installed
2023-06-12 16:16:36,258:INFO:           streamlit: 1.23.1
2023-06-12 16:16:36,258:INFO:             prophet: Not installed
2023-06-12 16:16:36,258:INFO:None
2023-06-12 16:16:36,259:INFO:Set up data.
2023-06-12 16:16:36,271:INFO:Set up train/test split.
2023-06-12 16:16:36,278:INFO:Set up index.
2023-06-12 16:16:36,278:INFO:Set up folding strategy.
2023-06-12 16:16:36,278:INFO:Assigning column types.
2023-06-12 16:16:36,283:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 16:16:36,334:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 16:16:36,335:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 16:16:36,363:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 16:16:36,364:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 16:16:36,409:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 16:16:36,410:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 16:16:36,439:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 16:16:36,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 16:16:36,440:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 16:16:36,485:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 16:16:36,513:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 16:16:36,513:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 16:16:36,559:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 16:16:36,587:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 16:16:36,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 16:16:36,588:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 16:16:36,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 16:16:36,661:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 16:16:36,735:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 16:16:36,736:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 16:16:36,738:INFO:Preparing preprocessing pipeline...
2023-06-12 16:16:36,739:INFO:Set up label encoding.
2023-06-12 16:16:36,739:INFO:Set up simple imputation.
2023-06-12 16:16:36,742:INFO:Set up encoding of categorical features.
2023-06-12 16:16:36,964:INFO:Finished creating preprocessing pipeline.
2023-06-12 16:16:36,971:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 16:16:36,971:INFO:Creating final display dataframe.
2023-06-12 16:16:37,406:INFO:Setup _display_container:                     Description             Value
0                    Session id              3564
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape         (278, 12)
5        Transformed data shape        (278, 340)
6   Transformed train set shape        (194, 340)
7    Transformed test set shape         (84, 340)
8              Numeric features                 4
9          Categorical features                 7
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              22a3
2023-06-12 16:16:37,491:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 16:16:37,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 16:16:37,565:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 16:16:37,565:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 16:16:37,566:INFO:Logging experiment in loggers
2023-06-12 16:16:37,745:INFO:SubProcess save_model() called ==================================
2023-06-12 16:16:37,758:INFO:Initializing save_model()
2023-06-12 16:16:37,758:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmpmgdgnxnn\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 16:16:37,758:INFO:Adding model into prep_pipe
2023-06-12 16:16:37,759:WARNING:Only Model saved as it was a pipeline.
2023-06-12 16:16:37,770:INFO:C:\Users\alniquia\AppData\Local\Temp\tmpmgdgnxnn\Transformation Pipeline.pkl saved in current working directory
2023-06-12 16:16:37,776:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2023-06-12 16:16:37,776:INFO:save_model() successfully completed......................................
2023-06-12 16:16:37,905:INFO:SubProcess save_model() end ==================================
2023-06-12 16:16:37,928:INFO:setup() successfully completed in 17.62s...............
2023-06-12 16:16:52,254:INFO:Initializing create_model()
2023-06-12 16:16:52,254:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162328F5000>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 16:16:52,255:INFO:Checking exceptions
2023-06-12 16:16:52,280:INFO:Importing libraries
2023-06-12 16:16:52,280:INFO:Copying training dataset
2023-06-12 16:16:52,293:INFO:Defining folds
2023-06-12 16:16:52,293:INFO:Declaring metric variables
2023-06-12 16:16:52,302:INFO:Importing untrained model
2023-06-12 16:16:52,311:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 16:16:52,326:INFO:Starting cross validation
2023-06-12 16:16:52,331:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 16:19:43,852:INFO:Calculating mean and std
2023-06-12 16:19:43,853:INFO:Creating metrics dataframe
2023-06-12 16:19:43,861:INFO:Finalizing model
2023-06-12 16:20:02,732:INFO:Creating Dashboard logs
2023-06-12 16:20:02,737:INFO:Model: Light Gradient Boosting Machine
2023-06-12 16:20:02,810:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 3564, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 16:20:03,068:INFO:Initializing predict_model()
2023-06-12 16:20:03,068:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162328F5000>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3564, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000016233519BD0>)
2023-06-12 16:20:03,069:INFO:Checking exceptions
2023-06-12 16:20:03,069:INFO:Preloading libraries
2023-06-12 16:20:18,201:INFO:Uploading results into container
2023-06-12 16:20:18,202:INFO:Uploading model into container now
2023-06-12 16:20:18,213:INFO:_master_model_container: 1
2023-06-12 16:20:18,214:INFO:_display_container: 2
2023-06-12 16:20:18,214:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3564, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 16:20:18,215:INFO:create_model() successfully completed......................................
2023-06-12 16:20:18,372:INFO:Initializing tune_model()
2023-06-12 16:20:18,373:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3564, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162328F5000>)
2023-06-12 16:20:18,373:INFO:Checking exceptions
2023-06-12 16:20:18,410:INFO:Copying training dataset
2023-06-12 16:20:18,416:INFO:Checking base model
2023-06-12 16:20:18,417:INFO:Base model : Light Gradient Boosting Machine
2023-06-12 16:20:18,424:INFO:Declaring metric variables
2023-06-12 16:20:18,432:INFO:Defining Hyperparameters
2023-06-12 16:20:18,585:INFO:Tuning with n_jobs=-1
2023-06-12 16:20:18,585:INFO:Initializing RandomizedSearchCV
2023-06-12 16:59:54,617:INFO:best_params: {'actual_estimator__reg_lambda': 10, 'actual_estimator__reg_alpha': 0.4, 'actual_estimator__num_leaves': 80, 'actual_estimator__n_estimators': 190, 'actual_estimator__min_split_gain': 0.7, 'actual_estimator__min_child_samples': 16, 'actual_estimator__learning_rate': 0.15, 'actual_estimator__feature_fraction': 1.0, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.5}
2023-06-12 16:59:54,618:INFO:Hyperparameter search completed
2023-06-12 16:59:54,618:INFO:SubProcess create_model() called ==================================
2023-06-12 16:59:54,619:INFO:Initializing create_model()
2023-06-12 16:59:54,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162328F5000>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3564, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622D2C76D0>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 10, 'reg_alpha': 0.4, 'num_leaves': 80, 'n_estimators': 190, 'min_split_gain': 0.7, 'min_child_samples': 16, 'learning_rate': 0.15, 'feature_fraction': 1.0, 'bagging_freq': 2, 'bagging_fraction': 0.5})
2023-06-12 16:59:54,619:INFO:Checking exceptions
2023-06-12 16:59:54,619:INFO:Importing libraries
2023-06-12 16:59:54,620:INFO:Copying training dataset
2023-06-12 16:59:54,624:INFO:Defining folds
2023-06-12 16:59:54,625:INFO:Declaring metric variables
2023-06-12 16:59:54,628:INFO:Importing untrained model
2023-06-12 16:59:54,628:INFO:Declaring custom model
2023-06-12 16:59:54,634:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 16:59:54,642:INFO:Starting cross validation
2023-06-12 16:59:54,645:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 17:02:56,474:INFO:Calculating mean and std
2023-06-12 17:02:56,475:INFO:Creating metrics dataframe
2023-06-12 17:02:56,482:INFO:Finalizing model
2023-06-12 17:02:56,645:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2023-06-12 17:02:56,645:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2023-06-12 17:02:56,645:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-06-12 17:03:21,973:INFO:Uploading results into container
2023-06-12 17:03:21,977:INFO:Uploading model into container now
2023-06-12 17:03:21,977:INFO:_master_model_container: 2
2023-06-12 17:03:21,978:INFO:_display_container: 3
2023-06-12 17:03:21,979:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.15, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=190, n_jobs=-1, num_leaves=80, objective=None,
               random_state=3564, reg_alpha=0.4, reg_lambda=10, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 17:03:21,979:INFO:create_model() successfully completed......................................
2023-06-12 17:03:22,165:INFO:SubProcess create_model() end ==================================
2023-06-12 17:03:22,166:INFO:choose_better activated
2023-06-12 17:03:22,178:INFO:SubProcess create_model() called ==================================
2023-06-12 17:03:22,179:INFO:Initializing create_model()
2023-06-12 17:03:22,197:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162328F5000>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3564, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 17:03:22,197:INFO:Checking exceptions
2023-06-12 17:03:22,200:INFO:Importing libraries
2023-06-12 17:03:22,200:INFO:Copying training dataset
2023-06-12 17:03:22,213:INFO:Defining folds
2023-06-12 17:03:22,213:INFO:Declaring metric variables
2023-06-12 17:03:22,213:INFO:Importing untrained model
2023-06-12 17:03:22,213:INFO:Declaring custom model
2023-06-12 17:03:22,215:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 17:03:22,215:INFO:Starting cross validation
2023-06-12 17:03:22,236:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 17:06:47,659:INFO:Calculating mean and std
2023-06-12 17:06:47,659:INFO:Creating metrics dataframe
2023-06-12 17:06:47,662:INFO:Finalizing model
2023-06-12 17:07:11,012:INFO:Uploading results into container
2023-06-12 17:07:11,020:INFO:Uploading model into container now
2023-06-12 17:07:11,020:INFO:_master_model_container: 3
2023-06-12 17:07:11,023:INFO:_display_container: 4
2023-06-12 17:07:11,024:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3564, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 17:07:11,024:INFO:create_model() successfully completed......................................
2023-06-12 17:07:11,178:INFO:SubProcess create_model() end ==================================
2023-06-12 17:07:11,179:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3564, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6352
2023-06-12 17:07:11,180:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.15, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=190, n_jobs=-1, num_leaves=80, objective=None,
               random_state=3564, reg_alpha=0.4, reg_lambda=10, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6771
2023-06-12 17:07:11,181:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.15, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=190, n_jobs=-1, num_leaves=80, objective=None,
               random_state=3564, reg_alpha=0.4, reg_lambda=10, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-06-12 17:07:11,181:INFO:choose_better completed
2023-06-12 17:07:11,181:INFO:Creating Dashboard logs
2023-06-12 17:07:11,185:INFO:Model: Light Gradient Boosting Machine
2023-06-12 17:07:11,312:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.15, 'max_depth': -1, 'min_child_samples': 16, 'min_child_weight': 0.001, 'min_split_gain': 0.7, 'n_estimators': 190, 'n_jobs': -1, 'num_leaves': 80, 'objective': None, 'random_state': 3564, 'reg_alpha': 0.4, 'reg_lambda': 10, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 1.0, 'bagging_freq': 2, 'bagging_fraction': 0.5}
2023-06-12 17:07:11,733:INFO:Initializing predict_model()
2023-06-12 17:07:11,733:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162328F5000>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.15, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=190, n_jobs=-1, num_leaves=80, objective=None,
               random_state=3564, reg_alpha=0.4, reg_lambda=10, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001623351AC20>)
2023-06-12 17:07:11,733:INFO:Checking exceptions
2023-06-12 17:07:11,733:INFO:Preloading libraries
2023-06-12 17:07:28,702:INFO:_master_model_container: 3
2023-06-12 17:07:28,702:INFO:_display_container: 3
2023-06-12 17:07:28,703:INFO:LGBMClassifier(bagging_fraction=0.5, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.15, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=190, n_jobs=-1, num_leaves=80, objective=None,
               random_state=3564, reg_alpha=0.4, reg_lambda=10, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 17:07:28,703:INFO:tune_model() successfully completed......................................
2023-06-12 17:07:47,884:INFO:Initializing finalize_model()
2023-06-12 17:07:47,885:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162328F5000>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.15, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=190, n_jobs=-1, num_leaves=80, objective=None,
               random_state=3564, reg_alpha=0.4, reg_lambda=10, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-12 17:07:47,886:INFO:Finalizing LGBMClassifier(bagging_fraction=0.5, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.15, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=190, n_jobs=-1, num_leaves=80, objective=None,
               random_state=3564, reg_alpha=0.4, reg_lambda=10, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 17:07:47,889:INFO:Initializing create_model()
2023-06-12 17:07:47,890:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162328F5000>, estimator=LGBMClassifier(bagging_fraction=0.5, bagging_freq=2, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,
               importance_type='split', learning_rate=0.15, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0.7,
               n_estimators=190, n_jobs=-1, num_leaves=80, objective=None,
               random_state=3564, reg_alpha=0.4, reg_lambda=10, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-12 17:07:47,890:INFO:Checking exceptions
2023-06-12 17:07:47,894:INFO:Importing libraries
2023-06-12 17:07:47,894:INFO:Copying training dataset
2023-06-12 17:07:47,895:INFO:Defining folds
2023-06-12 17:07:47,895:INFO:Declaring metric variables
2023-06-12 17:07:47,896:INFO:Importing untrained model
2023-06-12 17:07:47,896:INFO:Declaring custom model
2023-06-12 17:07:47,897:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 17:07:47,901:INFO:Cross validation set to False
2023-06-12 17:07:47,901:INFO:Fitting Model
2023-06-12 17:07:48,273:INFO:[LightGBM] [Warning] feature_fraction is set=1.0, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=1.0
2023-06-12 17:07:48,273:INFO:[LightGBM] [Warning] bagging_fraction is set=0.5, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5
2023-06-12 17:07:48,273:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2023-06-12 17:07:48,341:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.15,
                                max_depth=-1, min_child_samples=16,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=190, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=3564,
                                reg_alpha=0.4, reg_lambda=10, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-06-12 17:07:48,341:INFO:create_model() successfully completed......................................
2023-06-12 17:07:48,492:INFO:Creating Dashboard logs
2023-06-12 17:07:48,493:INFO:Model: Light Gradient Boosting Machine
2023-06-12 17:07:48,574:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.15, 'max_depth': -1, 'min_child_samples': 16, 'min_child_weight': 0.001, 'min_split_gain': 0.7, 'n_estimators': 190, 'n_jobs': -1, 'num_leaves': 80, 'objective': None, 'random_state': 3564, 'reg_alpha': 0.4, 'reg_lambda': 10, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'feature_fraction': 1.0, 'bagging_freq': 2, 'bagging_fraction': 0.5}
2023-06-12 17:07:49,063:INFO:_master_model_container: 3
2023-06-12 17:07:49,064:INFO:_display_container: 3
2023-06-12 17:07:49,075:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.15,
                                max_depth=-1, min_child_samples=16,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=190, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=3564,
                                reg_alpha=0.4, reg_lambda=10, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-06-12 17:07:49,075:INFO:finalize_model() successfully completed......................................
2023-06-12 17:07:49,234:INFO:Initializing save_model()
2023-06-12 17:07:49,235:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.15,
                                max_depth=-1, min_child_samples=16,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=190, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=3564,
                                reg_alpha=0.4, reg_lambda=10, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), model_name=models/bs_predictor_hotZone, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                                                    'battle_team1_player1_brawler_name',
                                                                    'battle_team1_player2_brawler_name',
                                                                    'battle_team1_player3_brawler_name',
                                                                    'battle_team2_player1_brawler_name',
                                                                    'battle_team2_player2_brawler_name',
                                                                    'battle_team2_player3_brawler_name'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 17:07:49,235:INFO:Adding model into prep_pipe
2023-06-12 17:07:49,235:WARNING:Only Model saved as it was a pipeline.
2023-06-12 17:07:49,269:INFO:models/bs_predictor_hotZone.pkl saved in current working directory
2023-06-12 17:07:49,289:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.15,
                                max_depth=-1, min_child_samples=16,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=190, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=3564,
                                reg_alpha=0.4, reg_lambda=10, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-06-12 17:07:49,289:INFO:save_model() successfully completed......................................
2023-06-12 17:07:49,620:INFO:Initializing predict_model()
2023-06-12 17:07:49,621:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162328F5000>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                                colsample_bytree=1.0, feature_fraction=1.0,
                                importance_type='split', learning_rate=0.15,
                                max_depth=-1, min_child_samples=16,
                                min_child_weight=0.001, min_split_gain=0.7,
                                n_estimators=190, n_jobs=-1, num_leaves=80,
                                objective=None, random_state=3564,
                                reg_alpha=0.4, reg_lambda=10, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001622B8A7400>)
2023-06-12 17:07:49,621:INFO:Checking exceptions
2023-06-12 17:07:49,621:INFO:Preloading libraries
2023-06-12 17:07:49,624:INFO:Set up data.
2023-06-12 17:07:49,642:INFO:Set up index.
2023-06-12 17:20:44,047:INFO:PyCaret ClassificationExperiment
2023-06-12 17:20:44,047:INFO:Logging name: clf-default-name
2023-06-12 17:20:44,047:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 17:20:44,047:INFO:version 3.0.2
2023-06-12 17:20:44,047:INFO:Initializing setup()
2023-06-12 17:20:44,048:INFO:self.USI: 5b33
2023-06-12 17:20:44,048:INFO:self._variable_keys: {'html_param', 'seed', 'gpu_n_jobs_param', 'X_train', 'exp_id', 'fix_imbalance', 'is_multiclass', 'USI', 'y_train', 'fold_shuffle_param', 'logging_param', 'gpu_param', 'y', 'fold_groups_param', 'target_param', 'X', 'idx', 'exp_name_log', '_available_plots', 'fold_generator', 'log_plots_param', 'pipeline', 'n_jobs_param', 'memory', 'X_test', '_ml_usecase', 'data', 'y_test'}
2023-06-12 17:20:44,048:INFO:Checking environment
2023-06-12 17:20:44,048:INFO:python_version: 3.10.10
2023-06-12 17:20:44,048:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 17:20:44,049:INFO:machine: AMD64
2023-06-12 17:20:44,049:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 17:20:44,053:INFO:Memory: svmem(total=17034072064, available=6415212544, percent=62.3, used=10618859520, free=6415212544)
2023-06-12 17:20:44,053:INFO:Physical Core: 2
2023-06-12 17:20:44,053:INFO:Logical Core: 4
2023-06-12 17:20:44,053:INFO:Checking libraries
2023-06-12 17:20:44,053:INFO:System:
2023-06-12 17:20:44,053:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 17:20:44,053:INFO:executable: c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 17:20:44,053:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 17:20:44,053:INFO:PyCaret required dependencies:
2023-06-12 17:20:44,053:INFO:                 pip: 23.1.2
2023-06-12 17:20:44,054:INFO:          setuptools: 65.5.0
2023-06-12 17:20:44,054:INFO:             pycaret: 3.0.2
2023-06-12 17:20:44,054:INFO:             IPython: 8.14.0
2023-06-12 17:20:44,054:INFO:          ipywidgets: 8.0.6
2023-06-12 17:20:44,054:INFO:                tqdm: 4.65.0
2023-06-12 17:20:44,054:INFO:               numpy: 1.23.5
2023-06-12 17:20:44,054:INFO:              pandas: 1.5.3
2023-06-12 17:20:44,054:INFO:              jinja2: 3.1.2
2023-06-12 17:20:44,054:INFO:               scipy: 1.10.1
2023-06-12 17:20:44,054:INFO:              joblib: 1.2.0
2023-06-12 17:20:44,054:INFO:             sklearn: 1.2.2
2023-06-12 17:20:44,054:INFO:                pyod: 1.0.9
2023-06-12 17:20:44,054:INFO:            imblearn: 0.10.1
2023-06-12 17:20:44,054:INFO:   category_encoders: 2.6.1
2023-06-12 17:20:44,054:INFO:            lightgbm: 3.3.5
2023-06-12 17:20:44,054:INFO:               numba: 0.57.0
2023-06-12 17:20:44,054:INFO:            requests: 2.31.0
2023-06-12 17:20:44,054:INFO:          matplotlib: 3.7.1
2023-06-12 17:20:44,055:INFO:          scikitplot: 0.3.7
2023-06-12 17:20:44,055:INFO:         yellowbrick: 1.5
2023-06-12 17:20:44,055:INFO:              plotly: 5.15.0
2023-06-12 17:20:44,055:INFO:             kaleido: 0.2.1
2023-06-12 17:20:44,055:INFO:         statsmodels: 0.14.0
2023-06-12 17:20:44,055:INFO:              sktime: 0.17.0
2023-06-12 17:20:44,055:INFO:               tbats: 1.1.3
2023-06-12 17:20:44,055:INFO:            pmdarima: 2.0.3
2023-06-12 17:20:44,055:INFO:              psutil: 5.9.5
2023-06-12 17:20:44,055:INFO:PyCaret optional dependencies:
2023-06-12 17:20:44,055:INFO:                shap: Not installed
2023-06-12 17:20:44,055:INFO:           interpret: Not installed
2023-06-12 17:20:44,055:INFO:                umap: Not installed
2023-06-12 17:20:44,055:INFO:    pandas_profiling: Not installed
2023-06-12 17:20:44,055:INFO:  explainerdashboard: Not installed
2023-06-12 17:20:44,055:INFO:             autoviz: Not installed
2023-06-12 17:20:44,056:INFO:           fairlearn: Not installed
2023-06-12 17:20:44,056:INFO:             xgboost: Not installed
2023-06-12 17:20:44,056:INFO:            catboost: Not installed
2023-06-12 17:20:44,056:INFO:              kmodes: Not installed
2023-06-12 17:20:44,056:INFO:             mlxtend: Not installed
2023-06-12 17:20:44,056:INFO:       statsforecast: Not installed
2023-06-12 17:20:44,056:INFO:        tune_sklearn: Not installed
2023-06-12 17:20:44,056:INFO:                 ray: Not installed
2023-06-12 17:20:44,056:INFO:            hyperopt: Not installed
2023-06-12 17:20:44,056:INFO:              optuna: Not installed
2023-06-12 17:20:44,056:INFO:               skopt: Not installed
2023-06-12 17:20:44,056:INFO:              mlflow: 2.4.1
2023-06-12 17:20:44,056:INFO:              gradio: Not installed
2023-06-12 17:20:44,056:INFO:             fastapi: Not installed
2023-06-12 17:20:44,056:INFO:             uvicorn: Not installed
2023-06-12 17:20:44,056:INFO:              m2cgen: Not installed
2023-06-12 17:20:44,056:INFO:           evidently: Not installed
2023-06-12 17:20:44,057:INFO:               fugue: Not installed
2023-06-12 17:20:44,057:INFO:           streamlit: 1.23.1
2023-06-12 17:20:44,057:INFO:             prophet: Not installed
2023-06-12 17:20:44,057:INFO:None
2023-06-12 17:20:44,057:INFO:Set up data.
2023-06-12 17:20:44,127:INFO:Set up train/test split.
2023-06-12 17:20:44,225:INFO:Set up index.
2023-06-12 17:20:44,228:INFO:Set up folding strategy.
2023-06-12 17:20:44,228:INFO:Assigning column types.
2023-06-12 17:20:44,276:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 17:20:44,322:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 17:20:44,323:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 17:20:44,351:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 17:20:44,352:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 17:20:44,401:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 17:20:44,402:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 17:20:44,430:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 17:20:44,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 17:20:44,431:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 17:20:44,476:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 17:20:44,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 17:20:44,508:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 17:20:44,555:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 17:20:44,587:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 17:20:44,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 17:20:44,587:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 17:20:44,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 17:20:44,661:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 17:20:44,741:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 17:20:44,741:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 17:20:44,742:INFO:Preparing preprocessing pipeline...
2023-06-12 17:20:44,751:INFO:Set up label encoding.
2023-06-12 17:20:44,751:INFO:Set up simple imputation.
2023-06-12 17:20:44,795:INFO:Set up encoding of categorical features.
2023-06-12 17:20:44,805:INFO:Set up column name cleaning.
2023-06-12 17:20:45,360:INFO:Finished creating preprocessing pipeline.
2023-06-12 17:20:45,368:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-12 17:20:45,369:INFO:Creating final display dataframe.
2023-06-12 17:20:46,286:INFO:Setup _display_container:                     Description             Value
0                    Session id              2557
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape      (62905, 142)
5        Transformed data shape      (62905, 146)
6   Transformed train set shape      (44033, 146)
7    Transformed test set shape      (18872, 146)
8              Numeric features               140
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              5b33
2023-06-12 17:20:46,393:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 17:20:46,394:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 17:20:46,478:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 17:20:46,478:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 17:20:46,479:INFO:Logging experiment in loggers
2023-06-12 17:20:46,701:INFO:SubProcess save_model() called ==================================
2023-06-12 17:20:46,728:INFO:Initializing save_model()
2023-06-12 17:20:46,728:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmpaw0avry_\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 17:20:46,728:INFO:Adding model into prep_pipe
2023-06-12 17:20:46,728:WARNING:Only Model saved as it was a pipeline.
2023-06-12 17:20:46,741:INFO:C:\Users\alniquia\AppData\Local\Temp\tmpaw0avry_\Transformation Pipeline.pkl saved in current working directory
2023-06-12 17:20:46,752:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-12 17:20:46,752:INFO:save_model() successfully completed......................................
2023-06-12 17:20:46,910:INFO:SubProcess save_model() end ==================================
2023-06-12 17:20:46,931:INFO:setup() successfully completed in 18.41s...............
2023-06-12 17:21:02,578:INFO:Initializing compare_models()
2023-06-12 17:21:02,579:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-06-12 17:21:02,579:INFO:Checking exceptions
2023-06-12 17:21:02,660:INFO:Preparing display monitor
2023-06-12 17:21:02,689:INFO:Initializing Logistic Regression
2023-06-12 17:21:02,690:INFO:Total runtime is 1.6597906748453774e-05 minutes
2023-06-12 17:21:02,694:INFO:SubProcess create_model() called ==================================
2023-06-12 17:21:02,695:INFO:Initializing create_model()
2023-06-12 17:21:02,695:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622F16FF10>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 17:21:02,695:INFO:Checking exceptions
2023-06-12 17:21:02,695:INFO:Importing libraries
2023-06-12 17:21:02,696:INFO:Copying training dataset
2023-06-12 17:21:02,820:INFO:Defining folds
2023-06-12 17:21:02,821:INFO:Declaring metric variables
2023-06-12 17:21:02,825:INFO:Importing untrained model
2023-06-12 17:21:02,829:INFO:Logistic Regression Imported successfully
2023-06-12 17:21:02,836:INFO:Starting cross validation
2023-06-12 17:21:02,841:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 17:24:19,795:INFO:Calculating mean and std
2023-06-12 17:24:19,796:INFO:Creating metrics dataframe
2023-06-12 17:24:39,699:INFO:Uploading results into container
2023-06-12 17:24:39,699:INFO:Uploading model into container now
2023-06-12 17:24:39,700:INFO:_master_model_container: 1
2023-06-12 17:24:39,700:INFO:_display_container: 2
2023-06-12 17:24:39,701:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=2557, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-06-12 17:24:39,701:INFO:create_model() successfully completed......................................
2023-06-12 17:24:39,825:INFO:SubProcess create_model() end ==================================
2023-06-12 17:24:39,825:INFO:Creating metrics dataframe
2023-06-12 17:24:39,840:INFO:Initializing K Neighbors Classifier
2023-06-12 17:24:39,840:INFO:Total runtime is 3.619192318121592 minutes
2023-06-12 17:24:39,840:INFO:SubProcess create_model() called ==================================
2023-06-12 17:24:39,840:INFO:Initializing create_model()
2023-06-12 17:24:39,840:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622F16FF10>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 17:24:39,840:INFO:Checking exceptions
2023-06-12 17:24:39,840:INFO:Importing libraries
2023-06-12 17:24:39,840:INFO:Copying training dataset
2023-06-12 17:24:40,001:INFO:Defining folds
2023-06-12 17:24:40,001:INFO:Declaring metric variables
2023-06-12 17:24:40,010:INFO:Importing untrained model
2023-06-12 17:24:40,021:INFO:K Neighbors Classifier Imported successfully
2023-06-12 17:24:40,035:INFO:Starting cross validation
2023-06-12 17:24:40,038:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 17:25:19,096:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 17:28:02,116:INFO:Calculating mean and std
2023-06-12 17:28:02,118:INFO:Creating metrics dataframe
2023-06-12 17:28:23,641:INFO:Uploading results into container
2023-06-12 17:28:23,642:INFO:Uploading model into container now
2023-06-12 17:28:23,643:INFO:_master_model_container: 2
2023-06-12 17:28:23,643:INFO:_display_container: 2
2023-06-12 17:28:23,644:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-06-12 17:28:23,644:INFO:create_model() successfully completed......................................
2023-06-12 17:28:23,790:INFO:SubProcess create_model() end ==================================
2023-06-12 17:28:23,790:INFO:Creating metrics dataframe
2023-06-12 17:28:23,803:INFO:Initializing Naive Bayes
2023-06-12 17:28:23,803:INFO:Total runtime is 7.351907237370809 minutes
2023-06-12 17:28:23,807:INFO:SubProcess create_model() called ==================================
2023-06-12 17:28:23,809:INFO:Initializing create_model()
2023-06-12 17:28:23,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622F16FF10>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 17:28:23,809:INFO:Checking exceptions
2023-06-12 17:28:23,809:INFO:Importing libraries
2023-06-12 17:28:23,810:INFO:Copying training dataset
2023-06-12 17:28:23,948:INFO:Defining folds
2023-06-12 17:28:23,948:INFO:Declaring metric variables
2023-06-12 17:28:23,952:INFO:Importing untrained model
2023-06-12 17:28:23,956:INFO:Naive Bayes Imported successfully
2023-06-12 17:28:23,966:INFO:Starting cross validation
2023-06-12 17:28:23,970:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 17:28:56,243:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 17:28:56,246:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 17:31:34,559:INFO:Calculating mean and std
2023-06-12 17:31:34,561:INFO:Creating metrics dataframe
2023-06-12 17:31:54,707:INFO:Uploading results into container
2023-06-12 17:31:54,708:INFO:Uploading model into container now
2023-06-12 17:31:54,709:INFO:_master_model_container: 3
2023-06-12 17:31:54,709:INFO:_display_container: 2
2023-06-12 17:31:54,709:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-06-12 17:31:54,709:INFO:create_model() successfully completed......................................
2023-06-12 17:31:54,853:INFO:SubProcess create_model() end ==================================
2023-06-12 17:31:54,853:INFO:Creating metrics dataframe
2023-06-12 17:31:54,865:INFO:Initializing Decision Tree Classifier
2023-06-12 17:31:54,866:INFO:Total runtime is 10.869621169567107 minutes
2023-06-12 17:31:54,870:INFO:SubProcess create_model() called ==================================
2023-06-12 17:31:54,870:INFO:Initializing create_model()
2023-06-12 17:31:54,870:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622F16FF10>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 17:31:54,871:INFO:Checking exceptions
2023-06-12 17:31:54,871:INFO:Importing libraries
2023-06-12 17:31:54,871:INFO:Copying training dataset
2023-06-12 17:31:55,011:INFO:Defining folds
2023-06-12 17:31:55,012:INFO:Declaring metric variables
2023-06-12 17:31:55,017:INFO:Importing untrained model
2023-06-12 17:31:55,022:INFO:Decision Tree Classifier Imported successfully
2023-06-12 17:31:55,030:INFO:Starting cross validation
2023-06-12 17:31:55,034:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 17:32:29,301:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 17:32:29,302:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 17:32:29,662:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 17:32:29,669:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 17:35:21,338:INFO:Calculating mean and std
2023-06-12 17:35:21,340:INFO:Creating metrics dataframe
2023-06-12 17:35:42,700:INFO:Uploading results into container
2023-06-12 17:35:42,700:INFO:Uploading model into container now
2023-06-12 17:35:42,700:INFO:_master_model_container: 4
2023-06-12 17:35:42,700:INFO:_display_container: 2
2023-06-12 17:35:42,700:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=2557, splitter='best')
2023-06-12 17:35:42,700:INFO:create_model() successfully completed......................................
2023-06-12 17:35:42,842:INFO:SubProcess create_model() end ==================================
2023-06-12 17:35:42,842:INFO:Creating metrics dataframe
2023-06-12 17:35:42,842:INFO:Initializing SVM - Linear Kernel
2023-06-12 17:35:42,842:INFO:Total runtime is 14.669212766488393 minutes
2023-06-12 17:35:42,858:INFO:SubProcess create_model() called ==================================
2023-06-12 17:35:42,858:INFO:Initializing create_model()
2023-06-12 17:35:42,859:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622F16FF10>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 17:35:42,859:INFO:Checking exceptions
2023-06-12 17:35:42,859:INFO:Importing libraries
2023-06-12 17:35:42,859:INFO:Copying training dataset
2023-06-12 17:35:42,987:INFO:Defining folds
2023-06-12 17:35:42,987:INFO:Declaring metric variables
2023-06-12 17:35:42,991:INFO:Importing untrained model
2023-06-12 17:35:42,996:INFO:SVM - Linear Kernel Imported successfully
2023-06-12 17:35:43,007:INFO:Starting cross validation
2023-06-12 17:35:43,010:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 17:35:46,093:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-12 17:35:46,123:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-12 17:35:46,139:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-12 17:35:46,378:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-12 17:36:13,628:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 17:36:15,966:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-12 17:36:16,320:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-12 17:36:17,070:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-12 17:36:17,246:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-12 17:36:51,111:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-12 17:36:52,987:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-06-12 17:38:48,283:INFO:Calculating mean and std
2023-06-12 17:38:48,284:INFO:Creating metrics dataframe
2023-06-12 17:39:08,030:INFO:Uploading results into container
2023-06-12 17:39:08,031:INFO:Uploading model into container now
2023-06-12 17:39:08,032:INFO:_master_model_container: 5
2023-06-12 17:39:08,032:INFO:_display_container: 2
2023-06-12 17:39:08,032:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=2557, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-06-12 17:39:08,033:INFO:create_model() successfully completed......................................
2023-06-12 17:39:08,175:INFO:SubProcess create_model() end ==================================
2023-06-12 17:39:08,175:INFO:Creating metrics dataframe
2023-06-12 17:39:08,187:INFO:Initializing Ridge Classifier
2023-06-12 17:39:08,187:INFO:Total runtime is 18.09163095553716 minutes
2023-06-12 17:39:08,193:INFO:SubProcess create_model() called ==================================
2023-06-12 17:39:08,193:INFO:Initializing create_model()
2023-06-12 17:39:08,193:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622F16FF10>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 17:39:08,193:INFO:Checking exceptions
2023-06-12 17:39:08,193:INFO:Importing libraries
2023-06-12 17:39:08,193:INFO:Copying training dataset
2023-06-12 17:39:08,329:INFO:Defining folds
2023-06-12 17:39:08,329:INFO:Declaring metric variables
2023-06-12 17:39:08,333:INFO:Importing untrained model
2023-06-12 17:39:08,337:INFO:Ridge Classifier Imported successfully
2023-06-12 17:39:08,347:INFO:Starting cross validation
2023-06-12 17:39:08,352:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 17:39:09,791:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-12 17:39:09,844:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-12 17:39:09,850:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-12 17:39:09,882:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-12 17:39:39,454:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-12 17:39:39,514:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-12 17:39:39,515:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-12 17:39:39,713:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-12 17:40:11,363:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-12 17:40:12,169:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-06-12 17:42:03,839:INFO:Calculating mean and std
2023-06-12 17:42:03,841:INFO:Creating metrics dataframe
2023-06-12 17:42:23,731:INFO:Uploading results into container
2023-06-12 17:42:23,732:INFO:Uploading model into container now
2023-06-12 17:42:23,732:INFO:_master_model_container: 6
2023-06-12 17:42:23,733:INFO:_display_container: 2
2023-06-12 17:42:23,733:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=2557, solver='auto',
                tol=0.0001)
2023-06-12 17:42:23,733:INFO:create_model() successfully completed......................................
2023-06-12 17:42:23,877:INFO:SubProcess create_model() end ==================================
2023-06-12 17:42:23,877:INFO:Creating metrics dataframe
2023-06-12 17:42:23,893:INFO:Initializing Random Forest Classifier
2023-06-12 17:42:23,894:INFO:Total runtime is 21.353426778316496 minutes
2023-06-12 17:42:23,899:INFO:SubProcess create_model() called ==================================
2023-06-12 17:42:23,899:INFO:Initializing create_model()
2023-06-12 17:42:23,899:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622F16FF10>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 17:42:23,900:INFO:Checking exceptions
2023-06-12 17:42:23,900:INFO:Importing libraries
2023-06-12 17:42:23,900:INFO:Copying training dataset
2023-06-12 17:42:24,059:INFO:Defining folds
2023-06-12 17:42:24,060:INFO:Declaring metric variables
2023-06-12 17:42:24,064:INFO:Importing untrained model
2023-06-12 17:42:24,068:INFO:Random Forest Classifier Imported successfully
2023-06-12 17:42:24,078:INFO:Starting cross validation
2023-06-12 17:42:24,082:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 17:42:52,701:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 17:42:52,802:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 17:42:54,265:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 17:42:54,740:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 17:43:54,308:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 17:43:54,626:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 17:43:55,236:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 17:43:56,112:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 17:43:56,240:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 17:43:57,253:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 17:44:43,985:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 17:46:30,161:INFO:Calculating mean and std
2023-06-12 17:46:30,162:INFO:Creating metrics dataframe
2023-06-12 17:46:49,447:INFO:Uploading results into container
2023-06-12 17:46:49,449:INFO:Uploading model into container now
2023-06-12 17:46:49,450:INFO:_master_model_container: 7
2023-06-12 17:46:49,450:INFO:_display_container: 2
2023-06-12 17:46:49,451:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=2557, verbose=0, warm_start=False)
2023-06-12 17:46:49,451:INFO:create_model() successfully completed......................................
2023-06-12 17:46:49,590:INFO:SubProcess create_model() end ==================================
2023-06-12 17:46:49,591:INFO:Creating metrics dataframe
2023-06-12 17:46:49,605:INFO:Initializing Quadratic Discriminant Analysis
2023-06-12 17:46:49,605:INFO:Total runtime is 25.78193254470825 minutes
2023-06-12 17:46:49,609:INFO:SubProcess create_model() called ==================================
2023-06-12 17:46:49,610:INFO:Initializing create_model()
2023-06-12 17:46:49,610:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622F16FF10>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 17:46:49,610:INFO:Checking exceptions
2023-06-12 17:46:49,610:INFO:Importing libraries
2023-06-12 17:46:49,610:INFO:Copying training dataset
2023-06-12 17:46:49,743:INFO:Defining folds
2023-06-12 17:46:49,743:INFO:Declaring metric variables
2023-06-12 17:46:49,747:INFO:Importing untrained model
2023-06-12 17:46:49,752:INFO:Quadratic Discriminant Analysis Imported successfully
2023-06-12 17:46:49,760:INFO:Starting cross validation
2023-06-12 17:46:49,762:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 17:46:51,934:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-12 17:46:52,007:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-12 17:46:52,020:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-12 17:47:24,992:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-12 17:47:25,000:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-12 17:47:25,076:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-12 17:47:25,121:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-12 17:47:58,272:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-12 17:47:59,456:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-06-12 17:50:41,483:INFO:Calculating mean and std
2023-06-12 17:50:41,484:INFO:Creating metrics dataframe
2023-06-12 17:51:10,136:INFO:Uploading results into container
2023-06-12 17:51:10,138:INFO:Uploading model into container now
2023-06-12 17:51:10,138:INFO:_master_model_container: 8
2023-06-12 17:51:10,139:INFO:_display_container: 2
2023-06-12 17:51:10,139:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-06-12 17:51:10,140:INFO:create_model() successfully completed......................................
2023-06-12 17:51:10,340:INFO:SubProcess create_model() end ==================================
2023-06-12 17:51:10,340:INFO:Creating metrics dataframe
2023-06-12 17:51:10,361:INFO:Initializing Ada Boost Classifier
2023-06-12 17:51:10,361:INFO:Total runtime is 30.127865624427795 minutes
2023-06-12 17:51:10,369:INFO:SubProcess create_model() called ==================================
2023-06-12 17:51:10,370:INFO:Initializing create_model()
2023-06-12 17:51:10,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622F16FF10>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 17:51:10,370:INFO:Checking exceptions
2023-06-12 17:51:10,370:INFO:Importing libraries
2023-06-12 17:51:10,370:INFO:Copying training dataset
2023-06-12 17:51:10,551:INFO:Defining folds
2023-06-12 17:51:10,551:INFO:Declaring metric variables
2023-06-12 17:51:10,555:INFO:Importing untrained model
2023-06-12 17:51:10,559:INFO:Ada Boost Classifier Imported successfully
2023-06-12 17:51:10,573:INFO:Starting cross validation
2023-06-12 17:51:10,577:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 17:55:14,006:INFO:Calculating mean and std
2023-06-12 17:55:14,008:INFO:Creating metrics dataframe
2023-06-12 17:55:42,243:INFO:Uploading results into container
2023-06-12 17:55:42,244:INFO:Uploading model into container now
2023-06-12 17:55:42,245:INFO:_master_model_container: 9
2023-06-12 17:55:42,245:INFO:_display_container: 2
2023-06-12 17:55:42,245:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=2557)
2023-06-12 17:55:42,246:INFO:create_model() successfully completed......................................
2023-06-12 17:55:42,435:INFO:SubProcess create_model() end ==================================
2023-06-12 17:55:42,435:INFO:Creating metrics dataframe
2023-06-12 17:55:42,459:INFO:Initializing Gradient Boosting Classifier
2023-06-12 17:55:42,459:INFO:Total runtime is 34.662827014923096 minutes
2023-06-12 17:55:42,464:INFO:SubProcess create_model() called ==================================
2023-06-12 17:55:42,464:INFO:Initializing create_model()
2023-06-12 17:55:42,465:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622F16FF10>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 17:55:42,465:INFO:Checking exceptions
2023-06-12 17:55:42,465:INFO:Importing libraries
2023-06-12 17:55:42,465:INFO:Copying training dataset
2023-06-12 17:55:42,650:INFO:Defining folds
2023-06-12 17:55:42,650:INFO:Declaring metric variables
2023-06-12 17:55:42,659:INFO:Importing untrained model
2023-06-12 17:55:42,663:INFO:Gradient Boosting Classifier Imported successfully
2023-06-12 17:55:42,675:INFO:Starting cross validation
2023-06-12 17:55:42,679:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 18:00:04,165:INFO:Calculating mean and std
2023-06-12 18:00:04,167:INFO:Creating metrics dataframe
2023-06-12 18:00:27,325:INFO:Uploading results into container
2023-06-12 18:00:27,326:INFO:Uploading model into container now
2023-06-12 18:00:27,326:INFO:_master_model_container: 10
2023-06-12 18:00:27,327:INFO:_display_container: 2
2023-06-12 18:00:27,327:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=2557, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-06-12 18:00:27,328:INFO:create_model() successfully completed......................................
2023-06-12 18:00:27,498:INFO:SubProcess create_model() end ==================================
2023-06-12 18:00:27,498:INFO:Creating metrics dataframe
2023-06-12 18:00:27,526:INFO:Initializing Linear Discriminant Analysis
2023-06-12 18:00:27,527:INFO:Total runtime is 39.41396232446035 minutes
2023-06-12 18:00:27,531:INFO:SubProcess create_model() called ==================================
2023-06-12 18:00:27,531:INFO:Initializing create_model()
2023-06-12 18:00:27,531:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622F16FF10>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 18:00:27,531:INFO:Checking exceptions
2023-06-12 18:00:27,531:INFO:Importing libraries
2023-06-12 18:00:27,532:INFO:Copying training dataset
2023-06-12 18:00:27,695:INFO:Defining folds
2023-06-12 18:00:27,695:INFO:Declaring metric variables
2023-06-12 18:00:27,700:INFO:Importing untrained model
2023-06-12 18:00:27,704:INFO:Linear Discriminant Analysis Imported successfully
2023-06-12 18:00:27,716:INFO:Starting cross validation
2023-06-12 18:00:27,720:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 18:03:33,593:INFO:Calculating mean and std
2023-06-12 18:03:33,595:INFO:Creating metrics dataframe
2023-06-12 18:03:54,394:INFO:Uploading results into container
2023-06-12 18:03:54,395:INFO:Uploading model into container now
2023-06-12 18:03:54,396:INFO:_master_model_container: 11
2023-06-12 18:03:54,396:INFO:_display_container: 2
2023-06-12 18:03:54,397:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-06-12 18:03:54,397:INFO:create_model() successfully completed......................................
2023-06-12 18:03:54,538:INFO:SubProcess create_model() end ==================================
2023-06-12 18:03:54,539:INFO:Creating metrics dataframe
2023-06-12 18:03:54,554:INFO:Initializing Extra Trees Classifier
2023-06-12 18:03:54,554:INFO:Total runtime is 42.864421502749124 minutes
2023-06-12 18:03:54,558:INFO:SubProcess create_model() called ==================================
2023-06-12 18:03:54,558:INFO:Initializing create_model()
2023-06-12 18:03:54,559:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622F16FF10>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 18:03:54,559:INFO:Checking exceptions
2023-06-12 18:03:54,559:INFO:Importing libraries
2023-06-12 18:03:54,559:INFO:Copying training dataset
2023-06-12 18:03:54,701:INFO:Defining folds
2023-06-12 18:03:54,701:INFO:Declaring metric variables
2023-06-12 18:03:54,706:INFO:Importing untrained model
2023-06-12 18:03:54,710:INFO:Extra Trees Classifier Imported successfully
2023-06-12 18:03:54,719:INFO:Starting cross validation
2023-06-12 18:03:54,722:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 18:04:38,449:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:04:39,312:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:04:40,528:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:04:41,262:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:04:41,624:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 18:04:42,666:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 18:05:15,966:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 18:05:17,654:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 18:05:58,215:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:05:58,247:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:06:00,278:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 18:06:00,280:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:06:02,379:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 18:06:02,639:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:06:04,251:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 18:07:00,310:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:07:00,777:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:07:01,814:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 18:08:45,389:INFO:Calculating mean and std
2023-06-12 18:08:45,390:INFO:Creating metrics dataframe
2023-06-12 18:09:05,604:INFO:Uploading results into container
2023-06-12 18:09:05,605:INFO:Uploading model into container now
2023-06-12 18:09:05,606:INFO:_master_model_container: 12
2023-06-12 18:09:05,606:INFO:_display_container: 2
2023-06-12 18:09:05,607:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=2557, verbose=0, warm_start=False)
2023-06-12 18:09:05,607:INFO:create_model() successfully completed......................................
2023-06-12 18:09:05,749:INFO:SubProcess create_model() end ==================================
2023-06-12 18:09:05,749:INFO:Creating metrics dataframe
2023-06-12 18:09:05,764:INFO:Initializing Light Gradient Boosting Machine
2023-06-12 18:09:05,764:INFO:Total runtime is 48.05124648014704 minutes
2023-06-12 18:09:05,769:INFO:SubProcess create_model() called ==================================
2023-06-12 18:09:05,769:INFO:Initializing create_model()
2023-06-12 18:09:05,770:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622F16FF10>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 18:09:05,770:INFO:Checking exceptions
2023-06-12 18:09:05,770:INFO:Importing libraries
2023-06-12 18:09:05,770:INFO:Copying training dataset
2023-06-12 18:09:05,911:INFO:Defining folds
2023-06-12 18:09:05,911:INFO:Declaring metric variables
2023-06-12 18:09:05,915:INFO:Importing untrained model
2023-06-12 18:09:05,921:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 18:09:05,930:INFO:Starting cross validation
2023-06-12 18:09:05,934:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 18:09:39,611:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:12:07,697:INFO:Calculating mean and std
2023-06-12 18:12:07,699:INFO:Creating metrics dataframe
2023-06-12 18:12:28,126:INFO:Uploading results into container
2023-06-12 18:12:28,127:INFO:Uploading model into container now
2023-06-12 18:12:28,128:INFO:_master_model_container: 13
2023-06-12 18:12:28,128:INFO:_display_container: 2
2023-06-12 18:12:28,129:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2557, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 18:12:28,129:INFO:create_model() successfully completed......................................
2023-06-12 18:12:28,278:INFO:SubProcess create_model() end ==================================
2023-06-12 18:12:28,278:INFO:Creating metrics dataframe
2023-06-12 18:12:28,295:INFO:Initializing Dummy Classifier
2023-06-12 18:12:28,295:INFO:Total runtime is 51.42676031589508 minutes
2023-06-12 18:12:28,309:INFO:SubProcess create_model() called ==================================
2023-06-12 18:12:28,309:INFO:Initializing create_model()
2023-06-12 18:12:28,309:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001622F16FF10>, model_only=True, return_train_score=False, kwargs={})
2023-06-12 18:12:28,309:INFO:Checking exceptions
2023-06-12 18:12:28,310:INFO:Importing libraries
2023-06-12 18:12:28,310:INFO:Copying training dataset
2023-06-12 18:12:28,444:INFO:Defining folds
2023-06-12 18:12:28,444:INFO:Declaring metric variables
2023-06-12 18:12:28,451:INFO:Importing untrained model
2023-06-12 18:12:28,456:INFO:Dummy Classifier Imported successfully
2023-06-12 18:12:28,465:INFO:Starting cross validation
2023-06-12 18:12:28,467:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 18:12:29,381:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-12 18:12:29,385:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-12 18:12:29,436:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-12 18:12:29,465:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-12 18:12:59,967:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-12 18:13:00,118:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-12 18:13:00,148:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-12 18:13:00,224:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-12 18:13:30,772:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-12 18:13:32,025:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-06-12 18:15:25,709:INFO:Calculating mean and std
2023-06-12 18:15:25,710:INFO:Creating metrics dataframe
2023-06-12 18:15:45,559:INFO:Uploading results into container
2023-06-12 18:15:45,561:INFO:Uploading model into container now
2023-06-12 18:15:45,561:INFO:_master_model_container: 14
2023-06-12 18:15:45,561:INFO:_display_container: 2
2023-06-12 18:15:45,562:INFO:DummyClassifier(constant=None, random_state=2557, strategy='prior')
2023-06-12 18:15:45,562:INFO:create_model() successfully completed......................................
2023-06-12 18:15:45,706:INFO:SubProcess create_model() end ==================================
2023-06-12 18:15:45,706:INFO:Creating metrics dataframe
2023-06-12 18:15:45,734:INFO:Initializing create_model()
2023-06-12 18:15:45,734:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2557, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 18:15:45,735:INFO:Checking exceptions
2023-06-12 18:15:45,737:INFO:Importing libraries
2023-06-12 18:15:45,737:INFO:Copying training dataset
2023-06-12 18:15:45,876:INFO:Defining folds
2023-06-12 18:15:45,877:INFO:Declaring metric variables
2023-06-12 18:15:45,878:INFO:Importing untrained model
2023-06-12 18:15:45,878:INFO:Declaring custom model
2023-06-12 18:15:45,879:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 18:15:45,880:INFO:Cross validation set to False
2023-06-12 18:15:45,880:INFO:Fitting Model
2023-06-12 18:16:02,580:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2557, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 18:16:02,580:INFO:create_model() successfully completed......................................
2023-06-12 18:16:02,735:INFO:Creating Dashboard logs
2023-06-12 18:16:02,739:INFO:Model: Light Gradient Boosting Machine
2023-06-12 18:16:02,866:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 2557, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 18:16:03,166:INFO:Initializing predict_model()
2023-06-12 18:16:03,166:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2557, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001623298FC70>)
2023-06-12 18:16:03,166:INFO:Checking exceptions
2023-06-12 18:16:03,166:INFO:Preloading libraries
2023-06-12 18:16:22,489:INFO:Creating Dashboard logs
2023-06-12 18:16:22,496:INFO:Model: Random Forest Classifier
2023-06-12 18:16:22,567:INFO:Logged params: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 2557, 'verbose': 0, 'warm_start': False}
2023-06-12 18:16:39,293:INFO:Creating Dashboard logs
2023-06-12 18:16:39,297:INFO:Model: Gradient Boosting Classifier
2023-06-12 18:16:39,381:INFO:Logged params: {'ccp_alpha': 0.0, 'criterion': 'friedman_mse', 'init': None, 'learning_rate': 0.1, 'loss': 'log_loss', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_iter_no_change': None, 'random_state': 2557, 'subsample': 1.0, 'tol': 0.0001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-06-12 18:16:55,356:INFO:Creating Dashboard logs
2023-06-12 18:16:55,363:INFO:Model: Ada Boost Classifier
2023-06-12 18:16:55,439:INFO:Logged params: {'algorithm': 'SAMME.R', 'base_estimator': 'deprecated', 'estimator': None, 'learning_rate': 1.0, 'n_estimators': 50, 'random_state': 2557}
2023-06-12 18:17:16,239:INFO:Creating Dashboard logs
2023-06-12 18:17:16,243:INFO:Model: Logistic Regression
2023-06-12 18:17:16,325:INFO:Logged params: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 1000, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': 2557, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}
2023-06-12 18:17:35,121:INFO:Creating Dashboard logs
2023-06-12 18:17:35,126:INFO:Model: Linear Discriminant Analysis
2023-06-12 18:17:35,233:INFO:Logged params: {'covariance_estimator': None, 'n_components': None, 'priors': None, 'shrinkage': None, 'solver': 'svd', 'store_covariance': False, 'tol': 0.0001}
2023-06-12 18:17:52,171:INFO:Creating Dashboard logs
2023-06-12 18:17:52,176:INFO:Model: Ridge Classifier
2023-06-12 18:17:52,263:INFO:Logged params: {'alpha': 1.0, 'class_weight': None, 'copy_X': True, 'fit_intercept': True, 'max_iter': None, 'positive': False, 'random_state': 2557, 'solver': 'auto', 'tol': 0.0001}
2023-06-12 18:18:09,341:INFO:Creating Dashboard logs
2023-06-12 18:18:09,345:INFO:Model: SVM - Linear Kernel
2023-06-12 18:18:09,429:INFO:Logged params: {'alpha': 0.0001, 'average': False, 'class_weight': None, 'early_stopping': False, 'epsilon': 0.1, 'eta0': 0.001, 'fit_intercept': True, 'l1_ratio': 0.15, 'learning_rate': 'optimal', 'loss': 'hinge', 'max_iter': 1000, 'n_iter_no_change': 5, 'n_jobs': -1, 'penalty': 'l2', 'power_t': 0.5, 'random_state': 2557, 'shuffle': True, 'tol': 0.001, 'validation_fraction': 0.1, 'verbose': 0, 'warm_start': False}
2023-06-12 18:18:25,929:INFO:Creating Dashboard logs
2023-06-12 18:18:25,933:INFO:Model: Extra Trees Classifier
2023-06-12 18:18:26,022:INFO:Logged params: {'bootstrap': False, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'oob_score': False, 'random_state': 2557, 'verbose': 0, 'warm_start': False}
2023-06-12 18:18:47,729:INFO:Creating Dashboard logs
2023-06-12 18:18:47,735:INFO:Model: K Neighbors Classifier
2023-06-12 18:18:47,823:INFO:Logged params: {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': -1, 'n_neighbors': 5, 'p': 2, 'weights': 'uniform'}
2023-06-12 18:19:06,629:INFO:Creating Dashboard logs
2023-06-12 18:19:06,633:INFO:Model: Decision Tree Classifier
2023-06-12 18:19:06,712:INFO:Logged params: {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 2557, 'splitter': 'best'}
2023-06-12 18:19:22,761:INFO:Creating Dashboard logs
2023-06-12 18:19:22,766:INFO:Model: Naive Bayes
2023-06-12 18:19:22,845:INFO:Logged params: {'priors': None, 'var_smoothing': 1e-09}
2023-06-12 18:19:38,474:INFO:Creating Dashboard logs
2023-06-12 18:19:38,479:INFO:Model: Quadratic Discriminant Analysis
2023-06-12 18:19:38,558:INFO:Logged params: {'priors': None, 'reg_param': 0.0, 'store_covariance': False, 'tol': 0.0001}
2023-06-12 18:19:53,858:INFO:Creating Dashboard logs
2023-06-12 18:19:53,862:INFO:Model: Dummy Classifier
2023-06-12 18:19:53,939:INFO:Logged params: {'constant': None, 'random_state': 2557, 'strategy': 'prior'}
2023-06-12 18:20:09,600:INFO:_master_model_container: 14
2023-06-12 18:20:09,600:INFO:_display_container: 2
2023-06-12 18:20:09,601:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2557, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 18:20:09,601:INFO:compare_models() successfully completed......................................
2023-06-12 18:20:09,631:INFO:Initializing tune_model()
2023-06-12 18:20:09,632:INFO:tune_model(estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2557, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, n_iter=10, custom_grid=None, optimize=F1, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>)
2023-06-12 18:20:09,632:INFO:Checking exceptions
2023-06-12 18:20:09,718:INFO:Copying training dataset
2023-06-12 18:20:09,812:INFO:Checking base model
2023-06-12 18:20:09,813:INFO:Base model : Light Gradient Boosting Machine
2023-06-12 18:20:09,818:INFO:Declaring metric variables
2023-06-12 18:20:09,823:INFO:Defining Hyperparameters
2023-06-12 18:20:09,977:INFO:Tuning with n_jobs=-1
2023-06-12 18:20:09,978:INFO:Initializing RandomizedSearchCV
2023-06-12 18:31:19,965:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:31:20,871:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-12 18:31:21,585:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-12 18:32:07,436:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:32:08,711:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 18:32:38,060:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.36s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:32:39,465:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 18:32:52,460:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 18:33:09,814:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.44s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:33:11,239:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 18:33:37,427:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.23s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:33:39,426:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.98s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 18:34:02,563:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:34:04,583:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 18:34:26,907:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:34:28,748:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 18:34:50,959:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.19s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:34:52,874:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 18:35:19,519:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.49s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:35:21,504:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 18:35:46,862:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.20s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:35:48,724:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 18:36:10,473:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.31s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:38:15,343:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:39:50,401:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:44:56,992:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:50:31,831:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:51:08,075:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 18:59:01,768:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-12 18:59:02,816:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-12 18:59:41,210:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.94s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 19:06:58,844:INFO:best_params: {'actual_estimator__reg_lambda': 5, 'actual_estimator__reg_alpha': 0.4, 'actual_estimator__num_leaves': 8, 'actual_estimator__n_estimators': 220, 'actual_estimator__min_split_gain': 0, 'actual_estimator__min_child_samples': 16, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 7, 'actual_estimator__bagging_fraction': 1.0}
2023-06-12 19:06:58,846:INFO:Hyperparameter search completed
2023-06-12 19:06:58,847:INFO:SubProcess create_model() called ==================================
2023-06-12 19:06:58,849:INFO:Initializing create_model()
2023-06-12 19:06:58,849:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2557, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000016232899090>, model_only=True, return_train_score=False, kwargs={'reg_lambda': 5, 'reg_alpha': 0.4, 'num_leaves': 8, 'n_estimators': 220, 'min_split_gain': 0, 'min_child_samples': 16, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 7, 'bagging_fraction': 1.0})
2023-06-12 19:06:58,850:INFO:Checking exceptions
2023-06-12 19:06:58,850:INFO:Importing libraries
2023-06-12 19:06:58,851:INFO:Copying training dataset
2023-06-12 19:06:59,065:INFO:Defining folds
2023-06-12 19:06:59,065:INFO:Declaring metric variables
2023-06-12 19:06:59,074:INFO:Importing untrained model
2023-06-12 19:06:59,074:INFO:Declaring custom model
2023-06-12 19:06:59,098:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 19:06:59,117:INFO:Starting cross validation
2023-06-12 19:06:59,120:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 19:07:15,570:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 19:07:15,679:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 19:07:16,848:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 19:07:17,339:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 19:08:15,481:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 19:08:15,640:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-12 19:08:16,699:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 19:08:16,756:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 19:08:22,608:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-12 19:08:23,403:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 19:08:23,451:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 19:12:24,729:INFO:Calculating mean and std
2023-06-12 19:12:24,731:INFO:Creating metrics dataframe
2023-06-12 19:12:24,743:INFO:Finalizing model
2023-06-12 19:12:25,366:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2023-06-12 19:12:25,366:INFO:[LightGBM] [Warning] bagging_fraction is set=1.0, subsample=1.0 will be ignored. Current value: bagging_fraction=1.0
2023-06-12 19:12:25,366:INFO:[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7
2023-06-12 19:13:11,803:INFO:Uploading results into container
2023-06-12 19:13:11,805:INFO:Uploading model into container now
2023-06-12 19:13:11,806:INFO:_master_model_container: 15
2023-06-12 19:13:11,806:INFO:_display_container: 3
2023-06-12 19:13:11,807:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0,
               n_estimators=220, n_jobs=-1, num_leaves=8, objective=None,
               random_state=2557, reg_alpha=0.4, reg_lambda=5, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 19:13:11,808:INFO:create_model() successfully completed......................................
2023-06-12 19:13:12,151:INFO:SubProcess create_model() end ==================================
2023-06-12 19:13:12,151:INFO:choose_better activated
2023-06-12 19:13:12,159:INFO:SubProcess create_model() called ==================================
2023-06-12 19:13:12,160:INFO:Initializing create_model()
2023-06-12 19:13:12,160:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2557, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 19:13:12,160:INFO:Checking exceptions
2023-06-12 19:13:12,162:INFO:Importing libraries
2023-06-12 19:13:12,163:INFO:Copying training dataset
2023-06-12 19:13:12,358:INFO:Defining folds
2023-06-12 19:13:12,358:INFO:Declaring metric variables
2023-06-12 19:13:12,359:INFO:Importing untrained model
2023-06-12 19:13:12,359:INFO:Declaring custom model
2023-06-12 19:13:12,360:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 19:13:12,360:INFO:Starting cross validation
2023-06-12 19:13:12,361:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 19:13:13,907:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 19:13:14,190:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 19:13:14,236:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 19:13:14,274:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 19:14:33,808:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.13s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 19:16:00,841:WARNING:c:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 19:19:12,858:INFO:Calculating mean and std
2023-06-12 19:19:12,860:INFO:Creating metrics dataframe
2023-06-12 19:19:12,863:INFO:Finalizing model
2023-06-12 19:19:42,101:INFO:Uploading results into container
2023-06-12 19:19:42,102:INFO:Uploading model into container now
2023-06-12 19:19:42,103:INFO:_master_model_container: 16
2023-06-12 19:19:42,103:INFO:_display_container: 4
2023-06-12 19:19:42,104:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2557, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 19:19:42,104:INFO:create_model() successfully completed......................................
2023-06-12 19:19:42,318:INFO:SubProcess create_model() end ==================================
2023-06-12 19:19:42,319:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2557, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6941
2023-06-12 19:19:42,320:INFO:LGBMClassifier(bagging_fraction=1.0, bagging_freq=7, boosting_type='gbdt',
               class_weight=None, colsample_bytree=1.0, feature_fraction=0.4,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=16, min_child_weight=0.001, min_split_gain=0,
               n_estimators=220, n_jobs=-1, num_leaves=8, objective=None,
               random_state=2557, reg_alpha=0.4, reg_lambda=5, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) result for F1 is 0.6941
2023-06-12 19:19:42,320:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2557, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) is best model
2023-06-12 19:19:42,321:INFO:choose_better completed
2023-06-12 19:19:42,321:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-06-12 19:19:42,321:INFO:Creating Dashboard logs
2023-06-12 19:19:42,327:INFO:Model: Light Gradient Boosting Machine
2023-06-12 19:19:42,492:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 2557, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 19:19:42,773:INFO:Initializing predict_model()
2023-06-12 19:19:42,773:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2557, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001623298F6D0>)
2023-06-12 19:19:42,773:INFO:Checking exceptions
2023-06-12 19:19:42,773:INFO:Preloading libraries
2023-06-12 19:20:06,259:INFO:_master_model_container: 16
2023-06-12 19:20:06,259:INFO:_display_container: 3
2023-06-12 19:20:06,260:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2557, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 19:20:06,260:INFO:tune_model() successfully completed......................................
2023-06-12 19:20:29,202:INFO:Initializing finalize_model()
2023-06-12 19:20:29,202:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2557, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-12 19:20:29,204:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2557, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 19:20:29,267:INFO:Initializing create_model()
2023-06-12 19:20:29,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=2557, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-12 19:20:29,268:INFO:Checking exceptions
2023-06-12 19:20:29,277:INFO:Importing libraries
2023-06-12 19:20:29,278:INFO:Copying training dataset
2023-06-12 19:20:29,281:INFO:Defining folds
2023-06-12 19:20:29,282:INFO:Declaring metric variables
2023-06-12 19:20:29,282:INFO:Importing untrained model
2023-06-12 19:20:29,282:INFO:Declaring custom model
2023-06-12 19:20:29,284:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 19:20:29,288:INFO:Cross validation set to False
2023-06-12 19:20:29,289:INFO:Fitting Model
2023-06-12 19:20:31,281:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=2557, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 19:20:31,281:INFO:create_model() successfully completed......................................
2023-06-12 19:20:31,507:INFO:Creating Dashboard logs
2023-06-12 19:20:31,508:INFO:Model: Light Gradient Boosting Machine
2023-06-12 19:20:31,599:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 2557, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 19:20:32,097:INFO:_master_model_container: 16
2023-06-12 19:20:32,097:INFO:_display_container: 3
2023-06-12 19:20:32,113:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=2557, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 19:20:32,113:INFO:finalize_model() successfully completed......................................
2023-06-12 19:20:32,382:INFO:Initializing save_model()
2023-06-12 19:20:32,382:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=2557, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=models/bs_predictor_brawlBall, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 19:20:32,382:INFO:Adding model into prep_pipe
2023-06-12 19:20:32,382:WARNING:Only Model saved as it was a pipeline.
2023-06-12 19:20:32,461:INFO:models/bs_predictor_brawlBall.pkl saved in current working directory
2023-06-12 19:20:32,491:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=2557, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 19:20:32,498:INFO:save_model() successfully completed......................................
2023-06-12 19:20:32,811:INFO:Initializing predict_model()
2023-06-12 19:20:32,811:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000162310DDF90>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=2557, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001623315C3A0>)
2023-06-12 19:20:32,811:INFO:Checking exceptions
2023-06-12 19:20:32,812:INFO:Preloading libraries
2023-06-12 19:20:32,815:INFO:Set up data.
2023-06-12 19:20:32,916:INFO:Set up index.
2023-06-12 19:35:49,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 19:35:49,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 19:35:49,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 19:35:49,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 19:35:54,863:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-12 19:36:04,335:INFO:Initializing load_model()
2023-06-12 19:36:04,336:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-12 19:36:04,496:INFO:Initializing load_model()
2023-06-12 19:36:04,497:INFO:load_model(model_name=models/bs_predictor_gemGrab, platform=None, authentication=None, verbose=True)
2023-06-12 19:41:06,514:INFO:Initializing predict_model()
2023-06-12 19:41:06,518:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D007978790>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=2557))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D078E3FD90>)
2023-06-12 19:41:06,518:INFO:Checking exceptions
2023-06-12 19:41:06,518:INFO:Preloading libraries
2023-06-12 19:41:06,518:INFO:Set up data.
2023-06-12 19:41:06,518:INFO:Set up index.
2023-06-12 19:50:34,820:INFO:Initializing predict_model()
2023-06-12 19:50:34,820:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0074C5EA0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=2557))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D078E3FD90>)
2023-06-12 19:50:34,820:INFO:Checking exceptions
2023-06-12 19:50:34,820:INFO:Preloading libraries
2023-06-12 19:50:34,821:INFO:Set up data.
2023-06-12 19:50:34,889:INFO:Set up index.
2023-06-12 19:51:34,359:INFO:Initializing predict_model()
2023-06-12 19:51:34,360:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D078E32A40>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=2557))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D078E3FA30>)
2023-06-12 19:51:34,360:INFO:Checking exceptions
2023-06-12 19:51:34,360:INFO:Preloading libraries
2023-06-12 19:51:34,361:INFO:Set up data.
2023-06-12 19:51:34,432:INFO:Set up index.
2023-06-12 19:53:11,753:INFO:Initializing predict_model()
2023-06-12 19:53:11,754:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0074C5780>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=2557))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D078E3F7F0>)
2023-06-12 19:53:11,754:INFO:Checking exceptions
2023-06-12 19:53:11,754:INFO:Preloading libraries
2023-06-12 19:53:11,755:INFO:Set up data.
2023-06-12 19:53:11,814:INFO:Set up index.
2023-06-12 19:53:23,641:INFO:Initializing predict_model()
2023-06-12 19:53:23,643:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0074C5420>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=2557))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D007C77EB0>)
2023-06-12 19:53:23,645:INFO:Checking exceptions
2023-06-12 19:53:23,645:INFO:Preloading libraries
2023-06-12 19:53:23,646:INFO:Set up data.
2023-06-12 19:53:23,718:INFO:Set up index.
2023-06-12 19:53:28,240:INFO:Initializing predict_model()
2023-06-12 19:53:28,241:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D0074C5C60>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=2557))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D007C77D90>)
2023-06-12 19:53:28,241:INFO:Checking exceptions
2023-06-12 19:53:28,241:INFO:Preloading libraries
2023-06-12 19:53:28,241:INFO:Set up data.
2023-06-12 19:53:28,297:INFO:Set up index.
2023-06-12 19:53:35,128:INFO:Initializing predict_model()
2023-06-12 19:53:35,128:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D007CB49D0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=2557))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D078E9CCA0>)
2023-06-12 19:53:35,128:INFO:Checking exceptions
2023-06-12 19:53:35,129:INFO:Preloading libraries
2023-06-12 19:53:35,130:INFO:Set up data.
2023-06-12 19:53:35,178:INFO:Set up index.
2023-06-12 19:53:45,951:INFO:Initializing predict_model()
2023-06-12 19:53:45,952:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D00797AD40>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=2557))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D007C777F0>)
2023-06-12 19:53:45,952:INFO:Checking exceptions
2023-06-12 19:53:45,952:INFO:Preloading libraries
2023-06-12 19:53:45,952:INFO:Set up data.
2023-06-12 19:53:45,989:INFO:Set up index.
2023-06-12 19:53:57,820:INFO:Initializing predict_model()
2023-06-12 19:53:57,820:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D007D50EB0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=2557))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D078E3F9A0>)
2023-06-12 19:53:57,821:INFO:Checking exceptions
2023-06-12 19:53:57,821:INFO:Preloading libraries
2023-06-12 19:53:57,821:INFO:Set up data.
2023-06-12 19:53:57,880:INFO:Set up index.
2023-06-12 19:54:05,893:INFO:Initializing predict_model()
2023-06-12 19:54:05,893:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D007979BD0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=2557))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D007C77640>)
2023-06-12 19:54:05,893:INFO:Checking exceptions
2023-06-12 19:54:05,893:INFO:Preloading libraries
2023-06-12 19:54:05,894:INFO:Set up data.
2023-06-12 19:54:05,962:INFO:Set up index.
2023-06-12 19:54:12,426:INFO:Initializing predict_model()
2023-06-12 19:54:12,426:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D007A65E10>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=2557))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D007C76E60>)
2023-06-12 19:54:12,426:INFO:Checking exceptions
2023-06-12 19:54:12,426:INFO:Preloading libraries
2023-06-12 19:54:12,426:INFO:Set up data.
2023-06-12 19:54:12,483:INFO:Set up index.
2023-06-12 19:59:45,012:INFO:Initializing predict_model()
2023-06-12 19:59:45,012:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D007CB52D0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=2557))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D007C76CB0>)
2023-06-12 19:59:45,012:INFO:Checking exceptions
2023-06-12 19:59:45,013:INFO:Preloading libraries
2023-06-12 19:59:45,013:INFO:Set up data.
2023-06-12 19:59:45,119:INFO:Set up index.
2023-06-12 22:10:14,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 22:10:14,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 22:10:14,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 22:10:14,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 22:10:16,387:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-12 22:10:20,203:INFO:Initializing load_model()
2023-06-12 22:10:20,204:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-12 22:10:20,264:INFO:Initializing load_model()
2023-06-12 22:10:20,264:INFO:load_model(model_name=models/bs_predictor_gemGrab, platform=None, authentication=None, verbose=True)
2023-06-12 23:00:49,468:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 23:00:49,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 23:00:49,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 23:00:49,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-12 23:00:50,670:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-12 23:07:04,509:INFO:PyCaret ClassificationExperiment
2023-06-12 23:07:04,513:INFO:Logging name: clf-default-name
2023-06-12 23:07:04,514:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 23:07:04,514:INFO:version 3.0.2
2023-06-12 23:07:04,514:INFO:Initializing setup()
2023-06-12 23:07:04,514:INFO:self.USI: 8614
2023-06-12 23:07:04,514:INFO:self._variable_keys: {'fold_groups_param', 'exp_name_log', 'y_test', 'log_plots_param', 'fix_imbalance', 'fold_generator', 'gpu_n_jobs_param', 'n_jobs_param', 'y', 'html_param', '_available_plots', 'memory', 'gpu_param', 'X_train', 'X', 'USI', 'seed', 'target_param', 'pipeline', 'data', '_ml_usecase', 'logging_param', 'fold_shuffle_param', 'idx', 'y_train', 'X_test', 'is_multiclass', 'exp_id'}
2023-06-12 23:07:04,514:INFO:Checking environment
2023-06-12 23:07:04,514:INFO:python_version: 3.10.10
2023-06-12 23:07:04,515:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 23:07:04,515:INFO:machine: AMD64
2023-06-12 23:07:04,544:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 23:07:04,544:INFO:Memory: svmem(total=17034072064, available=8106811392, percent=52.4, used=8927260672, free=8106811392)
2023-06-12 23:07:04,544:INFO:Physical Core: 2
2023-06-12 23:07:04,544:INFO:Logical Core: 4
2023-06-12 23:07:04,544:INFO:Checking libraries
2023-06-12 23:07:04,544:INFO:System:
2023-06-12 23:07:04,544:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 23:07:04,544:INFO:executable: C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 23:07:04,544:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 23:07:04,544:INFO:PyCaret required dependencies:
2023-06-12 23:07:04,544:INFO:                 pip: 23.1.2
2023-06-12 23:07:04,544:INFO:          setuptools: 65.5.0
2023-06-12 23:07:04,544:INFO:             pycaret: 3.0.2
2023-06-12 23:07:04,544:INFO:             IPython: 8.14.0
2023-06-12 23:07:04,544:INFO:          ipywidgets: 8.0.6
2023-06-12 23:07:04,544:INFO:                tqdm: 4.65.0
2023-06-12 23:07:04,544:INFO:               numpy: 1.23.5
2023-06-12 23:07:04,544:INFO:              pandas: 1.5.3
2023-06-12 23:07:04,544:INFO:              jinja2: 3.1.2
2023-06-12 23:07:04,544:INFO:               scipy: 1.10.1
2023-06-12 23:07:04,544:INFO:              joblib: 1.2.0
2023-06-12 23:07:04,544:INFO:             sklearn: 1.2.2
2023-06-12 23:07:04,544:INFO:                pyod: 1.0.9
2023-06-12 23:07:04,544:INFO:            imblearn: 0.10.1
2023-06-12 23:07:04,544:INFO:   category_encoders: 2.6.1
2023-06-12 23:07:04,544:INFO:            lightgbm: 3.3.5
2023-06-12 23:07:04,544:INFO:               numba: 0.57.0
2023-06-12 23:07:04,544:INFO:            requests: 2.31.0
2023-06-12 23:07:04,544:INFO:          matplotlib: 3.7.1
2023-06-12 23:07:04,544:INFO:          scikitplot: 0.3.7
2023-06-12 23:07:04,544:INFO:         yellowbrick: 1.5
2023-06-12 23:07:04,544:INFO:              plotly: 5.15.0
2023-06-12 23:07:04,544:INFO:             kaleido: 0.2.1
2023-06-12 23:07:04,544:INFO:         statsmodels: 0.14.0
2023-06-12 23:07:04,544:INFO:              sktime: 0.17.0
2023-06-12 23:07:04,544:INFO:               tbats: 1.1.3
2023-06-12 23:07:04,544:INFO:            pmdarima: 2.0.3
2023-06-12 23:07:04,544:INFO:              psutil: 5.9.5
2023-06-12 23:07:04,544:INFO:PyCaret optional dependencies:
2023-06-12 23:07:04,590:INFO:                shap: Not installed
2023-06-12 23:07:04,590:INFO:           interpret: Not installed
2023-06-12 23:07:04,590:INFO:                umap: Not installed
2023-06-12 23:07:04,590:INFO:    pandas_profiling: Not installed
2023-06-12 23:07:04,590:INFO:  explainerdashboard: Not installed
2023-06-12 23:07:04,590:INFO:             autoviz: Not installed
2023-06-12 23:07:04,590:INFO:           fairlearn: Not installed
2023-06-12 23:07:04,590:INFO:             xgboost: Not installed
2023-06-12 23:07:04,590:INFO:            catboost: Not installed
2023-06-12 23:07:04,590:INFO:              kmodes: Not installed
2023-06-12 23:07:04,590:INFO:             mlxtend: Not installed
2023-06-12 23:07:04,590:INFO:       statsforecast: Not installed
2023-06-12 23:07:04,590:INFO:        tune_sklearn: Not installed
2023-06-12 23:07:04,590:INFO:                 ray: Not installed
2023-06-12 23:07:04,590:INFO:            hyperopt: Not installed
2023-06-12 23:07:04,590:INFO:              optuna: Not installed
2023-06-12 23:07:04,590:INFO:               skopt: Not installed
2023-06-12 23:07:04,590:INFO:              mlflow: 2.4.1
2023-06-12 23:07:04,590:INFO:              gradio: Not installed
2023-06-12 23:07:04,590:INFO:             fastapi: Not installed
2023-06-12 23:07:04,590:INFO:             uvicorn: Not installed
2023-06-12 23:07:04,590:INFO:              m2cgen: Not installed
2023-06-12 23:07:04,590:INFO:           evidently: Not installed
2023-06-12 23:07:04,590:INFO:               fugue: Not installed
2023-06-12 23:07:04,590:INFO:           streamlit: 1.23.1
2023-06-12 23:07:04,590:INFO:             prophet: Not installed
2023-06-12 23:07:04,590:INFO:None
2023-06-12 23:07:04,590:INFO:Set up data.
2023-06-12 23:07:04,724:INFO:Set up train/test split.
2023-06-12 23:07:04,925:INFO:Set up index.
2023-06-12 23:07:04,926:INFO:Set up folding strategy.
2023-06-12 23:07:04,926:INFO:Assigning column types.
2023-06-12 23:07:05,004:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 23:07:05,051:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 23:07:05,051:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:07:05,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:07:05,143:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:07:05,190:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 23:07:05,190:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:07:05,222:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:07:05,222:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:07:05,222:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 23:07:05,294:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:07:05,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:07:05,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:07:05,408:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:07:05,455:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:07:05,455:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:07:05,455:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 23:07:05,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:07:05,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:07:05,605:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:07:05,605:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:07:05,605:INFO:Preparing preprocessing pipeline...
2023-06-12 23:07:05,621:INFO:Set up label encoding.
2023-06-12 23:07:05,621:INFO:Set up simple imputation.
2023-06-12 23:07:05,698:INFO:Set up encoding of categorical features.
2023-06-12 23:07:05,710:INFO:Set up column name cleaning.
2023-06-12 23:07:08,171:INFO:Finished creating preprocessing pipeline.
2023-06-12 23:07:08,187:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-12 23:07:08,187:INFO:Creating final display dataframe.
2023-06-12 23:07:10,872:INFO:Setup _display_container:                     Description             Value
0                    Session id              1329
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape     (105664, 142)
5        Transformed data shape     (105664, 152)
6   Transformed train set shape      (73964, 152)
7    Transformed test set shape      (31700, 152)
8              Numeric features               140
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              8614
2023-06-12 23:07:10,978:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:07:10,978:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:07:11,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:07:11,053:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:07:11,053:INFO:Logging experiment in loggers
2023-06-12 23:07:11,323:INFO:SubProcess save_model() called ==================================
2023-06-12 23:07:11,355:INFO:Initializing save_model()
2023-06-12 23:07:11,355:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmpaxzgoq4k\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 23:07:11,355:INFO:Adding model into prep_pipe
2023-06-12 23:07:11,355:WARNING:Only Model saved as it was a pipeline.
2023-06-12 23:07:11,363:INFO:C:\Users\alniquia\AppData\Local\Temp\tmpaxzgoq4k\Transformation Pipeline.pkl saved in current working directory
2023-06-12 23:07:11,372:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-12 23:07:11,372:INFO:save_model() successfully completed......................................
2023-06-12 23:07:11,468:INFO:SubProcess save_model() end ==================================
2023-06-12 23:07:11,502:INFO:setup() successfully completed in 23.86s...............
2023-06-12 23:07:11,502:INFO:Initializing create_model()
2023-06-12 23:07:11,502:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2D6C5E0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 23:07:11,502:INFO:Checking exceptions
2023-06-12 23:07:11,504:INFO:Importing libraries
2023-06-12 23:07:11,504:INFO:Copying training dataset
2023-06-12 23:07:11,690:INFO:Defining folds
2023-06-12 23:07:11,690:INFO:Declaring metric variables
2023-06-12 23:07:11,690:INFO:Importing untrained model
2023-06-12 23:07:11,703:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 23:07:11,703:INFO:Starting cross validation
2023-06-12 23:07:11,709:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 23:07:59,731:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:08:00,395:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 23:08:00,427:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 23:08:00,545:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 23:08:00,546:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 23:08:01,748:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:08:01,764:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:08:01,764:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:08:01,795:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:08:02,709:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:08:02,713:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:08:02,730:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:08:05,728:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:08:07,859:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-12 23:08:07,859:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 1.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-12 23:08:08,890:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 23:08:08,893:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.77s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 23:08:39,522:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 23:08:43,188:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:10:44,440:INFO:Calculating mean and std
2023-06-12 23:10:44,441:INFO:Creating metrics dataframe
2023-06-12 23:10:44,444:INFO:Finalizing model
2023-06-12 23:11:04,982:INFO:Creating Dashboard logs
2023-06-12 23:11:04,998:INFO:Model: Light Gradient Boosting Machine
2023-06-12 23:11:05,135:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 1329, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 23:11:05,384:INFO:Initializing predict_model()
2023-06-12 23:11:05,384:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2D6C5E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1329, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017ED085B910>)
2023-06-12 23:11:05,384:INFO:Checking exceptions
2023-06-12 23:11:05,384:INFO:Preloading libraries
2023-06-12 23:11:06,197:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning: Setuptools is replacing distutils.
  warnings.warn("Setuptools is replacing distutils.")

2023-06-12 23:11:21,142:INFO:Uploading results into container
2023-06-12 23:11:21,152:INFO:Uploading model into container now
2023-06-12 23:11:21,169:INFO:_master_model_container: 1
2023-06-12 23:11:21,169:INFO:_display_container: 2
2023-06-12 23:11:21,170:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1329, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 23:11:21,170:INFO:create_model() successfully completed......................................
2023-06-12 23:11:21,259:INFO:Initializing finalize_model()
2023-06-12 23:11:21,259:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2D6C5E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1329, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-12 23:11:21,259:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1329, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 23:11:21,314:INFO:Initializing create_model()
2023-06-12 23:11:21,314:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2D6C5E0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1329, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-12 23:11:21,314:INFO:Checking exceptions
2023-06-12 23:11:21,315:INFO:Importing libraries
2023-06-12 23:11:21,315:INFO:Copying training dataset
2023-06-12 23:11:21,319:INFO:Defining folds
2023-06-12 23:11:21,319:INFO:Declaring metric variables
2023-06-12 23:11:21,319:INFO:Importing untrained model
2023-06-12 23:11:21,319:INFO:Declaring custom model
2023-06-12 23:11:21,320:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 23:11:21,322:INFO:Cross validation set to False
2023-06-12 23:11:21,322:INFO:Fitting Model
2023-06-12 23:11:25,897:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=1329, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:11:25,898:INFO:create_model() successfully completed......................................
2023-06-12 23:11:25,988:INFO:Creating Dashboard logs
2023-06-12 23:11:25,988:INFO:Model: Light Gradient Boosting Machine
2023-06-12 23:11:26,092:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 1329, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 23:11:26,418:INFO:_master_model_container: 1
2023-06-12 23:11:26,418:INFO:_display_container: 2
2023-06-12 23:11:26,429:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=1329, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:11:26,429:INFO:finalize_model() successfully completed......................................
2023-06-12 23:11:26,529:INFO:Initializing save_model()
2023-06-12 23:11:26,529:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=1329, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=models/bs_predictor_brawlBall, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 23:11:26,530:INFO:Adding model into prep_pipe
2023-06-12 23:11:26,530:WARNING:Only Model saved as it was a pipeline.
2023-06-12 23:11:26,550:INFO:models/bs_predictor_brawlBall.pkl saved in current working directory
2023-06-12 23:11:26,574:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=1329, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:11:26,574:INFO:save_model() successfully completed......................................
2023-06-12 23:11:26,740:INFO:Initializing predict_model()
2023-06-12 23:11:26,740:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2D6C5E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=1329, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017ED8F21E10>)
2023-06-12 23:11:26,740:INFO:Checking exceptions
2023-06-12 23:11:26,740:INFO:Preloading libraries
2023-06-12 23:11:26,740:INFO:Set up data.
2023-06-12 23:11:26,787:INFO:Set up index.
2023-06-12 23:13:36,512:INFO:PyCaret ClassificationExperiment
2023-06-12 23:13:36,512:INFO:Logging name: clf-default-name
2023-06-12 23:13:36,513:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 23:13:36,513:INFO:version 3.0.2
2023-06-12 23:13:36,513:INFO:Initializing setup()
2023-06-12 23:13:36,513:INFO:self.USI: f23c
2023-06-12 23:13:36,514:INFO:self._variable_keys: {'fold_groups_param', 'exp_name_log', 'y_test', 'log_plots_param', 'fix_imbalance', 'fold_generator', 'gpu_n_jobs_param', 'n_jobs_param', 'y', 'html_param', '_available_plots', 'memory', 'gpu_param', 'X_train', 'X', 'USI', 'seed', 'target_param', 'pipeline', 'data', '_ml_usecase', 'logging_param', 'fold_shuffle_param', 'idx', 'y_train', 'X_test', 'is_multiclass', 'exp_id'}
2023-06-12 23:13:36,514:INFO:Checking environment
2023-06-12 23:13:36,514:INFO:python_version: 3.10.10
2023-06-12 23:13:36,514:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 23:13:36,514:INFO:machine: AMD64
2023-06-12 23:13:36,514:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 23:13:36,518:INFO:Memory: svmem(total=17034072064, available=7297703936, percent=57.2, used=9736368128, free=7297703936)
2023-06-12 23:13:36,518:INFO:Physical Core: 2
2023-06-12 23:13:36,519:INFO:Logical Core: 4
2023-06-12 23:13:36,519:INFO:Checking libraries
2023-06-12 23:13:36,520:INFO:System:
2023-06-12 23:13:36,520:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 23:13:36,520:INFO:executable: C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 23:13:36,520:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 23:13:36,520:INFO:PyCaret required dependencies:
2023-06-12 23:13:36,521:INFO:                 pip: 23.1.2
2023-06-12 23:13:36,521:INFO:          setuptools: 65.5.0
2023-06-12 23:13:36,521:INFO:             pycaret: 3.0.2
2023-06-12 23:13:36,522:INFO:             IPython: 8.14.0
2023-06-12 23:13:36,522:INFO:          ipywidgets: 8.0.6
2023-06-12 23:13:36,522:INFO:                tqdm: 4.65.0
2023-06-12 23:13:36,522:INFO:               numpy: 1.23.5
2023-06-12 23:13:36,523:INFO:              pandas: 1.5.3
2023-06-12 23:13:36,523:INFO:              jinja2: 3.1.2
2023-06-12 23:13:36,523:INFO:               scipy: 1.10.1
2023-06-12 23:13:36,524:INFO:              joblib: 1.2.0
2023-06-12 23:13:36,524:INFO:             sklearn: 1.2.2
2023-06-12 23:13:36,524:INFO:                pyod: 1.0.9
2023-06-12 23:13:36,524:INFO:            imblearn: 0.10.1
2023-06-12 23:13:36,524:INFO:   category_encoders: 2.6.1
2023-06-12 23:13:36,524:INFO:            lightgbm: 3.3.5
2023-06-12 23:13:36,524:INFO:               numba: 0.57.0
2023-06-12 23:13:36,524:INFO:            requests: 2.31.0
2023-06-12 23:13:36,524:INFO:          matplotlib: 3.7.1
2023-06-12 23:13:36,524:INFO:          scikitplot: 0.3.7
2023-06-12 23:13:36,524:INFO:         yellowbrick: 1.5
2023-06-12 23:13:36,524:INFO:              plotly: 5.15.0
2023-06-12 23:13:36,524:INFO:             kaleido: 0.2.1
2023-06-12 23:13:36,524:INFO:         statsmodels: 0.14.0
2023-06-12 23:13:36,524:INFO:              sktime: 0.17.0
2023-06-12 23:13:36,524:INFO:               tbats: 1.1.3
2023-06-12 23:13:36,524:INFO:            pmdarima: 2.0.3
2023-06-12 23:13:36,524:INFO:              psutil: 5.9.5
2023-06-12 23:13:36,524:INFO:PyCaret optional dependencies:
2023-06-12 23:13:36,524:INFO:                shap: Not installed
2023-06-12 23:13:36,524:INFO:           interpret: Not installed
2023-06-12 23:13:36,524:INFO:                umap: Not installed
2023-06-12 23:13:36,524:INFO:    pandas_profiling: Not installed
2023-06-12 23:13:36,524:INFO:  explainerdashboard: Not installed
2023-06-12 23:13:36,524:INFO:             autoviz: Not installed
2023-06-12 23:13:36,524:INFO:           fairlearn: Not installed
2023-06-12 23:13:36,524:INFO:             xgboost: Not installed
2023-06-12 23:13:36,524:INFO:            catboost: Not installed
2023-06-12 23:13:36,524:INFO:              kmodes: Not installed
2023-06-12 23:13:36,524:INFO:             mlxtend: Not installed
2023-06-12 23:13:36,524:INFO:       statsforecast: Not installed
2023-06-12 23:13:36,524:INFO:        tune_sklearn: Not installed
2023-06-12 23:13:36,524:INFO:                 ray: Not installed
2023-06-12 23:13:36,524:INFO:            hyperopt: Not installed
2023-06-12 23:13:36,524:INFO:              optuna: Not installed
2023-06-12 23:13:36,524:INFO:               skopt: Not installed
2023-06-12 23:13:36,524:INFO:              mlflow: 2.4.1
2023-06-12 23:13:36,524:INFO:              gradio: Not installed
2023-06-12 23:13:36,524:INFO:             fastapi: Not installed
2023-06-12 23:13:36,524:INFO:             uvicorn: Not installed
2023-06-12 23:13:36,524:INFO:              m2cgen: Not installed
2023-06-12 23:13:36,524:INFO:           evidently: Not installed
2023-06-12 23:13:36,524:INFO:               fugue: Not installed
2023-06-12 23:13:36,524:INFO:           streamlit: 1.23.1
2023-06-12 23:13:36,524:INFO:             prophet: Not installed
2023-06-12 23:13:36,524:INFO:None
2023-06-12 23:13:36,524:INFO:Set up data.
2023-06-12 23:13:36,720:INFO:Set up train/test split.
2023-06-12 23:13:36,938:INFO:Set up index.
2023-06-12 23:13:36,954:INFO:Set up folding strategy.
2023-06-12 23:13:36,954:INFO:Assigning column types.
2023-06-12 23:13:37,032:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 23:13:37,109:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 23:13:37,111:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:13:37,138:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:13:37,138:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:13:37,200:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 23:13:37,200:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:13:37,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:13:37,232:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:13:37,232:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 23:13:37,263:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:13:37,311:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:13:37,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:13:37,354:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:13:37,370:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:13:37,370:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:13:37,370:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 23:13:37,466:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:13:37,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:13:37,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:13:37,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:13:37,570:INFO:Preparing preprocessing pipeline...
2023-06-12 23:13:37,586:INFO:Set up label encoding.
2023-06-12 23:13:37,586:INFO:Set up simple imputation.
2023-06-12 23:13:37,702:INFO:Set up encoding of categorical features.
2023-06-12 23:13:37,723:INFO:Set up column name cleaning.
2023-06-12 23:13:40,551:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 23:13:42,558:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:13:44,480:INFO:Finished creating preprocessing pipeline.
2023-06-12 23:13:44,496:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-12 23:13:44,496:INFO:Creating final display dataframe.
2023-06-12 23:13:47,550:INFO:Setup _display_container:                     Description             Value
0                    Session id              3545
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape     (105664, 142)
5        Transformed data shape     (105664, 153)
6   Transformed train set shape      (73964, 153)
7    Transformed test set shape      (31700, 153)
8              Numeric features               140
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              f23c
2023-06-12 23:13:47,647:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:13:47,647:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:13:47,720:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:13:47,720:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:13:47,721:INFO:Logging experiment in loggers
2023-06-12 23:13:47,923:INFO:SubProcess save_model() called ==================================
2023-06-12 23:13:47,934:INFO:Initializing save_model()
2023-06-12 23:13:47,934:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmpjrm_4qbc\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 23:13:47,934:INFO:Adding model into prep_pipe
2023-06-12 23:13:47,934:WARNING:Only Model saved as it was a pipeline.
2023-06-12 23:13:47,949:INFO:C:\Users\alniquia\AppData\Local\Temp\tmpjrm_4qbc\Transformation Pipeline.pkl saved in current working directory
2023-06-12 23:13:47,965:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-12 23:13:47,965:INFO:save_model() successfully completed......................................
2023-06-12 23:13:47,965:INFO:SubProcess save_model() end ==================================
2023-06-12 23:13:47,981:INFO:setup() successfully completed in 28.74s...............
2023-06-12 23:13:47,981:INFO:Initializing create_model()
2023-06-12 23:13:47,981:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC1C5C700>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 23:13:47,981:INFO:Checking exceptions
2023-06-12 23:13:47,981:INFO:Importing libraries
2023-06-12 23:13:47,981:INFO:Copying training dataset
2023-06-12 23:13:48,293:INFO:Defining folds
2023-06-12 23:13:48,293:INFO:Declaring metric variables
2023-06-12 23:13:48,293:INFO:Importing untrained model
2023-06-12 23:13:48,294:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 23:13:48,295:INFO:Starting cross validation
2023-06-12 23:13:48,299:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 23:13:53,180:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:13:53,856:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:13:54,009:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:13:56,548:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:13:56,581:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:14:08,918:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 23:14:08,959:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 23:14:11,318:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:14:12,377:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:14:12,446:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:14:13,173:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 23:14:13,213:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 23:14:14,625:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:14:14,717:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:14:15,822:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:14:15,895:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:14:19,587:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:14:19,597:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.97s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:14:20,403:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-12 23:14:21,016:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 23:14:21,161:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 23:14:34,666:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:14:34,710:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:14:35,503:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 23:14:35,504:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 23:14:36,649:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:14:37,740:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:14:37,818:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:14:41,305:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:14:41,435:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:14:42,987:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 23:14:43,018:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 23:14:55,041:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:14:55,041:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:14:55,978:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:14:56,010:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:14:56,688:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 23:14:56,763:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 23:14:57,930:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:14:58,890:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:14:58,930:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:15:02,298:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:15:02,519:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:15:16,138:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:15:16,598:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:15:17,185:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 23:15:17,553:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 23:15:18,483:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:15:18,967:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:15:19,568:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:15:20,000:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:15:23,212:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:15:23,536:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:17:15,114:INFO:Calculating mean and std
2023-06-12 23:17:15,115:INFO:Creating metrics dataframe
2023-06-12 23:17:15,120:INFO:Finalizing model
2023-06-12 23:17:34,311:INFO:Creating Dashboard logs
2023-06-12 23:17:34,311:INFO:Model: Light Gradient Boosting Machine
2023-06-12 23:17:34,431:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 3545, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 23:17:34,811:INFO:Initializing predict_model()
2023-06-12 23:17:34,811:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC1C5C700>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3545, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017ED051B520>)
2023-06-12 23:17:34,811:INFO:Checking exceptions
2023-06-12 23:17:34,811:INFO:Preloading libraries
2023-06-12 23:17:50,770:INFO:Uploading results into container
2023-06-12 23:17:50,785:INFO:Uploading model into container now
2023-06-12 23:17:50,802:INFO:_master_model_container: 1
2023-06-12 23:17:50,802:INFO:_display_container: 2
2023-06-12 23:17:50,803:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3545, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 23:17:50,803:INFO:create_model() successfully completed......................................
2023-06-12 23:17:50,901:INFO:Initializing finalize_model()
2023-06-12 23:17:50,901:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC1C5C700>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3545, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-12 23:17:50,902:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3545, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 23:17:50,955:INFO:Initializing create_model()
2023-06-12 23:17:50,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC1C5C700>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3545, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-12 23:17:50,955:INFO:Checking exceptions
2023-06-12 23:17:50,955:INFO:Importing libraries
2023-06-12 23:17:50,955:INFO:Copying training dataset
2023-06-12 23:17:50,955:INFO:Defining folds
2023-06-12 23:17:50,955:INFO:Declaring metric variables
2023-06-12 23:17:50,955:INFO:Importing untrained model
2023-06-12 23:17:50,955:INFO:Declaring custom model
2023-06-12 23:17:50,955:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 23:17:50,955:INFO:Cross validation set to False
2023-06-12 23:17:50,955:INFO:Fitting Model
2023-06-12 23:17:55,487:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=3545, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:17:55,487:INFO:create_model() successfully completed......................................
2023-06-12 23:17:55,605:INFO:Creating Dashboard logs
2023-06-12 23:17:55,605:INFO:Model: Light Gradient Boosting Machine
2023-06-12 23:17:55,751:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 3545, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 23:17:56,200:INFO:_master_model_container: 1
2023-06-12 23:17:56,200:INFO:_display_container: 2
2023-06-12 23:17:56,216:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=3545, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:17:56,216:INFO:finalize_model() successfully completed......................................
2023-06-12 23:17:56,321:INFO:Initializing save_model()
2023-06-12 23:17:56,321:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=3545, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=models/bs_predictor_brawlBall, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 23:17:56,321:INFO:Adding model into prep_pipe
2023-06-12 23:17:56,321:WARNING:Only Model saved as it was a pipeline.
2023-06-12 23:17:56,336:INFO:models/bs_predictor_brawlBall.pkl saved in current working directory
2023-06-12 23:17:56,369:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=3545, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:17:56,369:INFO:save_model() successfully completed......................................
2023-06-12 23:17:56,485:INFO:Initializing predict_model()
2023-06-12 23:17:56,485:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC1C5C700>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=3545, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017EB302F7F0>)
2023-06-12 23:17:56,485:INFO:Checking exceptions
2023-06-12 23:17:56,485:INFO:Preloading libraries
2023-06-12 23:17:56,485:INFO:Set up data.
2023-06-12 23:17:56,538:INFO:Set up index.
2023-06-12 23:18:13,736:INFO:PyCaret ClassificationExperiment
2023-06-12 23:18:13,737:INFO:Logging name: clf-default-name
2023-06-12 23:18:13,737:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 23:18:13,738:INFO:version 3.0.2
2023-06-12 23:18:13,738:INFO:Initializing setup()
2023-06-12 23:18:13,738:INFO:self.USI: 36ad
2023-06-12 23:18:13,738:INFO:self._variable_keys: {'fold_groups_param', 'exp_name_log', 'y_test', 'log_plots_param', 'fix_imbalance', 'fold_generator', 'gpu_n_jobs_param', 'n_jobs_param', 'y', 'html_param', '_available_plots', 'memory', 'gpu_param', 'X_train', 'X', 'USI', 'seed', 'target_param', 'pipeline', 'data', '_ml_usecase', 'logging_param', 'fold_shuffle_param', 'idx', 'y_train', 'X_test', 'is_multiclass', 'exp_id'}
2023-06-12 23:18:13,738:INFO:Checking environment
2023-06-12 23:18:13,738:INFO:python_version: 3.10.10
2023-06-12 23:18:13,739:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 23:18:13,739:INFO:machine: AMD64
2023-06-12 23:18:13,740:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 23:18:13,743:INFO:Memory: svmem(total=17034072064, available=7672393728, percent=55.0, used=9361678336, free=7672393728)
2023-06-12 23:18:13,746:INFO:Physical Core: 2
2023-06-12 23:18:13,746:INFO:Logical Core: 4
2023-06-12 23:18:13,746:INFO:Checking libraries
2023-06-12 23:18:13,746:INFO:System:
2023-06-12 23:18:13,746:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 23:18:13,746:INFO:executable: C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 23:18:13,747:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 23:18:13,747:INFO:PyCaret required dependencies:
2023-06-12 23:18:13,747:INFO:                 pip: 23.1.2
2023-06-12 23:18:13,747:INFO:          setuptools: 65.5.0
2023-06-12 23:18:13,747:INFO:             pycaret: 3.0.2
2023-06-12 23:18:13,748:INFO:             IPython: 8.14.0
2023-06-12 23:18:13,748:INFO:          ipywidgets: 8.0.6
2023-06-12 23:18:13,748:INFO:                tqdm: 4.65.0
2023-06-12 23:18:13,748:INFO:               numpy: 1.23.5
2023-06-12 23:18:13,748:INFO:              pandas: 1.5.3
2023-06-12 23:18:13,749:INFO:              jinja2: 3.1.2
2023-06-12 23:18:13,749:INFO:               scipy: 1.10.1
2023-06-12 23:18:13,750:INFO:              joblib: 1.2.0
2023-06-12 23:18:13,750:INFO:             sklearn: 1.2.2
2023-06-12 23:18:13,750:INFO:                pyod: 1.0.9
2023-06-12 23:18:13,751:INFO:            imblearn: 0.10.1
2023-06-12 23:18:13,751:INFO:   category_encoders: 2.6.1
2023-06-12 23:18:13,751:INFO:            lightgbm: 3.3.5
2023-06-12 23:18:13,751:INFO:               numba: 0.57.0
2023-06-12 23:18:13,752:INFO:            requests: 2.31.0
2023-06-12 23:18:13,752:INFO:          matplotlib: 3.7.1
2023-06-12 23:18:13,752:INFO:          scikitplot: 0.3.7
2023-06-12 23:18:13,752:INFO:         yellowbrick: 1.5
2023-06-12 23:18:13,752:INFO:              plotly: 5.15.0
2023-06-12 23:18:13,753:INFO:             kaleido: 0.2.1
2023-06-12 23:18:13,753:INFO:         statsmodels: 0.14.0
2023-06-12 23:18:13,753:INFO:              sktime: 0.17.0
2023-06-12 23:18:13,753:INFO:               tbats: 1.1.3
2023-06-12 23:18:13,754:INFO:            pmdarima: 2.0.3
2023-06-12 23:18:13,754:INFO:              psutil: 5.9.5
2023-06-12 23:18:13,754:INFO:PyCaret optional dependencies:
2023-06-12 23:18:13,754:INFO:                shap: Not installed
2023-06-12 23:18:13,754:INFO:           interpret: Not installed
2023-06-12 23:18:13,754:INFO:                umap: Not installed
2023-06-12 23:18:13,755:INFO:    pandas_profiling: Not installed
2023-06-12 23:18:13,755:INFO:  explainerdashboard: Not installed
2023-06-12 23:18:13,755:INFO:             autoviz: Not installed
2023-06-12 23:18:13,755:INFO:           fairlearn: Not installed
2023-06-12 23:18:13,755:INFO:             xgboost: Not installed
2023-06-12 23:18:13,756:INFO:            catboost: Not installed
2023-06-12 23:18:13,756:INFO:              kmodes: Not installed
2023-06-12 23:18:13,756:INFO:             mlxtend: Not installed
2023-06-12 23:18:13,756:INFO:       statsforecast: Not installed
2023-06-12 23:18:13,757:INFO:        tune_sklearn: Not installed
2023-06-12 23:18:13,758:INFO:                 ray: Not installed
2023-06-12 23:18:13,758:INFO:            hyperopt: Not installed
2023-06-12 23:18:13,759:INFO:              optuna: Not installed
2023-06-12 23:18:13,759:INFO:               skopt: Not installed
2023-06-12 23:18:13,759:INFO:              mlflow: 2.4.1
2023-06-12 23:18:13,759:INFO:              gradio: Not installed
2023-06-12 23:18:13,759:INFO:             fastapi: Not installed
2023-06-12 23:18:13,760:INFO:             uvicorn: Not installed
2023-06-12 23:18:13,760:INFO:              m2cgen: Not installed
2023-06-12 23:18:13,760:INFO:           evidently: Not installed
2023-06-12 23:18:13,760:INFO:               fugue: Not installed
2023-06-12 23:18:13,760:INFO:           streamlit: 1.23.1
2023-06-12 23:18:13,760:INFO:             prophet: Not installed
2023-06-12 23:18:13,761:INFO:None
2023-06-12 23:18:13,761:INFO:Set up data.
2023-06-12 23:18:13,852:INFO:Set up train/test split.
2023-06-12 23:18:13,875:INFO:Set up index.
2023-06-12 23:18:13,876:INFO:Set up folding strategy.
2023-06-12 23:18:13,876:INFO:Assigning column types.
2023-06-12 23:18:13,901:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 23:18:13,971:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 23:18:13,972:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:18:14,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:18:14,008:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:18:14,065:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 23:18:14,067:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:18:14,101:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:18:14,102:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:18:14,103:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 23:18:14,160:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:18:14,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:18:14,196:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:18:14,252:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:18:14,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:18:14,283:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:18:14,284:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 23:18:14,367:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:18:14,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:18:14,449:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:18:14,449:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:18:14,451:INFO:Preparing preprocessing pipeline...
2023-06-12 23:18:14,454:INFO:Set up label encoding.
2023-06-12 23:18:14,454:INFO:Set up simple imputation.
2023-06-12 23:18:14,463:INFO:Set up encoding of categorical features.
2023-06-12 23:18:14,466:INFO:Set up column name cleaning.
2023-06-12 23:18:14,715:INFO:Finished creating preprocessing pipeline.
2023-06-12 23:18:14,724:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-12 23:18:14,724:INFO:Creating final display dataframe.
2023-06-12 23:18:15,745:INFO:Setup _display_container:                     Description             Value
0                    Session id              3800
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape       (9138, 142)
5        Transformed data shape       (9138, 151)
6   Transformed train set shape       (6396, 151)
7    Transformed test set shape       (2742, 151)
8              Numeric features               140
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              36ad
2023-06-12 23:18:15,860:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:18:15,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:18:15,936:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:18:15,936:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:18:15,937:INFO:Logging experiment in loggers
2023-06-12 23:18:16,218:INFO:SubProcess save_model() called ==================================
2023-06-12 23:18:16,235:INFO:Initializing save_model()
2023-06-12 23:18:16,235:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmp8cizssju\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 23:18:16,235:INFO:Adding model into prep_pipe
2023-06-12 23:18:16,236:WARNING:Only Model saved as it was a pipeline.
2023-06-12 23:18:16,249:INFO:C:\Users\alniquia\AppData\Local\Temp\tmp8cizssju\Transformation Pipeline.pkl saved in current working directory
2023-06-12 23:18:16,256:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-12 23:18:16,257:INFO:save_model() successfully completed......................................
2023-06-12 23:18:16,352:INFO:SubProcess save_model() end ==================================
2023-06-12 23:18:16,382:INFO:setup() successfully completed in 17.93s...............
2023-06-12 23:18:32,574:INFO:Initializing create_model()
2023-06-12 23:18:32,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2C4D330>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 23:18:32,575:INFO:Checking exceptions
2023-06-12 23:18:32,576:INFO:Importing libraries
2023-06-12 23:18:32,576:INFO:Copying training dataset
2023-06-12 23:18:32,604:INFO:Defining folds
2023-06-12 23:18:32,604:INFO:Declaring metric variables
2023-06-12 23:18:32,605:INFO:Importing untrained model
2023-06-12 23:18:32,605:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 23:18:32,605:INFO:Starting cross validation
2023-06-12 23:18:32,607:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 23:18:33,725:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:18:34,438:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.21s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:18:35,023:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.32s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:18:35,412:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.48s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:18:35,507:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.25s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:18:36,037:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:18:36,926:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:18:37,251:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 23:18:38,210:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 23:19:06,212:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:19:06,273:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:19:07,044:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:19:07,313:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:19:07,433:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:19:08,146:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 23:21:30,866:INFO:Calculating mean and std
2023-06-12 23:21:30,882:INFO:Creating metrics dataframe
2023-06-12 23:21:30,887:INFO:Finalizing model
2023-06-12 23:21:50,505:INFO:Creating Dashboard logs
2023-06-12 23:21:50,506:INFO:Model: Light Gradient Boosting Machine
2023-06-12 23:21:50,705:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 3800, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 23:21:51,035:INFO:Initializing predict_model()
2023-06-12 23:21:51,035:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2C4D330>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3800, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017ED051B1C0>)
2023-06-12 23:21:51,035:INFO:Checking exceptions
2023-06-12 23:21:51,035:INFO:Preloading libraries
2023-06-12 23:22:06,171:INFO:Uploading results into container
2023-06-12 23:22:06,179:INFO:Uploading model into container now
2023-06-12 23:22:06,196:INFO:_master_model_container: 1
2023-06-12 23:22:06,196:INFO:_display_container: 2
2023-06-12 23:22:06,197:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3800, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 23:22:06,197:INFO:create_model() successfully completed......................................
2023-06-12 23:22:06,296:INFO:Initializing finalize_model()
2023-06-12 23:22:06,296:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2C4D330>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3800, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-12 23:22:06,297:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3800, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 23:22:06,307:INFO:Initializing create_model()
2023-06-12 23:22:06,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2C4D330>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3800, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-12 23:22:06,307:INFO:Checking exceptions
2023-06-12 23:22:06,308:INFO:Importing libraries
2023-06-12 23:22:06,308:INFO:Copying training dataset
2023-06-12 23:22:06,309:INFO:Defining folds
2023-06-12 23:22:06,309:INFO:Declaring metric variables
2023-06-12 23:22:06,309:INFO:Importing untrained model
2023-06-12 23:22:06,309:INFO:Declaring custom model
2023-06-12 23:22:06,310:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 23:22:06,311:INFO:Cross validation set to False
2023-06-12 23:22:06,311:INFO:Fitting Model
2023-06-12 23:22:07,056:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=3800, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:22:07,056:INFO:create_model() successfully completed......................................
2023-06-12 23:22:07,172:INFO:Creating Dashboard logs
2023-06-12 23:22:07,172:INFO:Model: Light Gradient Boosting Machine
2023-06-12 23:22:07,295:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 3800, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 23:22:07,711:INFO:_master_model_container: 1
2023-06-12 23:22:07,711:INFO:_display_container: 2
2023-06-12 23:22:07,719:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=3800, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:22:07,719:INFO:finalize_model() successfully completed......................................
2023-06-12 23:22:22,841:INFO:Initializing save_model()
2023-06-12 23:22:22,841:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=3800, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=models/bs_predictor_heist, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 23:22:22,841:INFO:Adding model into prep_pipe
2023-06-12 23:22:22,841:WARNING:Only Model saved as it was a pipeline.
2023-06-12 23:22:22,857:INFO:models/bs_predictor_heist.pkl saved in current working directory
2023-06-12 23:22:22,881:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=3800, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:22:22,881:INFO:save_model() successfully completed......................................
2023-06-12 23:22:23,011:INFO:Initializing predict_model()
2023-06-12 23:22:23,011:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2C4D330>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=3800, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017EC1C2F400>)
2023-06-12 23:22:23,012:INFO:Checking exceptions
2023-06-12 23:22:23,012:INFO:Preloading libraries
2023-06-12 23:22:23,012:INFO:Set up data.
2023-06-12 23:22:23,047:INFO:Set up index.
2023-06-12 23:22:38,353:INFO:PyCaret ClassificationExperiment
2023-06-12 23:22:38,353:INFO:Logging name: clf-default-name
2023-06-12 23:22:38,354:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 23:22:38,354:INFO:version 3.0.2
2023-06-12 23:22:38,354:INFO:Initializing setup()
2023-06-12 23:22:38,354:INFO:self.USI: 403f
2023-06-12 23:22:38,354:INFO:self._variable_keys: {'fold_groups_param', 'exp_name_log', 'y_test', 'log_plots_param', 'fix_imbalance', 'fold_generator', 'gpu_n_jobs_param', 'n_jobs_param', 'y', 'html_param', '_available_plots', 'memory', 'gpu_param', 'X_train', 'X', 'USI', 'seed', 'target_param', 'pipeline', 'data', '_ml_usecase', 'logging_param', 'fold_shuffle_param', 'idx', 'y_train', 'X_test', 'is_multiclass', 'exp_id'}
2023-06-12 23:22:38,355:INFO:Checking environment
2023-06-12 23:22:38,355:INFO:python_version: 3.10.10
2023-06-12 23:22:38,355:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 23:22:38,356:INFO:machine: AMD64
2023-06-12 23:22:38,356:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 23:22:38,359:INFO:Memory: svmem(total=17034072064, available=7588634624, percent=55.5, used=9445437440, free=7588634624)
2023-06-12 23:22:38,359:INFO:Physical Core: 2
2023-06-12 23:22:38,359:INFO:Logical Core: 4
2023-06-12 23:22:38,359:INFO:Checking libraries
2023-06-12 23:22:38,360:INFO:System:
2023-06-12 23:22:38,360:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 23:22:38,360:INFO:executable: C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 23:22:38,360:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 23:22:38,361:INFO:PyCaret required dependencies:
2023-06-12 23:22:38,361:INFO:                 pip: 23.1.2
2023-06-12 23:22:38,361:INFO:          setuptools: 65.5.0
2023-06-12 23:22:38,361:INFO:             pycaret: 3.0.2
2023-06-12 23:22:38,361:INFO:             IPython: 8.14.0
2023-06-12 23:22:38,362:INFO:          ipywidgets: 8.0.6
2023-06-12 23:22:38,362:INFO:                tqdm: 4.65.0
2023-06-12 23:22:38,362:INFO:               numpy: 1.23.5
2023-06-12 23:22:38,362:INFO:              pandas: 1.5.3
2023-06-12 23:22:38,363:INFO:              jinja2: 3.1.2
2023-06-12 23:22:38,363:INFO:               scipy: 1.10.1
2023-06-12 23:22:38,363:INFO:              joblib: 1.2.0
2023-06-12 23:22:38,363:INFO:             sklearn: 1.2.2
2023-06-12 23:22:38,364:INFO:                pyod: 1.0.9
2023-06-12 23:22:38,364:INFO:            imblearn: 0.10.1
2023-06-12 23:22:38,364:INFO:   category_encoders: 2.6.1
2023-06-12 23:22:38,364:INFO:            lightgbm: 3.3.5
2023-06-12 23:22:38,365:INFO:               numba: 0.57.0
2023-06-12 23:22:38,365:INFO:            requests: 2.31.0
2023-06-12 23:22:38,365:INFO:          matplotlib: 3.7.1
2023-06-12 23:22:38,365:INFO:          scikitplot: 0.3.7
2023-06-12 23:22:38,365:INFO:         yellowbrick: 1.5
2023-06-12 23:22:38,365:INFO:              plotly: 5.15.0
2023-06-12 23:22:38,366:INFO:             kaleido: 0.2.1
2023-06-12 23:22:38,366:INFO:         statsmodels: 0.14.0
2023-06-12 23:22:38,366:INFO:              sktime: 0.17.0
2023-06-12 23:22:38,366:INFO:               tbats: 1.1.3
2023-06-12 23:22:38,366:INFO:            pmdarima: 2.0.3
2023-06-12 23:22:38,367:INFO:              psutil: 5.9.5
2023-06-12 23:22:38,367:INFO:PyCaret optional dependencies:
2023-06-12 23:22:38,367:INFO:                shap: Not installed
2023-06-12 23:22:38,368:INFO:           interpret: Not installed
2023-06-12 23:22:38,368:INFO:                umap: Not installed
2023-06-12 23:22:38,368:INFO:    pandas_profiling: Not installed
2023-06-12 23:22:38,368:INFO:  explainerdashboard: Not installed
2023-06-12 23:22:38,368:INFO:             autoviz: Not installed
2023-06-12 23:22:38,369:INFO:           fairlearn: Not installed
2023-06-12 23:22:38,369:INFO:             xgboost: Not installed
2023-06-12 23:22:38,369:INFO:            catboost: Not installed
2023-06-12 23:22:38,369:INFO:              kmodes: Not installed
2023-06-12 23:22:38,369:INFO:             mlxtend: Not installed
2023-06-12 23:22:38,370:INFO:       statsforecast: Not installed
2023-06-12 23:22:38,370:INFO:        tune_sklearn: Not installed
2023-06-12 23:22:38,370:INFO:                 ray: Not installed
2023-06-12 23:22:38,370:INFO:            hyperopt: Not installed
2023-06-12 23:22:38,371:INFO:              optuna: Not installed
2023-06-12 23:22:38,371:INFO:               skopt: Not installed
2023-06-12 23:22:38,371:INFO:              mlflow: 2.4.1
2023-06-12 23:22:38,371:INFO:              gradio: Not installed
2023-06-12 23:22:38,371:INFO:             fastapi: Not installed
2023-06-12 23:22:38,372:INFO:             uvicorn: Not installed
2023-06-12 23:22:38,372:INFO:              m2cgen: Not installed
2023-06-12 23:22:38,372:INFO:           evidently: Not installed
2023-06-12 23:22:38,372:INFO:               fugue: Not installed
2023-06-12 23:22:38,372:INFO:           streamlit: 1.23.1
2023-06-12 23:22:38,373:INFO:             prophet: Not installed
2023-06-12 23:22:38,373:INFO:None
2023-06-12 23:22:38,374:INFO:Set up data.
2023-06-12 23:22:38,438:INFO:Set up train/test split.
2023-06-12 23:22:38,503:INFO:Set up index.
2023-06-12 23:22:38,505:INFO:Set up folding strategy.
2023-06-12 23:22:38,505:INFO:Assigning column types.
2023-06-12 23:22:38,538:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 23:22:38,587:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 23:22:38,587:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:22:38,618:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:22:38,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:22:38,665:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 23:22:38,665:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:22:38,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:22:38,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:22:38,697:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 23:22:38,739:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:22:38,755:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:22:38,755:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:22:38,801:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:22:38,833:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:22:38,833:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:22:38,833:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 23:22:38,917:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:22:38,917:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:22:38,994:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:22:38,994:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:22:38,995:INFO:Preparing preprocessing pipeline...
2023-06-12 23:22:39,000:INFO:Set up label encoding.
2023-06-12 23:22:39,000:INFO:Set up simple imputation.
2023-06-12 23:22:39,023:INFO:Set up encoding of categorical features.
2023-06-12 23:22:39,028:INFO:Set up column name cleaning.
2023-06-12 23:22:39,703:INFO:Finished creating preprocessing pipeline.
2023-06-12 23:22:39,711:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-12 23:22:39,711:INFO:Creating final display dataframe.
2023-06-12 23:22:41,262:INFO:Setup _display_container:                     Description             Value
0                    Session id              6178
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape      (32355, 142)
5        Transformed data shape      (32355, 151)
6   Transformed train set shape      (22648, 151)
7    Transformed test set shape       (9707, 151)
8              Numeric features               140
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              403f
2023-06-12 23:22:41,374:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:22:41,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:22:41,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:22:41,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:22:41,451:INFO:Logging experiment in loggers
2023-06-12 23:22:41,649:INFO:SubProcess save_model() called ==================================
2023-06-12 23:22:41,665:INFO:Initializing save_model()
2023-06-12 23:22:41,665:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmpuja3_c25\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 23:22:41,665:INFO:Adding model into prep_pipe
2023-06-12 23:22:41,665:WARNING:Only Model saved as it was a pipeline.
2023-06-12 23:22:41,665:INFO:C:\Users\alniquia\AppData\Local\Temp\tmpuja3_c25\Transformation Pipeline.pkl saved in current working directory
2023-06-12 23:22:41,665:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-12 23:22:41,665:INFO:save_model() successfully completed......................................
2023-06-12 23:22:41,753:INFO:SubProcess save_model() end ==================================
2023-06-12 23:22:41,769:INFO:setup() successfully completed in 18.0s...............
2023-06-12 23:22:56,705:INFO:Initializing create_model()
2023-06-12 23:22:56,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2C4D6C0>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 23:22:56,705:INFO:Checking exceptions
2023-06-12 23:22:56,707:INFO:Importing libraries
2023-06-12 23:22:56,707:INFO:Copying training dataset
2023-06-12 23:22:56,773:INFO:Defining folds
2023-06-12 23:22:56,773:INFO:Declaring metric variables
2023-06-12 23:22:56,774:INFO:Importing untrained model
2023-06-12 23:22:56,774:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 23:22:56,774:INFO:Starting cross validation
2023-06-12 23:22:56,776:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 23:23:27,580:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-12 23:23:28,331:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:23:29,147:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:23:29,456:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:23:30,821:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:25:55,801:INFO:Calculating mean and std
2023-06-12 23:25:55,802:INFO:Creating metrics dataframe
2023-06-12 23:25:55,806:INFO:Finalizing model
2023-06-12 23:26:17,197:INFO:Creating Dashboard logs
2023-06-12 23:26:17,198:INFO:Model: Light Gradient Boosting Machine
2023-06-12 23:26:27,261:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6178, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 23:26:31,981:INFO:Initializing predict_model()
2023-06-12 23:26:31,982:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2C4D6C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6178, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017F117D60E0>)
2023-06-12 23:26:31,983:INFO:Checking exceptions
2023-06-12 23:26:31,984:INFO:Preloading libraries
2023-06-12 23:26:56,122:INFO:Uploading results into container
2023-06-12 23:26:56,123:INFO:Uploading model into container now
2023-06-12 23:26:56,136:INFO:_master_model_container: 1
2023-06-12 23:26:56,136:INFO:_display_container: 2
2023-06-12 23:26:56,137:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6178, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 23:26:56,137:INFO:create_model() successfully completed......................................
2023-06-12 23:26:56,239:INFO:Initializing finalize_model()
2023-06-12 23:26:56,239:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2C4D6C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6178, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-12 23:26:56,240:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6178, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 23:26:56,262:INFO:Initializing create_model()
2023-06-12 23:26:56,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2C4D6C0>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6178, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-12 23:26:56,263:INFO:Checking exceptions
2023-06-12 23:26:56,263:INFO:Importing libraries
2023-06-12 23:26:56,264:INFO:Copying training dataset
2023-06-12 23:26:56,266:INFO:Defining folds
2023-06-12 23:26:56,266:INFO:Declaring metric variables
2023-06-12 23:26:56,266:INFO:Importing untrained model
2023-06-12 23:26:56,266:INFO:Declaring custom model
2023-06-12 23:26:56,267:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 23:26:56,269:INFO:Cross validation set to False
2023-06-12 23:26:56,269:INFO:Fitting Model
2023-06-12 23:26:58,161:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6178, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:26:58,161:INFO:create_model() successfully completed......................................
2023-06-12 23:26:58,279:INFO:Creating Dashboard logs
2023-06-12 23:26:58,280:INFO:Model: Light Gradient Boosting Machine
2023-06-12 23:27:07,291:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6178, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 23:27:13,365:INFO:_master_model_container: 1
2023-06-12 23:27:13,365:INFO:_display_container: 2
2023-06-12 23:27:13,374:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6178, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:27:13,374:INFO:finalize_model() successfully completed......................................
2023-06-12 23:27:29,154:INFO:Initializing save_model()
2023-06-12 23:27:29,154:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6178, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=models/bs_predictor_gemGrab, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 23:27:29,154:INFO:Adding model into prep_pipe
2023-06-12 23:27:29,154:WARNING:Only Model saved as it was a pipeline.
2023-06-12 23:27:29,173:INFO:models/bs_predictor_gemGrab.pkl saved in current working directory
2023-06-12 23:27:29,194:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6178, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:27:29,194:INFO:save_model() successfully completed......................................
2023-06-12 23:27:29,324:INFO:Initializing predict_model()
2023-06-12 23:27:29,325:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2C4D6C0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6178, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017ED051B760>)
2023-06-12 23:27:29,325:INFO:Checking exceptions
2023-06-12 23:27:29,325:INFO:Preloading libraries
2023-06-12 23:27:29,325:INFO:Set up data.
2023-06-12 23:27:29,366:INFO:Set up index.
2023-06-12 23:27:47,231:INFO:PyCaret ClassificationExperiment
2023-06-12 23:27:47,231:INFO:Logging name: clf-default-name
2023-06-12 23:27:47,232:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 23:27:47,232:INFO:version 3.0.2
2023-06-12 23:27:47,232:INFO:Initializing setup()
2023-06-12 23:27:47,232:INFO:self.USI: b960
2023-06-12 23:27:47,233:INFO:self._variable_keys: {'fold_groups_param', 'exp_name_log', 'y_test', 'log_plots_param', 'fix_imbalance', 'fold_generator', 'gpu_n_jobs_param', 'n_jobs_param', 'y', 'html_param', '_available_plots', 'memory', 'gpu_param', 'X_train', 'X', 'USI', 'seed', 'target_param', 'pipeline', 'data', '_ml_usecase', 'logging_param', 'fold_shuffle_param', 'idx', 'y_train', 'X_test', 'is_multiclass', 'exp_id'}
2023-06-12 23:27:47,233:INFO:Checking environment
2023-06-12 23:27:47,233:INFO:python_version: 3.10.10
2023-06-12 23:27:47,233:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 23:27:47,234:INFO:machine: AMD64
2023-06-12 23:27:47,234:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 23:27:47,236:INFO:Memory: svmem(total=17034072064, available=7816171520, percent=54.1, used=9217900544, free=7816171520)
2023-06-12 23:27:47,237:INFO:Physical Core: 2
2023-06-12 23:27:47,237:INFO:Logical Core: 4
2023-06-12 23:27:47,237:INFO:Checking libraries
2023-06-12 23:27:47,238:INFO:System:
2023-06-12 23:27:47,238:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 23:27:47,238:INFO:executable: C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 23:27:47,238:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 23:27:47,239:INFO:PyCaret required dependencies:
2023-06-12 23:27:47,239:INFO:                 pip: 23.1.2
2023-06-12 23:27:47,239:INFO:          setuptools: 65.5.0
2023-06-12 23:27:47,240:INFO:             pycaret: 3.0.2
2023-06-12 23:27:47,240:INFO:             IPython: 8.14.0
2023-06-12 23:27:47,240:INFO:          ipywidgets: 8.0.6
2023-06-12 23:27:47,240:INFO:                tqdm: 4.65.0
2023-06-12 23:27:47,240:INFO:               numpy: 1.23.5
2023-06-12 23:27:47,241:INFO:              pandas: 1.5.3
2023-06-12 23:27:47,241:INFO:              jinja2: 3.1.2
2023-06-12 23:27:47,241:INFO:               scipy: 1.10.1
2023-06-12 23:27:47,241:INFO:              joblib: 1.2.0
2023-06-12 23:27:47,241:INFO:             sklearn: 1.2.2
2023-06-12 23:27:47,242:INFO:                pyod: 1.0.9
2023-06-12 23:27:47,242:INFO:            imblearn: 0.10.1
2023-06-12 23:27:47,242:INFO:   category_encoders: 2.6.1
2023-06-12 23:27:47,242:INFO:            lightgbm: 3.3.5
2023-06-12 23:27:47,243:INFO:               numba: 0.57.0
2023-06-12 23:27:47,243:INFO:            requests: 2.31.0
2023-06-12 23:27:47,243:INFO:          matplotlib: 3.7.1
2023-06-12 23:27:47,243:INFO:          scikitplot: 0.3.7
2023-06-12 23:27:47,243:INFO:         yellowbrick: 1.5
2023-06-12 23:27:47,244:INFO:              plotly: 5.15.0
2023-06-12 23:27:47,244:INFO:             kaleido: 0.2.1
2023-06-12 23:27:47,244:INFO:         statsmodels: 0.14.0
2023-06-12 23:27:47,244:INFO:              sktime: 0.17.0
2023-06-12 23:27:47,244:INFO:               tbats: 1.1.3
2023-06-12 23:27:47,245:INFO:            pmdarima: 2.0.3
2023-06-12 23:27:47,245:INFO:              psutil: 5.9.5
2023-06-12 23:27:47,245:INFO:PyCaret optional dependencies:
2023-06-12 23:27:47,246:INFO:                shap: Not installed
2023-06-12 23:27:47,246:INFO:           interpret: Not installed
2023-06-12 23:27:47,246:INFO:                umap: Not installed
2023-06-12 23:27:47,246:INFO:    pandas_profiling: Not installed
2023-06-12 23:27:47,247:INFO:  explainerdashboard: Not installed
2023-06-12 23:27:47,247:INFO:             autoviz: Not installed
2023-06-12 23:27:47,248:INFO:           fairlearn: Not installed
2023-06-12 23:27:47,248:INFO:             xgboost: Not installed
2023-06-12 23:27:47,248:INFO:            catboost: Not installed
2023-06-12 23:27:47,248:INFO:              kmodes: Not installed
2023-06-12 23:27:47,248:INFO:             mlxtend: Not installed
2023-06-12 23:27:47,248:INFO:       statsforecast: Not installed
2023-06-12 23:27:47,249:INFO:        tune_sklearn: Not installed
2023-06-12 23:27:47,249:INFO:                 ray: Not installed
2023-06-12 23:27:47,249:INFO:            hyperopt: Not installed
2023-06-12 23:27:47,249:INFO:              optuna: Not installed
2023-06-12 23:27:47,249:INFO:               skopt: Not installed
2023-06-12 23:27:47,250:INFO:              mlflow: 2.4.1
2023-06-12 23:27:47,250:INFO:              gradio: Not installed
2023-06-12 23:27:47,250:INFO:             fastapi: Not installed
2023-06-12 23:27:47,250:INFO:             uvicorn: Not installed
2023-06-12 23:27:47,250:INFO:              m2cgen: Not installed
2023-06-12 23:27:47,251:INFO:           evidently: Not installed
2023-06-12 23:27:47,251:INFO:               fugue: Not installed
2023-06-12 23:27:47,251:INFO:           streamlit: 1.23.1
2023-06-12 23:27:47,251:INFO:             prophet: Not installed
2023-06-12 23:27:47,252:INFO:None
2023-06-12 23:27:47,252:INFO:Set up data.
2023-06-12 23:27:47,333:INFO:Set up train/test split.
2023-06-12 23:27:47,374:INFO:Set up index.
2023-06-12 23:27:47,375:INFO:Set up folding strategy.
2023-06-12 23:27:47,375:INFO:Assigning column types.
2023-06-12 23:27:47,398:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 23:27:47,442:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 23:27:47,443:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:27:47,470:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:27:47,471:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:27:47,519:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 23:27:47,519:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:27:47,547:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:27:47,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:27:47,548:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 23:27:47,593:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:27:47,626:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:27:47,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:27:47,674:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:27:47,706:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:27:47,706:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:27:47,706:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 23:27:47,780:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:27:47,781:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:27:47,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:27:47,857:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:27:47,859:INFO:Preparing preprocessing pipeline...
2023-06-12 23:27:47,863:INFO:Set up label encoding.
2023-06-12 23:27:47,863:INFO:Set up simple imputation.
2023-06-12 23:27:47,883:INFO:Set up encoding of categorical features.
2023-06-12 23:27:47,887:INFO:Set up column name cleaning.
2023-06-12 23:27:49,589:INFO:Finished creating preprocessing pipeline.
2023-06-12 23:27:49,598:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-12 23:27:49,598:INFO:Creating final display dataframe.
2023-06-12 23:27:52,989:INFO:Setup _display_container:                     Description             Value
0                    Session id              6134
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape      (25088, 142)
5        Transformed data shape      (25088, 150)
6   Transformed train set shape      (17561, 150)
7    Transformed test set shape       (7527, 150)
8              Numeric features               140
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              b960
2023-06-12 23:27:53,088:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:27:53,088:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:27:53,165:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:27:53,165:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:27:53,166:INFO:Logging experiment in loggers
2023-06-12 23:28:03,480:INFO:SubProcess save_model() called ==================================
2023-06-12 23:28:03,499:INFO:Initializing save_model()
2023-06-12 23:28:03,500:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmp24t7u799\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 23:28:03,500:INFO:Adding model into prep_pipe
2023-06-12 23:28:03,500:WARNING:Only Model saved as it was a pipeline.
2023-06-12 23:28:03,507:INFO:C:\Users\alniquia\AppData\Local\Temp\tmp24t7u799\Transformation Pipeline.pkl saved in current working directory
2023-06-12 23:28:03,514:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-12 23:28:03,514:INFO:save_model() successfully completed......................................
2023-06-12 23:28:03,603:INFO:SubProcess save_model() end ==================================
2023-06-12 23:28:04,750:INFO:setup() successfully completed in 21.9s...............
2023-06-12 23:28:21,700:INFO:Initializing create_model()
2023-06-12 23:28:21,700:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC6EA1390>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 23:28:21,700:INFO:Checking exceptions
2023-06-12 23:28:21,701:INFO:Importing libraries
2023-06-12 23:28:21,701:INFO:Copying training dataset
2023-06-12 23:28:21,759:INFO:Defining folds
2023-06-12 23:28:21,759:INFO:Declaring metric variables
2023-06-12 23:28:21,759:INFO:Importing untrained model
2023-06-12 23:28:21,760:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 23:28:21,760:INFO:Starting cross validation
2023-06-12 23:28:21,762:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 23:29:00,400:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:29:00,455:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:29:00,556:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:29:01,359:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:29:01,480:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:29:01,545:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:29:01,621:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:29:02,970:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:29:03,012:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:29:03,170:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:29:03,180:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:29:04,020:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 23:31:18,818:INFO:Calculating mean and std
2023-06-12 23:31:18,819:INFO:Creating metrics dataframe
2023-06-12 23:31:18,824:INFO:Finalizing model
2023-06-12 23:31:36,220:INFO:Creating Dashboard logs
2023-06-12 23:31:36,220:INFO:Model: Light Gradient Boosting Machine
2023-06-12 23:31:36,298:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6134, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 23:31:36,590:INFO:Initializing predict_model()
2023-06-12 23:31:36,590:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC6EA1390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6134, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017ED0518550>)
2023-06-12 23:31:36,590:INFO:Checking exceptions
2023-06-12 23:31:36,590:INFO:Preloading libraries
2023-06-12 23:31:50,431:INFO:Uploading results into container
2023-06-12 23:31:50,443:INFO:Uploading model into container now
2023-06-12 23:31:50,461:INFO:_master_model_container: 1
2023-06-12 23:31:50,461:INFO:_display_container: 2
2023-06-12 23:31:50,462:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6134, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 23:31:50,463:INFO:create_model() successfully completed......................................
2023-06-12 23:31:50,553:INFO:Initializing finalize_model()
2023-06-12 23:31:50,553:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC6EA1390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6134, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-12 23:31:50,553:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6134, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 23:31:50,569:INFO:Initializing create_model()
2023-06-12 23:31:50,569:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC6EA1390>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6134, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-12 23:31:50,569:INFO:Checking exceptions
2023-06-12 23:31:50,569:INFO:Importing libraries
2023-06-12 23:31:50,569:INFO:Copying training dataset
2023-06-12 23:31:50,569:INFO:Defining folds
2023-06-12 23:31:50,569:INFO:Declaring metric variables
2023-06-12 23:31:50,569:INFO:Importing untrained model
2023-06-12 23:31:50,569:INFO:Declaring custom model
2023-06-12 23:31:50,569:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 23:31:50,569:INFO:Cross validation set to False
2023-06-12 23:31:50,569:INFO:Fitting Model
2023-06-12 23:31:52,201:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6134, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:31:52,201:INFO:create_model() successfully completed......................................
2023-06-12 23:31:52,327:INFO:Creating Dashboard logs
2023-06-12 23:31:52,328:INFO:Model: Light Gradient Boosting Machine
2023-06-12 23:31:52,522:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6134, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 23:31:52,924:INFO:_master_model_container: 1
2023-06-12 23:31:52,925:INFO:_display_container: 2
2023-06-12 23:31:52,934:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6134, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:31:52,934:INFO:finalize_model() successfully completed......................................
2023-06-12 23:32:06,704:INFO:Initializing save_model()
2023-06-12 23:32:06,704:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6134, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=models/bs_predictor_bounty, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 23:32:06,704:INFO:Adding model into prep_pipe
2023-06-12 23:32:06,704:WARNING:Only Model saved as it was a pipeline.
2023-06-12 23:32:06,722:INFO:models/bs_predictor_bounty.pkl saved in current working directory
2023-06-12 23:32:06,745:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6134, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:32:06,746:INFO:save_model() successfully completed......................................
2023-06-12 23:32:06,873:INFO:Initializing predict_model()
2023-06-12 23:32:06,873:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC6EA1390>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6134, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017EC1B9B9A0>)
2023-06-12 23:32:06,873:INFO:Checking exceptions
2023-06-12 23:32:06,873:INFO:Preloading libraries
2023-06-12 23:32:06,873:INFO:Set up data.
2023-06-12 23:32:06,921:INFO:Set up index.
2023-06-12 23:32:20,968:INFO:PyCaret ClassificationExperiment
2023-06-12 23:32:20,968:INFO:Logging name: clf-default-name
2023-06-12 23:32:20,968:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 23:32:20,968:INFO:version 3.0.2
2023-06-12 23:32:20,968:INFO:Initializing setup()
2023-06-12 23:32:20,968:INFO:self.USI: 1702
2023-06-12 23:32:20,968:INFO:self._variable_keys: {'fold_groups_param', 'exp_name_log', 'y_test', 'log_plots_param', 'fix_imbalance', 'fold_generator', 'gpu_n_jobs_param', 'n_jobs_param', 'y', 'html_param', '_available_plots', 'memory', 'gpu_param', 'X_train', 'X', 'USI', 'seed', 'target_param', 'pipeline', 'data', '_ml_usecase', 'logging_param', 'fold_shuffle_param', 'idx', 'y_train', 'X_test', 'is_multiclass', 'exp_id'}
2023-06-12 23:32:20,968:INFO:Checking environment
2023-06-12 23:32:20,968:INFO:python_version: 3.10.10
2023-06-12 23:32:20,968:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 23:32:20,968:INFO:machine: AMD64
2023-06-12 23:32:20,968:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 23:32:20,968:INFO:Memory: svmem(total=17034072064, available=7957692416, percent=53.3, used=9076379648, free=7957692416)
2023-06-12 23:32:20,968:INFO:Physical Core: 2
2023-06-12 23:32:20,968:INFO:Logical Core: 4
2023-06-12 23:32:20,968:INFO:Checking libraries
2023-06-12 23:32:20,968:INFO:System:
2023-06-12 23:32:20,968:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 23:32:20,968:INFO:executable: C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 23:32:20,984:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 23:32:20,984:INFO:PyCaret required dependencies:
2023-06-12 23:32:20,984:INFO:                 pip: 23.1.2
2023-06-12 23:32:20,985:INFO:          setuptools: 65.5.0
2023-06-12 23:32:20,985:INFO:             pycaret: 3.0.2
2023-06-12 23:32:20,985:INFO:             IPython: 8.14.0
2023-06-12 23:32:20,986:INFO:          ipywidgets: 8.0.6
2023-06-12 23:32:20,986:INFO:                tqdm: 4.65.0
2023-06-12 23:32:20,986:INFO:               numpy: 1.23.5
2023-06-12 23:32:20,986:INFO:              pandas: 1.5.3
2023-06-12 23:32:20,986:INFO:              jinja2: 3.1.2
2023-06-12 23:32:20,986:INFO:               scipy: 1.10.1
2023-06-12 23:32:20,987:INFO:              joblib: 1.2.0
2023-06-12 23:32:20,987:INFO:             sklearn: 1.2.2
2023-06-12 23:32:20,987:INFO:                pyod: 1.0.9
2023-06-12 23:32:20,987:INFO:            imblearn: 0.10.1
2023-06-12 23:32:20,987:INFO:   category_encoders: 2.6.1
2023-06-12 23:32:20,988:INFO:            lightgbm: 3.3.5
2023-06-12 23:32:20,988:INFO:               numba: 0.57.0
2023-06-12 23:32:20,988:INFO:            requests: 2.31.0
2023-06-12 23:32:20,988:INFO:          matplotlib: 3.7.1
2023-06-12 23:32:20,988:INFO:          scikitplot: 0.3.7
2023-06-12 23:32:20,989:INFO:         yellowbrick: 1.5
2023-06-12 23:32:20,989:INFO:              plotly: 5.15.0
2023-06-12 23:32:20,989:INFO:             kaleido: 0.2.1
2023-06-12 23:32:20,990:INFO:         statsmodels: 0.14.0
2023-06-12 23:32:20,990:INFO:              sktime: 0.17.0
2023-06-12 23:32:20,990:INFO:               tbats: 1.1.3
2023-06-12 23:32:20,990:INFO:            pmdarima: 2.0.3
2023-06-12 23:32:20,990:INFO:              psutil: 5.9.5
2023-06-12 23:32:20,991:INFO:PyCaret optional dependencies:
2023-06-12 23:32:20,991:INFO:                shap: Not installed
2023-06-12 23:32:20,991:INFO:           interpret: Not installed
2023-06-12 23:32:20,991:INFO:                umap: Not installed
2023-06-12 23:32:20,991:INFO:    pandas_profiling: Not installed
2023-06-12 23:32:20,992:INFO:  explainerdashboard: Not installed
2023-06-12 23:32:20,992:INFO:             autoviz: Not installed
2023-06-12 23:32:20,992:INFO:           fairlearn: Not installed
2023-06-12 23:32:20,992:INFO:             xgboost: Not installed
2023-06-12 23:32:20,992:INFO:            catboost: Not installed
2023-06-12 23:32:20,993:INFO:              kmodes: Not installed
2023-06-12 23:32:20,993:INFO:             mlxtend: Not installed
2023-06-12 23:32:20,993:INFO:       statsforecast: Not installed
2023-06-12 23:32:20,993:INFO:        tune_sklearn: Not installed
2023-06-12 23:32:20,993:INFO:                 ray: Not installed
2023-06-12 23:32:20,994:INFO:            hyperopt: Not installed
2023-06-12 23:32:20,994:INFO:              optuna: Not installed
2023-06-12 23:32:20,994:INFO:               skopt: Not installed
2023-06-12 23:32:20,994:INFO:              mlflow: 2.4.1
2023-06-12 23:32:20,994:INFO:              gradio: Not installed
2023-06-12 23:32:20,995:INFO:             fastapi: Not installed
2023-06-12 23:32:20,995:INFO:             uvicorn: Not installed
2023-06-12 23:32:20,995:INFO:              m2cgen: Not installed
2023-06-12 23:32:20,996:INFO:           evidently: Not installed
2023-06-12 23:32:20,996:INFO:               fugue: Not installed
2023-06-12 23:32:20,996:INFO:           streamlit: 1.23.1
2023-06-12 23:32:20,996:INFO:             prophet: Not installed
2023-06-12 23:32:20,997:INFO:None
2023-06-12 23:32:20,997:INFO:Set up data.
2023-06-12 23:32:21,068:INFO:Set up train/test split.
2023-06-12 23:32:21,083:INFO:Set up index.
2023-06-12 23:32:21,083:INFO:Set up folding strategy.
2023-06-12 23:32:21,083:INFO:Assigning column types.
2023-06-12 23:32:21,103:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 23:32:21,148:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 23:32:21,149:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:32:21,169:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:32:21,169:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:32:21,216:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 23:32:21,216:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:32:21,247:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:32:21,247:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:32:21,247:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 23:32:21,296:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:32:21,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:32:21,324:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:32:21,369:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:32:21,385:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:32:21,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:32:21,385:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 23:32:21,463:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:32:21,463:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:32:21,537:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:32:21,537:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:32:21,537:INFO:Preparing preprocessing pipeline...
2023-06-12 23:32:21,537:INFO:Set up label encoding.
2023-06-12 23:32:21,537:INFO:Set up simple imputation.
2023-06-12 23:32:21,552:INFO:Set up encoding of categorical features.
2023-06-12 23:32:21,552:INFO:Set up column name cleaning.
2023-06-12 23:32:21,768:INFO:Finished creating preprocessing pipeline.
2023-06-12 23:32:21,768:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-12 23:32:21,768:INFO:Creating final display dataframe.
2023-06-12 23:32:22,385:INFO:Setup _display_container:                     Description             Value
0                    Session id              5675
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape      (10055, 142)
5        Transformed data shape      (10055, 151)
6   Transformed train set shape       (7038, 151)
7    Transformed test set shape       (3017, 151)
8              Numeric features               140
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              1702
2023-06-12 23:32:22,503:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:32:22,503:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:32:22,567:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:32:22,567:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:32:22,567:INFO:Logging experiment in loggers
2023-06-12 23:32:22,718:INFO:SubProcess save_model() called ==================================
2023-06-12 23:32:22,734:INFO:Initializing save_model()
2023-06-12 23:32:22,734:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmp5privge3\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 23:32:22,734:INFO:Adding model into prep_pipe
2023-06-12 23:32:22,734:WARNING:Only Model saved as it was a pipeline.
2023-06-12 23:32:22,735:INFO:C:\Users\alniquia\AppData\Local\Temp\tmp5privge3\Transformation Pipeline.pkl saved in current working directory
2023-06-12 23:32:22,735:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-12 23:32:22,735:INFO:save_model() successfully completed......................................
2023-06-12 23:32:22,829:INFO:SubProcess save_model() end ==================================
2023-06-12 23:32:22,845:INFO:setup() successfully completed in 15.0s...............
2023-06-12 23:32:35,777:INFO:Initializing create_model()
2023-06-12 23:32:35,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2D10400>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 23:32:35,793:INFO:Checking exceptions
2023-06-12 23:32:35,793:INFO:Importing libraries
2023-06-12 23:32:35,793:INFO:Copying training dataset
2023-06-12 23:32:35,824:INFO:Defining folds
2023-06-12 23:32:35,824:INFO:Declaring metric variables
2023-06-12 23:32:35,824:INFO:Importing untrained model
2023-06-12 23:32:35,825:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 23:32:35,825:INFO:Starting cross validation
2023-06-12 23:32:35,827:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 23:35:08,242:INFO:Calculating mean and std
2023-06-12 23:35:08,242:INFO:Creating metrics dataframe
2023-06-12 23:35:08,254:INFO:Finalizing model
2023-06-12 23:35:25,451:INFO:Creating Dashboard logs
2023-06-12 23:35:25,451:INFO:Model: Light Gradient Boosting Machine
2023-06-12 23:35:25,541:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5675, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 23:35:25,756:INFO:Initializing predict_model()
2023-06-12 23:35:25,756:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2D10400>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5675, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017F117D4DC0>)
2023-06-12 23:35:25,756:INFO:Checking exceptions
2023-06-12 23:35:25,756:INFO:Preloading libraries
2023-06-12 23:35:39,427:INFO:Uploading results into container
2023-06-12 23:35:39,430:INFO:Uploading model into container now
2023-06-12 23:35:39,448:INFO:_master_model_container: 1
2023-06-12 23:35:39,448:INFO:_display_container: 2
2023-06-12 23:35:39,449:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5675, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 23:35:39,450:INFO:create_model() successfully completed......................................
2023-06-12 23:35:39,557:INFO:Initializing finalize_model()
2023-06-12 23:35:39,557:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2D10400>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5675, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-12 23:35:39,558:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5675, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 23:35:39,566:INFO:Initializing create_model()
2023-06-12 23:35:39,566:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2D10400>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5675, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-12 23:35:39,566:INFO:Checking exceptions
2023-06-12 23:35:39,566:INFO:Importing libraries
2023-06-12 23:35:39,566:INFO:Copying training dataset
2023-06-12 23:35:39,566:INFO:Defining folds
2023-06-12 23:35:39,566:INFO:Declaring metric variables
2023-06-12 23:35:39,566:INFO:Importing untrained model
2023-06-12 23:35:39,566:INFO:Declaring custom model
2023-06-12 23:35:39,566:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 23:35:39,566:INFO:Cross validation set to False
2023-06-12 23:35:39,566:INFO:Fitting Model
2023-06-12 23:35:40,317:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5675, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:35:40,317:INFO:create_model() successfully completed......................................
2023-06-12 23:35:40,428:INFO:Creating Dashboard logs
2023-06-12 23:35:40,428:INFO:Model: Light Gradient Boosting Machine
2023-06-12 23:35:40,543:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5675, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 23:35:40,900:INFO:_master_model_container: 1
2023-06-12 23:35:40,900:INFO:_display_container: 2
2023-06-12 23:35:40,910:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5675, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:35:40,910:INFO:finalize_model() successfully completed......................................
2023-06-12 23:35:54,357:INFO:Initializing save_model()
2023-06-12 23:35:54,357:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5675, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=models/bs_predictor_hotZone, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 23:35:54,357:INFO:Adding model into prep_pipe
2023-06-12 23:35:54,357:WARNING:Only Model saved as it was a pipeline.
2023-06-12 23:35:54,381:INFO:models/bs_predictor_hotZone.pkl saved in current working directory
2023-06-12 23:35:54,404:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5675, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:35:54,404:INFO:save_model() successfully completed......................................
2023-06-12 23:35:54,540:INFO:Initializing predict_model()
2023-06-12 23:35:54,540:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC2D10400>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5675, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017EB302F7F0>)
2023-06-12 23:35:54,540:INFO:Checking exceptions
2023-06-12 23:35:54,540:INFO:Preloading libraries
2023-06-12 23:35:54,541:INFO:Set up data.
2023-06-12 23:35:54,575:INFO:Set up index.
2023-06-12 23:36:10,090:INFO:PyCaret ClassificationExperiment
2023-06-12 23:36:10,090:INFO:Logging name: clf-default-name
2023-06-12 23:36:10,090:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 23:36:10,090:INFO:version 3.0.2
2023-06-12 23:36:10,090:INFO:Initializing setup()
2023-06-12 23:36:10,090:INFO:self.USI: dd8c
2023-06-12 23:36:10,090:INFO:self._variable_keys: {'fold_groups_param', 'exp_name_log', 'y_test', 'log_plots_param', 'fix_imbalance', 'fold_generator', 'gpu_n_jobs_param', 'n_jobs_param', 'y', 'html_param', '_available_plots', 'memory', 'gpu_param', 'X_train', 'X', 'USI', 'seed', 'target_param', 'pipeline', 'data', '_ml_usecase', 'logging_param', 'fold_shuffle_param', 'idx', 'y_train', 'X_test', 'is_multiclass', 'exp_id'}
2023-06-12 23:36:10,091:INFO:Checking environment
2023-06-12 23:36:10,091:INFO:python_version: 3.10.10
2023-06-12 23:36:10,091:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 23:36:10,091:INFO:machine: AMD64
2023-06-12 23:36:10,091:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 23:36:10,095:INFO:Memory: svmem(total=17034072064, available=7602032640, percent=55.4, used=9432039424, free=7602032640)
2023-06-12 23:36:10,095:INFO:Physical Core: 2
2023-06-12 23:36:10,095:INFO:Logical Core: 4
2023-06-12 23:36:10,096:INFO:Checking libraries
2023-06-12 23:36:10,096:INFO:System:
2023-06-12 23:36:10,096:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 23:36:10,096:INFO:executable: C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 23:36:10,096:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 23:36:10,096:INFO:PyCaret required dependencies:
2023-06-12 23:36:10,096:INFO:                 pip: 23.1.2
2023-06-12 23:36:10,096:INFO:          setuptools: 65.5.0
2023-06-12 23:36:10,097:INFO:             pycaret: 3.0.2
2023-06-12 23:36:10,097:INFO:             IPython: 8.14.0
2023-06-12 23:36:10,097:INFO:          ipywidgets: 8.0.6
2023-06-12 23:36:10,097:INFO:                tqdm: 4.65.0
2023-06-12 23:36:10,097:INFO:               numpy: 1.23.5
2023-06-12 23:36:10,097:INFO:              pandas: 1.5.3
2023-06-12 23:36:10,097:INFO:              jinja2: 3.1.2
2023-06-12 23:36:10,097:INFO:               scipy: 1.10.1
2023-06-12 23:36:10,097:INFO:              joblib: 1.2.0
2023-06-12 23:36:10,097:INFO:             sklearn: 1.2.2
2023-06-12 23:36:10,097:INFO:                pyod: 1.0.9
2023-06-12 23:36:10,097:INFO:            imblearn: 0.10.1
2023-06-12 23:36:10,097:INFO:   category_encoders: 2.6.1
2023-06-12 23:36:10,098:INFO:            lightgbm: 3.3.5
2023-06-12 23:36:10,098:INFO:               numba: 0.57.0
2023-06-12 23:36:10,098:INFO:            requests: 2.31.0
2023-06-12 23:36:10,098:INFO:          matplotlib: 3.7.1
2023-06-12 23:36:10,098:INFO:          scikitplot: 0.3.7
2023-06-12 23:36:10,098:INFO:         yellowbrick: 1.5
2023-06-12 23:36:10,098:INFO:              plotly: 5.15.0
2023-06-12 23:36:10,098:INFO:             kaleido: 0.2.1
2023-06-12 23:36:10,098:INFO:         statsmodels: 0.14.0
2023-06-12 23:36:10,098:INFO:              sktime: 0.17.0
2023-06-12 23:36:10,098:INFO:               tbats: 1.1.3
2023-06-12 23:36:10,099:INFO:            pmdarima: 2.0.3
2023-06-12 23:36:10,099:INFO:              psutil: 5.9.5
2023-06-12 23:36:10,100:INFO:PyCaret optional dependencies:
2023-06-12 23:36:10,101:INFO:                shap: Not installed
2023-06-12 23:36:10,102:INFO:           interpret: Not installed
2023-06-12 23:36:10,102:INFO:                umap: Not installed
2023-06-12 23:36:10,102:INFO:    pandas_profiling: Not installed
2023-06-12 23:36:10,102:INFO:  explainerdashboard: Not installed
2023-06-12 23:36:10,102:INFO:             autoviz: Not installed
2023-06-12 23:36:10,102:INFO:           fairlearn: Not installed
2023-06-12 23:36:10,102:INFO:             xgboost: Not installed
2023-06-12 23:36:10,102:INFO:            catboost: Not installed
2023-06-12 23:36:10,102:INFO:              kmodes: Not installed
2023-06-12 23:36:10,103:INFO:             mlxtend: Not installed
2023-06-12 23:36:10,103:INFO:       statsforecast: Not installed
2023-06-12 23:36:10,103:INFO:        tune_sklearn: Not installed
2023-06-12 23:36:10,103:INFO:                 ray: Not installed
2023-06-12 23:36:10,103:INFO:            hyperopt: Not installed
2023-06-12 23:36:10,103:INFO:              optuna: Not installed
2023-06-12 23:36:10,103:INFO:               skopt: Not installed
2023-06-12 23:36:10,103:INFO:              mlflow: 2.4.1
2023-06-12 23:36:10,103:INFO:              gradio: Not installed
2023-06-12 23:36:10,103:INFO:             fastapi: Not installed
2023-06-12 23:36:10,103:INFO:             uvicorn: Not installed
2023-06-12 23:36:10,103:INFO:              m2cgen: Not installed
2023-06-12 23:36:10,104:INFO:           evidently: Not installed
2023-06-12 23:36:10,104:INFO:               fugue: Not installed
2023-06-12 23:36:10,104:INFO:           streamlit: 1.23.1
2023-06-12 23:36:10,104:INFO:             prophet: Not installed
2023-06-12 23:36:10,104:INFO:None
2023-06-12 23:36:10,104:INFO:Set up data.
2023-06-12 23:36:10,208:INFO:Set up train/test split.
2023-06-12 23:36:10,272:INFO:Set up index.
2023-06-12 23:36:10,273:INFO:Set up folding strategy.
2023-06-12 23:36:10,274:INFO:Assigning column types.
2023-06-12 23:36:10,308:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 23:36:10,365:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 23:36:10,366:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:36:10,404:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:36:10,405:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:36:10,461:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 23:36:10,463:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:36:10,512:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:36:10,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:36:10,513:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 23:36:10,578:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:36:10,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:36:10,635:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:36:10,721:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:36:10,763:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:36:10,764:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:36:10,764:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 23:36:10,875:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:36:10,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:36:10,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:36:10,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:36:10,982:INFO:Preparing preprocessing pipeline...
2023-06-12 23:36:10,988:INFO:Set up label encoding.
2023-06-12 23:36:10,988:INFO:Set up simple imputation.
2023-06-12 23:36:11,007:INFO:Set up encoding of categorical features.
2023-06-12 23:36:11,011:INFO:Set up column name cleaning.
2023-06-12 23:36:11,721:INFO:Finished creating preprocessing pipeline.
2023-06-12 23:36:11,729:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-12 23:36:11,729:INFO:Creating final display dataframe.
2023-06-12 23:36:13,061:INFO:Setup _display_container:                     Description             Value
0                    Session id              8196
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape      (19503, 142)
5        Transformed data shape      (19503, 153)
6   Transformed train set shape      (13652, 153)
7    Transformed test set shape       (5851, 153)
8              Numeric features               140
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              dd8c
2023-06-12 23:36:13,226:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:36:13,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:36:13,323:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:36:13,324:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:36:13,324:INFO:Logging experiment in loggers
2023-06-12 23:36:13,536:INFO:SubProcess save_model() called ==================================
2023-06-12 23:36:13,555:INFO:Initializing save_model()
2023-06-12 23:36:13,555:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmpgfy9qjit\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 23:36:13,556:INFO:Adding model into prep_pipe
2023-06-12 23:36:13,556:WARNING:Only Model saved as it was a pipeline.
2023-06-12 23:36:13,563:INFO:C:\Users\alniquia\AppData\Local\Temp\tmpgfy9qjit\Transformation Pipeline.pkl saved in current working directory
2023-06-12 23:36:13,576:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-12 23:36:13,576:INFO:save_model() successfully completed......................................
2023-06-12 23:36:13,688:INFO:SubProcess save_model() end ==================================
2023-06-12 23:36:13,716:INFO:setup() successfully completed in 18.35s...............
2023-06-12 23:36:32,477:INFO:Initializing create_model()
2023-06-12 23:36:32,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC6909240>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 23:36:32,477:INFO:Checking exceptions
2023-06-12 23:36:32,479:INFO:Importing libraries
2023-06-12 23:36:32,479:INFO:Copying training dataset
2023-06-12 23:36:32,556:INFO:Defining folds
2023-06-12 23:36:32,556:INFO:Declaring metric variables
2023-06-12 23:36:32,557:INFO:Importing untrained model
2023-06-12 23:36:32,559:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 23:36:32,560:INFO:Starting cross validation
2023-06-12 23:36:32,563:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 23:37:02,356:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-12 23:37:02,953:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:37:03,043:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:37:03,541:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:37:04,289:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-12 23:39:28,728:INFO:Calculating mean and std
2023-06-12 23:39:28,729:INFO:Creating metrics dataframe
2023-06-12 23:39:28,736:INFO:Finalizing model
2023-06-12 23:39:49,212:INFO:Creating Dashboard logs
2023-06-12 23:39:49,213:INFO:Model: Light Gradient Boosting Machine
2023-06-12 23:39:49,348:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 8196, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 23:39:49,593:INFO:Initializing predict_model()
2023-06-12 23:39:49,593:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC6909240>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8196, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017F117D6170>)
2023-06-12 23:39:49,593:INFO:Checking exceptions
2023-06-12 23:39:49,593:INFO:Preloading libraries
2023-06-12 23:40:06,018:INFO:Uploading results into container
2023-06-12 23:40:06,019:INFO:Uploading model into container now
2023-06-12 23:40:06,036:INFO:_master_model_container: 1
2023-06-12 23:40:06,037:INFO:_display_container: 2
2023-06-12 23:40:06,038:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8196, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 23:40:06,038:INFO:create_model() successfully completed......................................
2023-06-12 23:40:06,165:INFO:Initializing finalize_model()
2023-06-12 23:40:06,165:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC6909240>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8196, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-12 23:40:06,166:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8196, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 23:40:06,187:INFO:Initializing create_model()
2023-06-12 23:40:06,187:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC6909240>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8196, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-12 23:40:06,187:INFO:Checking exceptions
2023-06-12 23:40:06,188:INFO:Importing libraries
2023-06-12 23:40:06,188:INFO:Copying training dataset
2023-06-12 23:40:06,190:INFO:Defining folds
2023-06-12 23:40:06,190:INFO:Declaring metric variables
2023-06-12 23:40:06,190:INFO:Importing untrained model
2023-06-12 23:40:06,190:INFO:Declaring custom model
2023-06-12 23:40:06,191:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 23:40:06,195:INFO:Cross validation set to False
2023-06-12 23:40:06,195:INFO:Fitting Model
2023-06-12 23:40:07,585:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=8196, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:40:07,586:INFO:create_model() successfully completed......................................
2023-06-12 23:40:07,706:INFO:Creating Dashboard logs
2023-06-12 23:40:07,707:INFO:Model: Light Gradient Boosting Machine
2023-06-12 23:40:07,787:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 8196, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 23:40:08,148:INFO:_master_model_container: 1
2023-06-12 23:40:08,148:INFO:_display_container: 2
2023-06-12 23:40:08,157:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=8196, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:40:08,157:INFO:finalize_model() successfully completed......................................
2023-06-12 23:40:24,848:INFO:Initializing save_model()
2023-06-12 23:40:24,848:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=8196, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=models/bs_predictor_knockout, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 23:40:24,848:INFO:Adding model into prep_pipe
2023-06-12 23:40:24,848:WARNING:Only Model saved as it was a pipeline.
2023-06-12 23:40:24,875:INFO:models/bs_predictor_knockout.pkl saved in current working directory
2023-06-12 23:40:24,901:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=8196, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:40:24,901:INFO:save_model() successfully completed......................................
2023-06-12 23:40:25,040:INFO:Initializing predict_model()
2023-06-12 23:40:25,041:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC6909240>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=8196, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017EB308CD30>)
2023-06-12 23:40:25,041:INFO:Checking exceptions
2023-06-12 23:40:25,041:INFO:Preloading libraries
2023-06-12 23:40:25,041:INFO:Set up data.
2023-06-12 23:40:25,115:INFO:Set up index.
2023-06-12 23:40:41,969:INFO:PyCaret ClassificationExperiment
2023-06-12 23:40:41,969:INFO:Logging name: clf-default-name
2023-06-12 23:40:41,969:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-12 23:40:41,969:INFO:version 3.0.2
2023-06-12 23:40:41,969:INFO:Initializing setup()
2023-06-12 23:40:41,969:INFO:self.USI: 7c0e
2023-06-12 23:40:41,969:INFO:self._variable_keys: {'fold_groups_param', 'exp_name_log', 'y_test', 'log_plots_param', 'fix_imbalance', 'fold_generator', 'gpu_n_jobs_param', 'n_jobs_param', 'y', 'html_param', '_available_plots', 'memory', 'gpu_param', 'X_train', 'X', 'USI', 'seed', 'target_param', 'pipeline', 'data', '_ml_usecase', 'logging_param', 'fold_shuffle_param', 'idx', 'y_train', 'X_test', 'is_multiclass', 'exp_id'}
2023-06-12 23:40:41,969:INFO:Checking environment
2023-06-12 23:40:41,970:INFO:python_version: 3.10.10
2023-06-12 23:40:41,970:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-12 23:40:41,970:INFO:machine: AMD64
2023-06-12 23:40:41,970:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-12 23:40:41,973:INFO:Memory: svmem(total=17034072064, available=7772000256, percent=54.4, used=9262071808, free=7772000256)
2023-06-12 23:40:41,973:INFO:Physical Core: 2
2023-06-12 23:40:41,974:INFO:Logical Core: 4
2023-06-12 23:40:41,974:INFO:Checking libraries
2023-06-12 23:40:41,974:INFO:System:
2023-06-12 23:40:41,974:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-12 23:40:41,974:INFO:executable: C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-12 23:40:41,974:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-12 23:40:41,974:INFO:PyCaret required dependencies:
2023-06-12 23:40:41,974:INFO:                 pip: 23.1.2
2023-06-12 23:40:41,974:INFO:          setuptools: 65.5.0
2023-06-12 23:40:41,974:INFO:             pycaret: 3.0.2
2023-06-12 23:40:41,974:INFO:             IPython: 8.14.0
2023-06-12 23:40:41,975:INFO:          ipywidgets: 8.0.6
2023-06-12 23:40:41,975:INFO:                tqdm: 4.65.0
2023-06-12 23:40:41,975:INFO:               numpy: 1.23.5
2023-06-12 23:40:41,976:INFO:              pandas: 1.5.3
2023-06-12 23:40:41,976:INFO:              jinja2: 3.1.2
2023-06-12 23:40:41,976:INFO:               scipy: 1.10.1
2023-06-12 23:40:41,976:INFO:              joblib: 1.2.0
2023-06-12 23:40:41,976:INFO:             sklearn: 1.2.2
2023-06-12 23:40:41,976:INFO:                pyod: 1.0.9
2023-06-12 23:40:41,976:INFO:            imblearn: 0.10.1
2023-06-12 23:40:41,976:INFO:   category_encoders: 2.6.1
2023-06-12 23:40:41,977:INFO:            lightgbm: 3.3.5
2023-06-12 23:40:41,977:INFO:               numba: 0.57.0
2023-06-12 23:40:41,977:INFO:            requests: 2.31.0
2023-06-12 23:40:41,977:INFO:          matplotlib: 3.7.1
2023-06-12 23:40:41,977:INFO:          scikitplot: 0.3.7
2023-06-12 23:40:41,977:INFO:         yellowbrick: 1.5
2023-06-12 23:40:41,977:INFO:              plotly: 5.15.0
2023-06-12 23:40:41,977:INFO:             kaleido: 0.2.1
2023-06-12 23:40:41,977:INFO:         statsmodels: 0.14.0
2023-06-12 23:40:41,977:INFO:              sktime: 0.17.0
2023-06-12 23:40:41,977:INFO:               tbats: 1.1.3
2023-06-12 23:40:41,977:INFO:            pmdarima: 2.0.3
2023-06-12 23:40:41,977:INFO:              psutil: 5.9.5
2023-06-12 23:40:41,977:INFO:PyCaret optional dependencies:
2023-06-12 23:40:41,977:INFO:                shap: Not installed
2023-06-12 23:40:41,977:INFO:           interpret: Not installed
2023-06-12 23:40:41,977:INFO:                umap: Not installed
2023-06-12 23:40:41,977:INFO:    pandas_profiling: Not installed
2023-06-12 23:40:41,977:INFO:  explainerdashboard: Not installed
2023-06-12 23:40:41,977:INFO:             autoviz: Not installed
2023-06-12 23:40:41,977:INFO:           fairlearn: Not installed
2023-06-12 23:40:41,977:INFO:             xgboost: Not installed
2023-06-12 23:40:41,978:INFO:            catboost: Not installed
2023-06-12 23:40:41,978:INFO:              kmodes: Not installed
2023-06-12 23:40:41,978:INFO:             mlxtend: Not installed
2023-06-12 23:40:41,978:INFO:       statsforecast: Not installed
2023-06-12 23:40:41,978:INFO:        tune_sklearn: Not installed
2023-06-12 23:40:41,978:INFO:                 ray: Not installed
2023-06-12 23:40:41,978:INFO:            hyperopt: Not installed
2023-06-12 23:40:41,978:INFO:              optuna: Not installed
2023-06-12 23:40:41,978:INFO:               skopt: Not installed
2023-06-12 23:40:41,978:INFO:              mlflow: 2.4.1
2023-06-12 23:40:41,978:INFO:              gradio: Not installed
2023-06-12 23:40:41,978:INFO:             fastapi: Not installed
2023-06-12 23:40:41,978:INFO:             uvicorn: Not installed
2023-06-12 23:40:41,978:INFO:              m2cgen: Not installed
2023-06-12 23:40:41,978:INFO:           evidently: Not installed
2023-06-12 23:40:41,978:INFO:               fugue: Not installed
2023-06-12 23:40:41,978:INFO:           streamlit: 1.23.1
2023-06-12 23:40:41,978:INFO:             prophet: Not installed
2023-06-12 23:40:41,978:INFO:None
2023-06-12 23:40:41,978:INFO:Set up data.
2023-06-12 23:40:42,019:INFO:Set up train/test split.
2023-06-12 23:40:42,033:INFO:Set up index.
2023-06-12 23:40:42,034:INFO:Set up folding strategy.
2023-06-12 23:40:42,034:INFO:Assigning column types.
2023-06-12 23:40:42,044:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-12 23:40:42,105:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 23:40:42,107:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:40:42,143:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:40:42,144:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:40:42,199:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-12 23:40:42,200:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:40:42,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:40:42,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:40:42,235:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-12 23:40:42,300:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:40:42,345:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:40:42,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:40:42,401:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-12 23:40:42,435:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:40:42,435:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:40:42,435:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-12 23:40:42,527:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:40:42,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:40:42,606:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:40:42,607:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:40:42,610:INFO:Preparing preprocessing pipeline...
2023-06-12 23:40:42,612:INFO:Set up label encoding.
2023-06-12 23:40:42,612:INFO:Set up simple imputation.
2023-06-12 23:40:42,621:INFO:Set up encoding of categorical features.
2023-06-12 23:40:42,622:INFO:Set up column name cleaning.
2023-06-12 23:40:42,839:INFO:Finished creating preprocessing pipeline.
2023-06-12 23:40:42,851:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-12 23:40:42,851:INFO:Creating final display dataframe.
2023-06-12 23:40:43,703:INFO:Setup _display_container:                     Description             Value
0                    Session id              6353
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape       (7435, 142)
5        Transformed data shape       (7435, 145)
6   Transformed train set shape       (5204, 145)
7    Transformed test set shape       (2231, 145)
8              Numeric features               140
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              7c0e
2023-06-12 23:40:43,822:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:40:43,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:40:43,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:40:43,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-12 23:40:43,925:INFO:Logging experiment in loggers
2023-06-12 23:40:44,080:INFO:SubProcess save_model() called ==================================
2023-06-12 23:40:44,099:INFO:Initializing save_model()
2023-06-12 23:40:44,099:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmpixo60b8j\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 23:40:44,099:INFO:Adding model into prep_pipe
2023-06-12 23:40:44,099:WARNING:Only Model saved as it was a pipeline.
2023-06-12 23:40:44,107:INFO:C:\Users\alniquia\AppData\Local\Temp\tmpixo60b8j\Transformation Pipeline.pkl saved in current working directory
2023-06-12 23:40:44,118:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-12 23:40:44,118:INFO:save_model() successfully completed......................................
2023-06-12 23:40:44,219:INFO:SubProcess save_model() end ==================================
2023-06-12 23:40:44,243:INFO:setup() successfully completed in 18.06s...............
2023-06-12 23:41:00,634:INFO:Initializing create_model()
2023-06-12 23:41:00,634:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC26F3D00>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-12 23:41:00,634:INFO:Checking exceptions
2023-06-12 23:41:00,636:INFO:Importing libraries
2023-06-12 23:41:00,636:INFO:Copying training dataset
2023-06-12 23:41:00,662:INFO:Defining folds
2023-06-12 23:41:00,662:INFO:Declaring metric variables
2023-06-12 23:41:00,662:INFO:Importing untrained model
2023-06-12 23:41:00,663:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 23:41:00,664:INFO:Starting cross validation
2023-06-12 23:41:00,667:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-12 23:41:28,208:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-12 23:43:54,081:INFO:Calculating mean and std
2023-06-12 23:43:54,082:INFO:Creating metrics dataframe
2023-06-12 23:43:54,087:INFO:Finalizing model
2023-06-12 23:44:14,661:INFO:Creating Dashboard logs
2023-06-12 23:44:14,662:INFO:Model: Light Gradient Boosting Machine
2023-06-12 23:44:14,727:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6353, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 23:44:14,879:INFO:Initializing predict_model()
2023-06-12 23:44:14,879:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC26F3D00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6353, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017EC1C2F370>)
2023-06-12 23:44:14,879:INFO:Checking exceptions
2023-06-12 23:44:14,879:INFO:Preloading libraries
2023-06-12 23:44:31,871:INFO:Uploading results into container
2023-06-12 23:44:31,872:INFO:Uploading model into container now
2023-06-12 23:44:31,896:INFO:_master_model_container: 1
2023-06-12 23:44:31,896:INFO:_display_container: 2
2023-06-12 23:44:31,897:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6353, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 23:44:31,897:INFO:create_model() successfully completed......................................
2023-06-12 23:44:32,018:INFO:Initializing finalize_model()
2023-06-12 23:44:32,018:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC26F3D00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6353, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-12 23:44:32,019:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6353, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-12 23:44:32,027:INFO:Initializing create_model()
2023-06-12 23:44:32,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC26F3D00>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6353, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-12 23:44:32,028:INFO:Checking exceptions
2023-06-12 23:44:32,029:INFO:Importing libraries
2023-06-12 23:44:32,029:INFO:Copying training dataset
2023-06-12 23:44:32,030:INFO:Defining folds
2023-06-12 23:44:32,030:INFO:Declaring metric variables
2023-06-12 23:44:32,030:INFO:Importing untrained model
2023-06-12 23:44:32,030:INFO:Declaring custom model
2023-06-12 23:44:32,031:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-12 23:44:32,034:INFO:Cross validation set to False
2023-06-12 23:44:32,034:INFO:Fitting Model
2023-06-12 23:44:32,943:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6353, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:44:32,943:INFO:create_model() successfully completed......................................
2023-06-12 23:44:33,060:INFO:Creating Dashboard logs
2023-06-12 23:44:33,061:INFO:Model: Light Gradient Boosting Machine
2023-06-12 23:44:33,163:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 6353, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-12 23:44:33,529:INFO:_master_model_container: 1
2023-06-12 23:44:33,529:INFO:_display_container: 2
2023-06-12 23:44:33,540:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6353, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:44:33,541:INFO:finalize_model() successfully completed......................................
2023-06-12 23:44:50,026:INFO:Initializing save_model()
2023-06-12 23:44:50,026:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6353, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=models/bs_predictor_volleyBrawl, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-12 23:44:50,026:INFO:Adding model into prep_pipe
2023-06-12 23:44:50,026:WARNING:Only Model saved as it was a pipeline.
2023-06-12 23:44:50,046:INFO:models/bs_predictor_volleyBrawl.pkl saved in current working directory
2023-06-12 23:44:50,072:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6353, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-12 23:44:50,072:INFO:save_model() successfully completed......................................
2023-06-12 23:44:50,198:INFO:Initializing predict_model()
2023-06-12 23:44:50,198:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000017EC26F3D00>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=6353, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000017ED8F23BE0>)
2023-06-12 23:44:50,199:INFO:Checking exceptions
2023-06-12 23:44:50,199:INFO:Preloading libraries
2023-06-12 23:44:50,199:INFO:Set up data.
2023-06-12 23:44:50,243:INFO:Set up index.
2023-06-13 13:09:13,776:INFO:Initializing load_model()
2023-06-13 13:09:13,776:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-13 13:09:13,790:INFO:Initializing load_model()
2023-06-13 13:09:13,790:INFO:load_model(model_name=models/bs_predictor_gemGrab, platform=None, authentication=None, verbose=True)
2023-06-13 13:09:13,814:INFO:Initializing load_model()
2023-06-13 13:09:13,815:INFO:load_model(model_name=models/bs_predictor_heist, platform=None, authentication=None, verbose=True)
2023-06-13 13:09:13,834:INFO:Initializing load_model()
2023-06-13 13:09:13,834:INFO:load_model(model_name=models/bs_predictor_bounty, platform=None, authentication=None, verbose=True)
2023-06-13 13:09:13,854:INFO:Initializing load_model()
2023-06-13 13:09:13,854:INFO:load_model(model_name=models/bs_predictor_hotZone, platform=None, authentication=None, verbose=True)
2023-06-13 13:09:13,874:INFO:Initializing load_model()
2023-06-13 13:09:13,875:INFO:load_model(model_name=models/bs_predictor_knockout, platform=None, authentication=None, verbose=True)
2023-06-13 13:09:13,898:INFO:Initializing load_model()
2023-06-13 13:09:13,899:INFO:load_model(model_name=models/bs_predictor_volleyBrawl, platform=None, authentication=None, verbose=True)
2023-06-13 13:10:50,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 13:10:50,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 13:10:50,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 13:10:50,328:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 13:10:54,626:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-13 13:11:02,307:INFO:Initializing load_model()
2023-06-13 13:11:02,307:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-13 13:11:02,490:INFO:Initializing load_model()
2023-06-13 13:11:02,490:INFO:load_model(model_name=models/bs_predictor_gemGrab, platform=None, authentication=None, verbose=True)
2023-06-13 13:11:02,526:INFO:Initializing load_model()
2023-06-13 13:11:02,527:INFO:load_model(model_name=models/bs_predictor_heist, platform=None, authentication=None, verbose=True)
2023-06-13 13:11:02,546:INFO:Initializing load_model()
2023-06-13 13:11:02,546:INFO:load_model(model_name=models/bs_predictor_bounty, platform=None, authentication=None, verbose=True)
2023-06-13 13:11:02,568:INFO:Initializing load_model()
2023-06-13 13:11:02,569:INFO:load_model(model_name=models/bs_predictor_hotZone, platform=None, authentication=None, verbose=True)
2023-06-13 13:11:02,593:INFO:Initializing load_model()
2023-06-13 13:11:02,593:INFO:load_model(model_name=models/bs_predictor_knockout, platform=None, authentication=None, verbose=True)
2023-06-13 13:11:02,613:INFO:Initializing load_model()
2023-06-13 13:11:02,613:INFO:load_model(model_name=models/bs_predictor_volleyBrawl, platform=None, authentication=None, verbose=True)
2023-06-13 13:47:58,847:INFO:Initializing predict_model()
2023-06-13 13:47:58,848:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208BEA0D7E0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=6134))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000208A5AAB1C0>)
2023-06-13 13:47:58,848:INFO:Checking exceptions
2023-06-13 13:47:58,848:INFO:Preloading libraries
2023-06-13 13:47:58,848:INFO:Set up data.
2023-06-13 13:47:58,907:INFO:Set up index.
2023-06-13 13:48:08,192:INFO:Initializing predict_model()
2023-06-13 13:48:08,193:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208BE40C640>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=3800))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000208A5AA9B40>)
2023-06-13 13:48:08,193:INFO:Checking exceptions
2023-06-13 13:48:08,193:INFO:Preloading libraries
2023-06-13 13:48:08,194:INFO:Set up data.
2023-06-13 13:48:08,255:INFO:Set up index.
2023-06-13 13:48:15,009:INFO:Initializing predict_model()
2023-06-13 13:48:15,009:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208BEA0D840>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=6178))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002088DE4C160>)
2023-06-13 13:48:15,010:INFO:Checking exceptions
2023-06-13 13:48:15,010:INFO:Preloading libraries
2023-06-13 13:48:15,011:INFO:Set up data.
2023-06-13 13:48:15,092:INFO:Set up index.
2023-06-13 13:48:23,901:INFO:Initializing predict_model()
2023-06-13 13:48:23,903:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208BE3AFDF0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=6178))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000208A5AAA680>)
2023-06-13 13:48:23,903:INFO:Checking exceptions
2023-06-13 13:48:23,904:INFO:Preloading libraries
2023-06-13 13:48:23,905:INFO:Set up data.
2023-06-13 13:48:23,959:INFO:Set up index.
2023-06-13 13:48:31,225:INFO:Initializing predict_model()
2023-06-13 13:48:31,225:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208BE40EAA0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=6178))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002088E189090>)
2023-06-13 13:48:31,226:INFO:Checking exceptions
2023-06-13 13:48:31,226:INFO:Preloading libraries
2023-06-13 13:48:31,226:INFO:Set up data.
2023-06-13 13:48:31,309:INFO:Set up index.
2023-06-13 14:00:44,246:INFO:PyCaret ClassificationExperiment
2023-06-13 14:00:44,246:INFO:Logging name: clf-default-name
2023-06-13 14:00:44,247:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-13 14:00:44,247:INFO:version 3.0.2
2023-06-13 14:00:44,247:INFO:Initializing setup()
2023-06-13 14:00:44,247:INFO:self.USI: ab86
2023-06-13 14:00:44,247:INFO:self._variable_keys: {'seed', 'pipeline', 'gpu_n_jobs_param', 'exp_id', 'idx', 'fold_shuffle_param', '_available_plots', 'data', 'y_train', 'USI', 'fix_imbalance', 'y', 'exp_name_log', 'y_test', 'fold_groups_param', 'target_param', 'memory', 'is_multiclass', 'logging_param', 'X_train', 'html_param', 'n_jobs_param', 'X', '_ml_usecase', 'fold_generator', 'X_test', 'gpu_param', 'log_plots_param'}
2023-06-13 14:00:44,247:INFO:Checking environment
2023-06-13 14:00:44,247:INFO:python_version: 3.10.10
2023-06-13 14:00:44,247:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-13 14:00:44,247:INFO:machine: AMD64
2023-06-13 14:00:44,276:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-13 14:00:44,280:INFO:Memory: svmem(total=17034072064, available=6071726080, percent=64.4, used=10962345984, free=6071726080)
2023-06-13 14:00:44,280:INFO:Physical Core: 2
2023-06-13 14:00:44,280:INFO:Logical Core: 4
2023-06-13 14:00:44,280:INFO:Checking libraries
2023-06-13 14:00:44,280:INFO:System:
2023-06-13 14:00:44,280:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-13 14:00:44,280:INFO:executable: C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-13 14:00:44,280:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-13 14:00:44,280:INFO:PyCaret required dependencies:
2023-06-13 14:00:44,280:INFO:                 pip: 23.1.2
2023-06-13 14:00:44,280:INFO:          setuptools: 65.5.0
2023-06-13 14:00:44,280:INFO:             pycaret: 3.0.2
2023-06-13 14:00:44,280:INFO:             IPython: 8.14.0
2023-06-13 14:00:44,280:INFO:          ipywidgets: 8.0.6
2023-06-13 14:00:44,281:INFO:                tqdm: 4.65.0
2023-06-13 14:00:44,281:INFO:               numpy: 1.23.5
2023-06-13 14:00:44,281:INFO:              pandas: 1.5.3
2023-06-13 14:00:44,281:INFO:              jinja2: 3.1.2
2023-06-13 14:00:44,281:INFO:               scipy: 1.10.1
2023-06-13 14:00:44,281:INFO:              joblib: 1.2.0
2023-06-13 14:00:44,281:INFO:             sklearn: 1.2.2
2023-06-13 14:00:44,281:INFO:                pyod: 1.0.9
2023-06-13 14:00:44,281:INFO:            imblearn: 0.10.1
2023-06-13 14:00:44,281:INFO:   category_encoders: 2.6.1
2023-06-13 14:00:44,281:INFO:            lightgbm: 3.3.5
2023-06-13 14:00:44,281:INFO:               numba: 0.57.0
2023-06-13 14:00:44,281:INFO:            requests: 2.31.0
2023-06-13 14:00:44,281:INFO:          matplotlib: 3.7.1
2023-06-13 14:00:44,281:INFO:          scikitplot: 0.3.7
2023-06-13 14:00:44,281:INFO:         yellowbrick: 1.5
2023-06-13 14:00:44,281:INFO:              plotly: 5.15.0
2023-06-13 14:00:44,281:INFO:             kaleido: 0.2.1
2023-06-13 14:00:44,281:INFO:         statsmodels: 0.14.0
2023-06-13 14:00:44,281:INFO:              sktime: 0.17.0
2023-06-13 14:00:44,281:INFO:               tbats: 1.1.3
2023-06-13 14:00:44,281:INFO:            pmdarima: 2.0.3
2023-06-13 14:00:44,281:INFO:              psutil: 5.9.5
2023-06-13 14:00:44,281:INFO:PyCaret optional dependencies:
2023-06-13 14:00:44,320:INFO:                shap: Not installed
2023-06-13 14:00:44,320:INFO:           interpret: Not installed
2023-06-13 14:00:44,320:INFO:                umap: Not installed
2023-06-13 14:00:44,320:INFO:    pandas_profiling: Not installed
2023-06-13 14:00:44,320:INFO:  explainerdashboard: Not installed
2023-06-13 14:00:44,320:INFO:             autoviz: Not installed
2023-06-13 14:00:44,320:INFO:           fairlearn: Not installed
2023-06-13 14:00:44,321:INFO:             xgboost: Not installed
2023-06-13 14:00:44,321:INFO:            catboost: Not installed
2023-06-13 14:00:44,321:INFO:              kmodes: Not installed
2023-06-13 14:00:44,321:INFO:             mlxtend: Not installed
2023-06-13 14:00:44,321:INFO:       statsforecast: Not installed
2023-06-13 14:00:44,321:INFO:        tune_sklearn: Not installed
2023-06-13 14:00:44,321:INFO:                 ray: Not installed
2023-06-13 14:00:44,321:INFO:            hyperopt: Not installed
2023-06-13 14:00:44,321:INFO:              optuna: Not installed
2023-06-13 14:00:44,321:INFO:               skopt: Not installed
2023-06-13 14:00:44,321:INFO:              mlflow: 2.4.1
2023-06-13 14:00:44,321:INFO:              gradio: Not installed
2023-06-13 14:00:44,321:INFO:             fastapi: Not installed
2023-06-13 14:00:44,321:INFO:             uvicorn: Not installed
2023-06-13 14:00:44,321:INFO:              m2cgen: Not installed
2023-06-13 14:00:44,321:INFO:           evidently: Not installed
2023-06-13 14:00:44,321:INFO:               fugue: Not installed
2023-06-13 14:00:44,321:INFO:           streamlit: 1.23.1
2023-06-13 14:00:44,321:INFO:             prophet: Not installed
2023-06-13 14:00:44,321:INFO:None
2023-06-13 14:00:44,321:INFO:Set up data.
2023-06-13 14:00:44,371:INFO:Set up train/test split.
2023-06-13 14:00:44,397:INFO:Set up index.
2023-06-13 14:00:44,398:INFO:Set up folding strategy.
2023-06-13 14:00:44,398:INFO:Assigning column types.
2023-06-13 14:00:44,415:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-13 14:00:44,463:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 14:00:44,471:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-13 14:00:44,540:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 14:00:44,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 14:00:44,593:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 14:00:44,594:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-13 14:00:44,625:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 14:00:44,625:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 14:00:44,626:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-13 14:00:44,676:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-13 14:00:44,707:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 14:00:44,707:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 14:00:44,757:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-13 14:00:44,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 14:00:44,788:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 14:00:44,788:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-13 14:00:44,868:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 14:00:44,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 14:00:44,946:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 14:00:44,946:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 14:00:44,949:INFO:Preparing preprocessing pipeline...
2023-06-13 14:00:44,953:INFO:Set up label encoding.
2023-06-13 14:00:44,953:INFO:Set up simple imputation.
2023-06-13 14:00:44,963:INFO:Set up encoding of categorical features.
2023-06-13 14:00:44,966:INFO:Set up column name cleaning.
2023-06-13 14:00:45,231:INFO:Finished creating preprocessing pipeline.
2023-06-13 14:00:45,240:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-13 14:00:45,241:INFO:Creating final display dataframe.
2023-06-13 14:00:46,222:INFO:Setup _display_container:                     Description             Value
0                    Session id              5085
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape      (11235, 142)
5        Transformed data shape      (11235, 151)
6   Transformed train set shape       (7864, 151)
7    Transformed test set shape       (3371, 151)
8              Numeric features               140
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              ab86
2023-06-13 14:00:46,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 14:00:46,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 14:00:46,554:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 14:00:46,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 14:00:46,556:INFO:Logging experiment in loggers
2023-06-13 14:00:47,051:INFO:SubProcess save_model() called ==================================
2023-06-13 14:00:47,071:INFO:Initializing save_model()
2023-06-13 14:00:47,071:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmp4fo00hj6\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-13 14:00:47,072:INFO:Adding model into prep_pipe
2023-06-13 14:00:47,072:WARNING:Only Model saved as it was a pipeline.
2023-06-13 14:00:47,086:INFO:C:\Users\alniquia\AppData\Local\Temp\tmp4fo00hj6\Transformation Pipeline.pkl saved in current working directory
2023-06-13 14:00:47,093:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-13 14:00:47,094:INFO:save_model() successfully completed......................................
2023-06-13 14:00:47,200:INFO:SubProcess save_model() end ==================================
2023-06-13 14:00:47,239:INFO:setup() successfully completed in 23.1s...............
2023-06-13 14:00:47,240:INFO:Initializing create_model()
2023-06-13 14:00:47,240:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E675FB80>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-13 14:00:47,240:INFO:Checking exceptions
2023-06-13 14:00:47,242:INFO:Importing libraries
2023-06-13 14:00:47,243:INFO:Copying training dataset
2023-06-13 14:00:47,301:INFO:Defining folds
2023-06-13 14:00:47,301:INFO:Declaring metric variables
2023-06-13 14:00:47,301:INFO:Importing untrained model
2023-06-13 14:00:47,302:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-13 14:00:47,302:INFO:Starting cross validation
2023-06-13 14:00:47,304:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 14:01:00,267:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 14:01:00,267:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 14:01:00,268:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 14:01:00,273:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 14:01:36,139:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-13 14:01:36,172:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-13 14:01:36,222:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 14:01:36,270:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 14:01:36,831:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 14:01:36,996:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 14:01:37,809:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 14:01:37,905:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 14:01:38,064:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 14:01:38,553:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 14:01:38,720:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-13 14:01:38,897:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-13 14:01:39,132:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 14:01:39,467:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-13 14:01:40,392:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.90s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-13 14:02:16,267:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 14:02:29,672:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 14:04:52,444:INFO:Calculating mean and std
2023-06-13 14:04:52,445:INFO:Creating metrics dataframe
2023-06-13 14:04:52,450:INFO:Finalizing model
2023-06-13 14:05:17,399:INFO:Creating Dashboard logs
2023-06-13 14:05:17,400:INFO:Model: Light Gradient Boosting Machine
2023-06-13 14:05:17,505:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5085, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-13 14:05:17,772:INFO:Initializing predict_model()
2023-06-13 14:05:17,772:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E675FB80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5085, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000208D37E6830>)
2023-06-13 14:05:17,772:INFO:Checking exceptions
2023-06-13 14:05:17,772:INFO:Preloading libraries
2023-06-13 14:05:18,104:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning:

Setuptools is replacing distutils.


2023-06-13 14:05:37,617:INFO:Uploading results into container
2023-06-13 14:05:37,618:INFO:Uploading model into container now
2023-06-13 14:05:37,637:INFO:_master_model_container: 1
2023-06-13 14:05:37,637:INFO:_display_container: 2
2023-06-13 14:05:37,638:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5085, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-13 14:05:37,639:INFO:create_model() successfully completed......................................
2023-06-13 14:05:37,769:INFO:Initializing finalize_model()
2023-06-13 14:05:37,769:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E675FB80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5085, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-13 14:05:37,770:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5085, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-13 14:05:37,786:INFO:Initializing create_model()
2023-06-13 14:05:37,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E675FB80>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5085, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-13 14:05:37,786:INFO:Checking exceptions
2023-06-13 14:05:37,789:INFO:Importing libraries
2023-06-13 14:05:37,789:INFO:Copying training dataset
2023-06-13 14:05:37,790:INFO:Defining folds
2023-06-13 14:05:37,790:INFO:Declaring metric variables
2023-06-13 14:05:37,791:INFO:Importing untrained model
2023-06-13 14:05:37,791:INFO:Declaring custom model
2023-06-13 14:05:37,792:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-13 14:05:37,795:INFO:Cross validation set to False
2023-06-13 14:05:37,795:INFO:Fitting Model
2023-06-13 14:05:38,735:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5085, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-13 14:05:38,736:INFO:create_model() successfully completed......................................
2023-06-13 14:05:38,863:INFO:Creating Dashboard logs
2023-06-13 14:05:38,865:INFO:Model: Light Gradient Boosting Machine
2023-06-13 14:05:38,961:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 5085, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-13 14:05:39,349:INFO:_master_model_container: 1
2023-06-13 14:05:39,349:INFO:_display_container: 2
2023-06-13 14:05:39,358:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5085, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-13 14:05:39,358:INFO:finalize_model() successfully completed......................................
2023-06-13 14:05:39,483:INFO:Initializing save_model()
2023-06-13 14:05:39,483:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5085, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), model_name=models/bs_predictor_hotZone, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-13 14:05:39,483:INFO:Adding model into prep_pipe
2023-06-13 14:05:39,484:WARNING:Only Model saved as it was a pipeline.
2023-06-13 14:05:39,511:INFO:models/bs_predictor_hotZone.pkl saved in current working directory
2023-06-13 14:05:39,529:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5085, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2023-06-13 14:05:39,530:INFO:save_model() successfully completed......................................
2023-06-13 14:05:39,683:INFO:Initializing predict_model()
2023-06-13 14:05:39,684:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E675FB80>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None,
                                random_state=5085, reg_alpha=0.0,
                                reg_lambda=0.0, silent='warn', subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002088E189090>)
2023-06-13 14:05:39,684:INFO:Checking exceptions
2023-06-13 14:05:39,685:INFO:Preloading libraries
2023-06-13 14:05:39,685:INFO:Set up data.
2023-06-13 14:05:39,746:INFO:Set up index.
2023-06-13 14:07:07,090:INFO:Initializing predict_model()
2023-06-13 14:07:07,092:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E675FB80>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=5675))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000208AC53BC70>)
2023-06-13 14:07:07,093:INFO:Checking exceptions
2023-06-13 14:07:07,093:INFO:Preloading libraries
2023-06-13 14:07:07,094:INFO:Set up data.
2023-06-13 14:07:07,165:INFO:Set up index.
2023-06-13 14:07:22,936:INFO:Initializing predict_model()
2023-06-13 14:07:22,941:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000208E675FB80>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power_diff', 'T1_8-BIT',
                                             'T1_AMBER', 'T1_ASH', '...
                 TransformerWrapper(include=['event_map'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator', LGBMClassifier(random_state=5675))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000208B41D6320>)
2023-06-13 14:07:22,941:INFO:Checking exceptions
2023-06-13 14:07:22,941:INFO:Preloading libraries
2023-06-13 14:07:22,946:INFO:Set up data.
2023-06-13 14:07:23,046:INFO:Set up index.
2023-06-13 14:45:24,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 14:45:24,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 14:45:24,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 14:45:24,005:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 14:45:26,087:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-13 14:45:28,369:INFO:Initializing load_model()
2023-06-13 14:45:28,369:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-13 14:45:28,420:INFO:Initializing load_model()
2023-06-13 14:45:28,420:INFO:load_model(model_name=models/bs_predictor_gemGrab, platform=None, authentication=None, verbose=True)
2023-06-13 14:45:28,445:INFO:Initializing load_model()
2023-06-13 14:45:28,445:INFO:load_model(model_name=models/bs_predictor_heist, platform=None, authentication=None, verbose=True)
2023-06-13 14:45:28,465:INFO:Initializing load_model()
2023-06-13 14:45:28,465:INFO:load_model(model_name=models/bs_predictor_bounty, platform=None, authentication=None, verbose=True)
2023-06-13 14:45:28,483:INFO:Initializing load_model()
2023-06-13 14:45:28,484:INFO:load_model(model_name=models/bs_predictor_hotZone, platform=None, authentication=None, verbose=True)
2023-06-13 14:45:28,501:INFO:Initializing load_model()
2023-06-13 14:45:28,501:INFO:load_model(model_name=models/bs_predictor_knockout, platform=None, authentication=None, verbose=True)
2023-06-13 14:45:28,522:INFO:Initializing load_model()
2023-06-13 14:45:28,522:INFO:load_model(model_name=models/bs_predictor_volleyBrawl, platform=None, authentication=None, verbose=True)
2023-06-13 17:01:39,528:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 17:01:39,528:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 17:01:39,528:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 17:01:39,528:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-06-13 17:01:40,793:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-06-13 17:01:43,109:INFO:Initializing load_model()
2023-06-13 17:01:43,109:INFO:load_model(model_name=models/bs_predictor_brawlBall, platform=None, authentication=None, verbose=True)
2023-06-13 17:01:43,142:INFO:Initializing load_model()
2023-06-13 17:01:43,142:INFO:load_model(model_name=models/bs_predictor_gemGrab, platform=None, authentication=None, verbose=True)
2023-06-13 17:01:43,176:INFO:Initializing load_model()
2023-06-13 17:01:43,177:INFO:load_model(model_name=models/bs_predictor_heist, platform=None, authentication=None, verbose=True)
2023-06-13 17:01:43,196:INFO:Initializing load_model()
2023-06-13 17:01:43,196:INFO:load_model(model_name=models/bs_predictor_bounty, platform=None, authentication=None, verbose=True)
2023-06-13 17:01:43,215:INFO:Initializing load_model()
2023-06-13 17:01:43,215:INFO:load_model(model_name=models/bs_predictor_hotZone, platform=None, authentication=None, verbose=True)
2023-06-13 17:01:43,234:INFO:Initializing load_model()
2023-06-13 17:01:43,235:INFO:load_model(model_name=models/bs_predictor_knockout, platform=None, authentication=None, verbose=True)
2023-06-13 17:01:43,254:INFO:Initializing load_model()
2023-06-13 17:01:43,254:INFO:load_model(model_name=models/bs_predictor_volleyBrawl, platform=None, authentication=None, verbose=True)
2023-06-13 18:04:45,091:INFO:PyCaret ClassificationExperiment
2023-06-13 18:04:45,091:INFO:Logging name: clf-default-name
2023-06-13 18:04:45,091:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-13 18:04:45,091:INFO:version 3.0.2
2023-06-13 18:04:45,091:INFO:Initializing setup()
2023-06-13 18:04:45,091:INFO:self.USI: 9e2c
2023-06-13 18:04:45,091:INFO:self._variable_keys: {'log_plots_param', 'y_train', 'fold_groups_param', 'idx', 'USI', 'fix_imbalance', 'X', 'data', 'fold_generator', 'y', 'n_jobs_param', 'target_param', 'fold_shuffle_param', 'X_test', 'pipeline', 'exp_id', 'X_train', 'logging_param', 'html_param', 'exp_name_log', 'is_multiclass', 'y_test', '_ml_usecase', 'seed', 'memory', 'gpu_n_jobs_param', 'gpu_param', '_available_plots'}
2023-06-13 18:04:45,091:INFO:Checking environment
2023-06-13 18:04:45,091:INFO:python_version: 3.10.10
2023-06-13 18:04:45,091:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-13 18:04:45,091:INFO:machine: AMD64
2023-06-13 18:04:45,117:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-13 18:04:45,117:INFO:Memory: svmem(total=17034072064, available=6689701888, percent=60.7, used=10344370176, free=6689701888)
2023-06-13 18:04:45,117:INFO:Physical Core: 2
2023-06-13 18:04:45,117:INFO:Logical Core: 4
2023-06-13 18:04:45,117:INFO:Checking libraries
2023-06-13 18:04:45,117:INFO:System:
2023-06-13 18:04:45,117:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-13 18:04:45,117:INFO:executable: C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-13 18:04:45,117:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-13 18:04:45,117:INFO:PyCaret required dependencies:
2023-06-13 18:04:45,117:INFO:                 pip: 23.1.2
2023-06-13 18:04:45,117:INFO:          setuptools: 65.5.0
2023-06-13 18:04:45,117:INFO:             pycaret: 3.0.2
2023-06-13 18:04:45,117:INFO:             IPython: 8.14.0
2023-06-13 18:04:45,117:INFO:          ipywidgets: 8.0.6
2023-06-13 18:04:45,117:INFO:                tqdm: 4.65.0
2023-06-13 18:04:45,117:INFO:               numpy: 1.23.5
2023-06-13 18:04:45,117:INFO:              pandas: 1.5.3
2023-06-13 18:04:45,117:INFO:              jinja2: 3.1.2
2023-06-13 18:04:45,117:INFO:               scipy: 1.10.1
2023-06-13 18:04:45,117:INFO:              joblib: 1.2.0
2023-06-13 18:04:45,117:INFO:             sklearn: 1.2.2
2023-06-13 18:04:45,117:INFO:                pyod: 1.0.9
2023-06-13 18:04:45,117:INFO:            imblearn: 0.10.1
2023-06-13 18:04:45,117:INFO:   category_encoders: 2.6.1
2023-06-13 18:04:45,117:INFO:            lightgbm: 3.3.5
2023-06-13 18:04:45,117:INFO:               numba: 0.57.0
2023-06-13 18:04:45,117:INFO:            requests: 2.31.0
2023-06-13 18:04:45,117:INFO:          matplotlib: 3.7.1
2023-06-13 18:04:45,117:INFO:          scikitplot: 0.3.7
2023-06-13 18:04:45,117:INFO:         yellowbrick: 1.5
2023-06-13 18:04:45,117:INFO:              plotly: 5.15.0
2023-06-13 18:04:45,117:INFO:             kaleido: 0.2.1
2023-06-13 18:04:45,117:INFO:         statsmodels: 0.14.0
2023-06-13 18:04:45,117:INFO:              sktime: 0.17.0
2023-06-13 18:04:45,117:INFO:               tbats: 1.1.3
2023-06-13 18:04:45,117:INFO:            pmdarima: 2.0.3
2023-06-13 18:04:45,117:INFO:              psutil: 5.9.5
2023-06-13 18:04:45,117:INFO:PyCaret optional dependencies:
2023-06-13 18:04:45,159:INFO:                shap: Not installed
2023-06-13 18:04:45,159:INFO:           interpret: Not installed
2023-06-13 18:04:45,159:INFO:                umap: Not installed
2023-06-13 18:04:45,159:INFO:    pandas_profiling: Not installed
2023-06-13 18:04:45,159:INFO:  explainerdashboard: Not installed
2023-06-13 18:04:45,159:INFO:             autoviz: Not installed
2023-06-13 18:04:45,159:INFO:           fairlearn: Not installed
2023-06-13 18:04:45,159:INFO:             xgboost: Not installed
2023-06-13 18:04:45,159:INFO:            catboost: Not installed
2023-06-13 18:04:45,159:INFO:              kmodes: Not installed
2023-06-13 18:04:45,159:INFO:             mlxtend: Not installed
2023-06-13 18:04:45,159:INFO:       statsforecast: Not installed
2023-06-13 18:04:45,159:INFO:        tune_sklearn: Not installed
2023-06-13 18:04:45,159:INFO:                 ray: Not installed
2023-06-13 18:04:45,160:INFO:            hyperopt: Not installed
2023-06-13 18:04:45,160:INFO:              optuna: Not installed
2023-06-13 18:04:45,160:INFO:               skopt: Not installed
2023-06-13 18:04:45,160:INFO:              mlflow: 2.4.1
2023-06-13 18:04:45,160:INFO:              gradio: Not installed
2023-06-13 18:04:45,160:INFO:             fastapi: Not installed
2023-06-13 18:04:45,160:INFO:             uvicorn: Not installed
2023-06-13 18:04:45,160:INFO:              m2cgen: Not installed
2023-06-13 18:04:45,160:INFO:           evidently: Not installed
2023-06-13 18:04:45,160:INFO:               fugue: Not installed
2023-06-13 18:04:45,160:INFO:           streamlit: 1.23.1
2023-06-13 18:04:45,160:INFO:             prophet: Not installed
2023-06-13 18:04:45,160:INFO:None
2023-06-13 18:04:45,160:INFO:Set up data.
2023-06-13 18:04:45,201:INFO:Set up train/test split.
2023-06-13 18:04:45,263:INFO:Set up index.
2023-06-13 18:04:45,263:INFO:Set up folding strategy.
2023-06-13 18:04:45,263:INFO:Assigning column types.
2023-06-13 18:04:45,295:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-13 18:04:45,332:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 18:04:45,332:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-13 18:04:45,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:04:45,386:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:04:45,432:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 18:04:45,432:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-13 18:04:45,448:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:04:45,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:04:45,448:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-13 18:04:45,502:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-13 18:04:45,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:04:45,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:04:45,580:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-13 18:04:45,606:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:04:45,606:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:04:45,606:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-13 18:04:45,702:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:04:45,702:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:04:45,802:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:04:45,802:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:04:45,802:INFO:Preparing preprocessing pipeline...
2023-06-13 18:04:45,802:INFO:Set up label encoding.
2023-06-13 18:04:45,802:INFO:Set up simple imputation.
2023-06-13 18:04:45,833:INFO:Set up encoding of categorical features.
2023-06-13 18:04:45,833:INFO:Set up column name cleaning.
2023-06-13 18:04:46,503:INFO:Finished creating preprocessing pipeline.
2023-06-13 18:04:46,503:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-13 18:04:46,503:INFO:Creating final display dataframe.
2023-06-13 18:04:47,806:INFO:Setup _display_container:                     Description             Value
0                    Session id              4199
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape      (36354, 142)
5        Transformed data shape      (36354, 151)
6   Transformed train set shape      (25447, 151)
7    Transformed test set shape      (10907, 151)
8              Numeric features               140
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              9e2c
2023-06-13 18:04:47,913:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:04:47,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:04:47,989:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:04:47,989:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:04:47,989:INFO:Logging experiment in loggers
2023-06-13 18:04:48,239:INFO:SubProcess save_model() called ==================================
2023-06-13 18:04:48,270:INFO:Initializing save_model()
2023-06-13 18:04:48,270:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmp9ww52h6n\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-13 18:04:48,270:INFO:Adding model into prep_pipe
2023-06-13 18:04:48,270:WARNING:Only Model saved as it was a pipeline.
2023-06-13 18:04:48,270:INFO:C:\Users\alniquia\AppData\Local\Temp\tmp9ww52h6n\Transformation Pipeline.pkl saved in current working directory
2023-06-13 18:04:48,286:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-13 18:04:48,286:INFO:save_model() successfully completed......................................
2023-06-13 18:04:48,386:INFO:SubProcess save_model() end ==================================
2023-06-13 18:04:48,407:INFO:setup() successfully completed in 18.9s...............
2023-06-13 18:04:48,407:INFO:Initializing create_model()
2023-06-13 18:04:48,407:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D70D1F4730>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-13 18:04:48,407:INFO:Checking exceptions
2023-06-13 18:04:48,407:INFO:Importing libraries
2023-06-13 18:04:48,407:INFO:Copying training dataset
2023-06-13 18:04:48,507:INFO:Defining folds
2023-06-13 18:04:48,507:INFO:Declaring metric variables
2023-06-13 18:04:48,507:INFO:Importing untrained model
2023-06-13 18:04:48,507:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-13 18:04:48,507:INFO:Starting cross validation
2023-06-13 18:04:48,520:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 18:05:29,442:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:05:29,847:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:05:30,952:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 18:05:31,381:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 18:06:00,502:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:06:00,662:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:07:06,305:INFO:Entrenando modelo para gemGrab...
2023-06-13 18:07:06,559:INFO:train:  (36354, 142)
2023-06-13 18:07:06,561:INFO:test:  (12118, 142)
2023-06-13 18:07:34,199:INFO:PyCaret ClassificationExperiment
2023-06-13 18:07:34,199:INFO:Logging name: clf-default-name
2023-06-13 18:07:34,199:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-06-13 18:07:34,199:INFO:version 3.0.2
2023-06-13 18:07:34,200:INFO:Initializing setup()
2023-06-13 18:07:34,200:INFO:self.USI: 0ff0
2023-06-13 18:07:34,201:INFO:self._variable_keys: {'log_plots_param', 'y_train', 'fold_groups_param', 'idx', 'USI', 'fix_imbalance', 'X', 'data', 'fold_generator', 'y', 'n_jobs_param', 'target_param', 'fold_shuffle_param', 'X_test', 'pipeline', 'exp_id', 'X_train', 'logging_param', 'html_param', 'exp_name_log', 'is_multiclass', 'y_test', '_ml_usecase', 'seed', 'memory', 'gpu_n_jobs_param', 'gpu_param', '_available_plots'}
2023-06-13 18:07:34,201:INFO:Checking environment
2023-06-13 18:07:34,201:INFO:python_version: 3.10.10
2023-06-13 18:07:34,202:INFO:python_build: ('tags/v3.10.10:aad5f6a', 'Feb  7 2023 17:20:36')
2023-06-13 18:07:34,202:INFO:machine: AMD64
2023-06-13 18:07:34,202:INFO:platform: Windows-10-10.0.19044-SP0
2023-06-13 18:07:34,206:INFO:Memory: svmem(total=17034072064, available=5498073088, percent=67.7, used=11535998976, free=5498073088)
2023-06-13 18:07:34,206:INFO:Physical Core: 2
2023-06-13 18:07:34,207:INFO:Logical Core: 4
2023-06-13 18:07:34,207:INFO:Checking libraries
2023-06-13 18:07:34,208:INFO:System:
2023-06-13 18:07:34,208:INFO:    python: 3.10.10 (tags/v3.10.10:aad5f6a, Feb  7 2023, 17:20:36) [MSC v.1929 64 bit (AMD64)]
2023-06-13 18:07:34,208:INFO:executable: C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\Scripts\python.exe
2023-06-13 18:07:34,208:INFO:   machine: Windows-10-10.0.19044-SP0
2023-06-13 18:07:34,209:INFO:PyCaret required dependencies:
2023-06-13 18:07:34,209:INFO:                 pip: 23.1.2
2023-06-13 18:07:34,209:INFO:          setuptools: 65.5.0
2023-06-13 18:07:34,209:INFO:             pycaret: 3.0.2
2023-06-13 18:07:34,210:INFO:             IPython: 8.14.0
2023-06-13 18:07:34,210:INFO:          ipywidgets: 8.0.6
2023-06-13 18:07:34,210:INFO:                tqdm: 4.65.0
2023-06-13 18:07:34,211:INFO:               numpy: 1.23.5
2023-06-13 18:07:34,211:INFO:              pandas: 1.5.3
2023-06-13 18:07:34,211:INFO:              jinja2: 3.1.2
2023-06-13 18:07:34,211:INFO:               scipy: 1.10.1
2023-06-13 18:07:34,212:INFO:              joblib: 1.2.0
2023-06-13 18:07:34,212:INFO:             sklearn: 1.2.2
2023-06-13 18:07:34,212:INFO:                pyod: 1.0.9
2023-06-13 18:07:34,212:INFO:            imblearn: 0.10.1
2023-06-13 18:07:34,212:INFO:   category_encoders: 2.6.1
2023-06-13 18:07:34,213:INFO:            lightgbm: 3.3.5
2023-06-13 18:07:34,213:INFO:               numba: 0.57.0
2023-06-13 18:07:34,213:INFO:            requests: 2.31.0
2023-06-13 18:07:34,213:INFO:          matplotlib: 3.7.1
2023-06-13 18:07:34,214:INFO:          scikitplot: 0.3.7
2023-06-13 18:07:34,214:INFO:         yellowbrick: 1.5
2023-06-13 18:07:34,215:INFO:              plotly: 5.15.0
2023-06-13 18:07:34,215:INFO:             kaleido: 0.2.1
2023-06-13 18:07:34,215:INFO:         statsmodels: 0.14.0
2023-06-13 18:07:34,215:INFO:              sktime: 0.17.0
2023-06-13 18:07:34,216:INFO:               tbats: 1.1.3
2023-06-13 18:07:34,216:INFO:            pmdarima: 2.0.3
2023-06-13 18:07:34,216:INFO:              psutil: 5.9.5
2023-06-13 18:07:34,217:INFO:PyCaret optional dependencies:
2023-06-13 18:07:34,217:INFO:                shap: Not installed
2023-06-13 18:07:34,217:INFO:           interpret: Not installed
2023-06-13 18:07:34,218:INFO:                umap: Not installed
2023-06-13 18:07:34,219:INFO:    pandas_profiling: Not installed
2023-06-13 18:07:34,219:INFO:  explainerdashboard: Not installed
2023-06-13 18:07:34,219:INFO:             autoviz: Not installed
2023-06-13 18:07:34,219:INFO:           fairlearn: Not installed
2023-06-13 18:07:34,220:INFO:             xgboost: Not installed
2023-06-13 18:07:34,220:INFO:            catboost: Not installed
2023-06-13 18:07:34,221:INFO:              kmodes: Not installed
2023-06-13 18:07:34,221:INFO:             mlxtend: Not installed
2023-06-13 18:07:34,221:INFO:       statsforecast: Not installed
2023-06-13 18:07:34,221:INFO:        tune_sklearn: Not installed
2023-06-13 18:07:34,222:INFO:                 ray: Not installed
2023-06-13 18:07:34,222:INFO:            hyperopt: Not installed
2023-06-13 18:07:34,222:INFO:              optuna: Not installed
2023-06-13 18:07:34,222:INFO:               skopt: Not installed
2023-06-13 18:07:34,223:INFO:              mlflow: 2.4.1
2023-06-13 18:07:34,223:INFO:              gradio: Not installed
2023-06-13 18:07:34,223:INFO:             fastapi: Not installed
2023-06-13 18:07:34,223:INFO:             uvicorn: Not installed
2023-06-13 18:07:34,223:INFO:              m2cgen: Not installed
2023-06-13 18:07:34,224:INFO:           evidently: Not installed
2023-06-13 18:07:34,224:INFO:               fugue: Not installed
2023-06-13 18:07:34,224:INFO:           streamlit: 1.23.1
2023-06-13 18:07:34,224:INFO:             prophet: Not installed
2023-06-13 18:07:34,225:INFO:None
2023-06-13 18:07:34,225:INFO:Set up data.
2023-06-13 18:07:34,316:INFO:Set up train/test split.
2023-06-13 18:07:34,426:INFO:Set up index.
2023-06-13 18:07:34,428:INFO:Set up folding strategy.
2023-06-13 18:07:34,429:INFO:Assigning column types.
2023-06-13 18:07:34,466:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-06-13 18:07:34,542:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 18:07:34,544:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-13 18:07:34,590:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:07:34,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:07:34,660:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-06-13 18:07:34,662:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-13 18:07:34,703:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:07:34,703:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:07:34,704:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-06-13 18:07:34,759:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-13 18:07:34,791:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:07:34,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:07:34,847:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-06-13 18:07:34,866:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:07:34,866:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:07:34,866:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-06-13 18:07:34,966:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:07:34,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:07:35,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:07:35,058:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:07:35,061:INFO:Preparing preprocessing pipeline...
2023-06-13 18:07:35,066:INFO:Set up label encoding.
2023-06-13 18:07:35,066:INFO:Set up simple imputation.
2023-06-13 18:07:35,107:INFO:Set up encoding of categorical features.
2023-06-13 18:07:35,114:INFO:Set up column name cleaning.
2023-06-13 18:07:36,593:INFO:Finished creating preprocessing pipeline.
2023-06-13 18:07:36,603:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-13 18:07:36,604:INFO:Creating final display dataframe.
2023-06-13 18:07:38,356:INFO:Setup _display_container:                     Description             Value
0                    Session id               366
1                        Target       winner_team
2                   Target type            Binary
3                Target mapping        1: 0, 2: 1
4           Original data shape      (36354, 142)
5        Transformed data shape      (36354, 151)
6   Transformed train set shape      (25447, 151)
7    Transformed test set shape      (10907, 151)
8              Numeric features               140
9          Categorical features                 1
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding               500
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment      MlflowLogger
21              Experiment Name  clf-default-name
22                          USI              0ff0
2023-06-13 18:07:38,364:INFO:                    Description             Value
2023-06-13 18:07:38,364:INFO:0                    Session id               366
2023-06-13 18:07:38,364:INFO:1                        Target       winner_team
2023-06-13 18:07:38,364:INFO:2                   Target type            Binary
2023-06-13 18:07:38,364:INFO:3                Target mapping        1: 0, 2: 1
2023-06-13 18:07:38,364:INFO:4           Original data shape      (36354, 142)
2023-06-13 18:07:38,364:INFO:5        Transformed data shape      (36354, 151)
2023-06-13 18:07:38,364:INFO:6   Transformed train set shape      (25447, 151)
2023-06-13 18:07:38,364:INFO:7    Transformed test set shape      (10907, 151)
2023-06-13 18:07:38,364:INFO:8              Numeric features               140
2023-06-13 18:07:38,364:INFO:9          Categorical features                 1
2023-06-13 18:07:38,364:INFO:10                   Preprocess              True
2023-06-13 18:07:38,364:INFO:11              Imputation type            simple
2023-06-13 18:07:38,364:INFO:12           Numeric imputation              mean
2023-06-13 18:07:38,364:INFO:13       Categorical imputation              mode
2023-06-13 18:07:38,364:INFO:14     Maximum one-hot encoding               500
2023-06-13 18:07:38,364:INFO:15              Encoding method              None
2023-06-13 18:07:38,364:INFO:16               Fold Generator   StratifiedKFold
2023-06-13 18:07:38,364:INFO:17                  Fold Number                10
2023-06-13 18:07:38,364:INFO:18                     CPU Jobs                -1
2023-06-13 18:07:38,364:INFO:19                      Use GPU             False
2023-06-13 18:07:38,364:INFO:20               Log Experiment      MlflowLogger
2023-06-13 18:07:38,364:INFO:21              Experiment Name  clf-default-name
2023-06-13 18:07:38,364:INFO:22                          USI              0ff0
2023-06-13 18:07:38,476:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:07:38,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:07:38,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:07:38,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-06-13 18:07:38,576:INFO:Logging experiment in loggers
2023-06-13 18:07:38,834:INFO:SubProcess save_model() called ==================================
2023-06-13 18:07:38,857:INFO:Initializing save_model()
2023-06-13 18:07:38,857:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), model_name=C:\Users\alniquia\AppData\Local\Temp\tmpk0c1kolr\Transformation Pipeline, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=False, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-13 18:07:38,857:INFO:Adding model into prep_pipe
2023-06-13 18:07:38,857:WARNING:Only Model saved as it was a pipeline.
2023-06-13 18:07:38,871:INFO:C:\Users\alniquia\AppData\Local\Temp\tmpk0c1kolr\Transformation Pipeline.pkl saved in current working directory
2023-06-13 18:07:38,879:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2023-06-13 18:07:38,880:INFO:save_model() successfully completed......................................
2023-06-13 18:07:38,997:INFO:SubProcess save_model() end ==================================
2023-06-13 18:07:39,014:INFO:setup() successfully completed in 32.01s...............
2023-06-13 18:07:39,014:INFO:Initializing create_model()
2023-06-13 18:07:39,014:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D70E260B20>, estimator=lightgbm, fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-06-13 18:07:39,014:INFO:Checking exceptions
2023-06-13 18:07:39,029:WARNING:
2023-06-13 18:07:39,029:WARNING:Processing:   0%|                                                                                                                                                        | 0/4 [00:00<?, ?it/s]
2023-06-13 18:07:39,030:WARNING:[A
2023-06-13 18:07:39,030:INFO:Importing libraries
2023-06-13 18:07:39,030:INFO:Copying training dataset
2023-06-13 18:07:39,138:WARNING:
2023-06-13 18:07:39,139:WARNING:Processing:  25%|####################################                                                                                                            | 1/4 [00:00<00:00,  9.26it/s]
2023-06-13 18:07:39,139:WARNING:[A
2023-06-13 18:07:39,139:INFO:Defining folds
2023-06-13 18:07:39,139:INFO:Declaring metric variables
2023-06-13 18:07:39,140:INFO:Importing untrained model
2023-06-13 18:07:39,140:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-13 18:07:39,141:INFO:Starting cross validation
2023-06-13 18:07:39,143:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-06-13 18:07:51,163:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-13 18:07:51,172:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-13 18:07:51,289:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-13 18:07:51,303:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-13 18:07:52,306:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:07:52,408:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:07:52,580:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:07:52,648:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:07:53,179:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:07:53,321:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:07:53,829:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:07:53,845:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:07:54,251:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-06-13 18:07:54,264:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:07:55,205:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:07:56,185:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.12s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 18:07:56,230:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.05s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 18:07:56,301:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:07:56,936:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.08s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 18:07:57,402:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-13 18:07:57,430:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-13 18:07:58,084:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-13 18:07:58,464:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-13 18:07:59,050:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 1.30s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 18:08:00,165:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:108: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = pipeline._memory_transform(transformer, X, y)

2023-06-13 18:08:01,249:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-06-13 18:08:32,261:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:08:32,737:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:08:33,345:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:08:33,885:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 18:08:34,154:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 18:08:34,264:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 18:09:02,679:INFO:Calculating mean and std
2023-06-13 18:09:02,699:INFO:Creating metrics dataframe
2023-06-13 18:09:02,710:INFO:Finalizing model
2023-06-13 18:09:03,657:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning:

Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.


2023-06-13 18:09:04,844:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning:

Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.


2023-06-13 18:09:05,772:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning:

Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.


2023-06-13 18:09:27,900:INFO:Creating Dashboard logs
2023-06-13 18:09:27,900:INFO:Model: Light Gradient Boosting Machine
2023-06-13 18:09:28,008:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 4199, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-13 18:09:28,265:INFO:Initializing predict_model()
2023-06-13 18:09:28,266:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D70D1F4730>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4199, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D70E285FC0>)
2023-06-13 18:09:28,266:INFO:Checking exceptions
2023-06-13 18:09:28,266:INFO:Preloading libraries
2023-06-13 18:09:28,825:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\_distutils_hack\__init__.py:33: UserWarning:

Setuptools is replacing distutils.


2023-06-13 18:09:51,465:INFO:Uploading results into container
2023-06-13 18:09:51,467:INFO:Uploading model into container now
2023-06-13 18:09:51,508:INFO:_master_model_container: 1
2023-06-13 18:09:51,509:INFO:_display_container: 2
2023-06-13 18:09:51,510:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=4199, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-13 18:09:51,510:INFO:create_model() successfully completed......................................
2023-06-13 18:09:53,531:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:09:54,855:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:260: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_estimator = self._memory_fit(

2023-06-13 18:10:21,012:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 1.06s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-06-13 18:12:36,704:INFO:Calculating mean and std
2023-06-13 18:12:36,705:WARNING:
2023-06-13 18:12:36,705:WARNING:Processing:  75%|###########################################################################################################2                                   | 3/4 [04:57<01:50, 110.24s/it]
2023-06-13 18:12:36,705:WARNING:[A
2023-06-13 18:12:36,705:INFO:Creating metrics dataframe
2023-06-13 18:12:36,707:INFO:Finalizing model
2023-06-13 18:13:01,770:INFO:Creating Dashboard logs
2023-06-13 18:13:01,771:INFO:Model: Light Gradient Boosting Machine
2023-06-13 18:13:01,905:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 366, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-13 18:13:02,154:INFO:Initializing predict_model()
2023-06-13 18:13:02,154:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D70E260B20>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=366, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=False, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D773E181F0>)
2023-06-13 18:13:02,154:INFO:Checking exceptions
2023-06-13 18:13:02,154:INFO:Preloading libraries
2023-06-13 18:13:23,017:WARNING:
2023-06-13 18:13:23,017:WARNING:Processing: 100%|################################################################################################################################################| 4/4 [05:43<00:00, 88.12s/it]
2023-06-13 18:13:23,017:WARNING:[A
2023-06-13 18:13:23,017:WARNING:
2023-06-13 18:13:23,017:WARNING:                                                                                                                                                                                               
2023-06-13 18:13:23,017:WARNING:[A
2023-06-13 18:13:23,017:INFO:Uploading results into container
2023-06-13 18:13:23,017:INFO:Uploading model into container now
2023-06-13 18:13:23,033:INFO:      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC
2023-06-13 18:13:23,033:INFO:Fold                                                          
2023-06-13 18:13:23,033:INFO:0       0.6605  0.7419  0.6562  0.6510  0.6536  0.3208  0.3208
2023-06-13 18:13:23,033:INFO:1       0.6747  0.7526  0.6667  0.6667  0.6667  0.3489  0.3489
2023-06-13 18:13:23,033:INFO:2       0.6864  0.7530  0.6828  0.6773  0.6800  0.3726  0.3727
2023-06-13 18:13:23,033:INFO:3       0.6664  0.7451  0.6753  0.6526  0.6638  0.3330  0.3331
2023-06-13 18:13:23,033:INFO:4       0.6699  0.7447  0.6640  0.6608  0.6624  0.3396  0.3396
2023-06-13 18:13:23,033:INFO:5       0.6648  0.7297  0.6438  0.6603  0.6520  0.3289  0.3289
2023-06-13 18:13:23,033:INFO:6       0.6809  0.7509  0.6720  0.6731  0.6726  0.3615  0.3615
2023-06-13 18:13:23,033:INFO:7       0.6631  0.7409  0.6551  0.6546  0.6549  0.3259  0.3259
2023-06-13 18:13:23,033:INFO:8       0.6761  0.7478  0.6454  0.6759  0.6603  0.3511  0.3515
2023-06-13 18:13:23,033:INFO:9       0.6942  0.7580  0.6704  0.6928  0.6814  0.3875  0.3877
2023-06-13 18:13:23,033:INFO:Mean    0.6737  0.7465  0.6632  0.6665  0.6648  0.3470  0.3471
2023-06-13 18:13:23,033:INFO:Std     0.0104  0.0076  0.0121  0.0126  0.0099  0.0206  0.0206
2023-06-13 18:13:23,033:INFO:_master_model_container: 1
2023-06-13 18:13:23,033:INFO:_display_container: 2
2023-06-13 18:13:23,033:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=366, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-13 18:13:23,033:INFO:create_model() successfully completed......................................
2023-06-13 18:13:23,129:INFO:Initializing finalize_model()
2023-06-13 18:13:23,129:INFO:finalize_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D70E260B20>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=366, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2023-06-13 18:13:23,130:INFO:Finalizing LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=366, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-06-13 18:13:23,162:INFO:Initializing create_model()
2023-06-13 18:13:23,162:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D70E260B20>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=366, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, kwargs={})
2023-06-13 18:13:23,162:INFO:Checking exceptions
2023-06-13 18:13:23,163:INFO:Importing libraries
2023-06-13 18:13:23,164:INFO:Copying training dataset
2023-06-13 18:13:23,166:INFO:Defining folds
2023-06-13 18:13:23,166:INFO:Declaring metric variables
2023-06-13 18:13:23,166:INFO:Importing untrained model
2023-06-13 18:13:23,166:INFO:Declaring custom model
2023-06-13 18:13:23,169:INFO:Light Gradient Boosting Machine Imported successfully
2023-06-13 18:13:23,172:INFO:Cross validation set to False
2023-06-13 18:13:23,172:INFO:Fitting Model
2023-06-13 18:13:24,870:WARNING:C:\Users\alniquia\OneDrive - Telefonica\Documents\Projects\BrawlStars_Model\.venv\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning:

Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.


2023-06-13 18:13:26,248:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=366,
                                reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-06-13 18:13:26,248:INFO:create_model() successfully completed......................................
2023-06-13 18:13:26,357:INFO:Creating Dashboard logs
2023-06-13 18:13:26,358:INFO:Model: Light Gradient Boosting Machine
2023-06-13 18:13:26,486:INFO:Logged params: {'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 1.0, 'importance_type': 'split', 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 100, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': 366, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': 'warn', 'subsample': 1.0, 'subsample_for_bin': 200000, 'subsample_freq': 0}
2023-06-13 18:13:26,967:INFO:_master_model_container: 1
2023-06-13 18:13:26,967:INFO:_display_container: 2
2023-06-13 18:13:26,978:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=366,
                                reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-06-13 18:13:26,979:INFO:finalize_model() successfully completed......................................
2023-06-13 18:13:27,093:INFO:Initializing save_model()
2023-06-13 18:13:27,093:INFO:save_model(model=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=366,
                                reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), model_name=models/bs_predictor_gemGrab, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 TransformerWrapper(exclude=None, include=['event_map'],
                                    transformer=OneHotEncoder(cols=['event_map'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2023-06-13 18:13:27,093:INFO:Adding model into prep_pipe
2023-06-13 18:13:27,093:WARNING:Only Model saved as it was a pipeline.
2023-06-13 18:13:27,112:INFO:Transformation Pipeline and Model Successfully Saved
2023-06-13 18:13:27,112:INFO:models/bs_predictor_gemGrab.pkl saved in current working directory
2023-06-13 18:13:27,135:INFO:Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=366,
                                reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False)
2023-06-13 18:13:27,135:INFO:save_model() successfully completed......................................
2023-06-13 18:13:27,270:INFO:Initializing predict_model()
2023-06-13 18:13:27,270:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001D70E260B20>, estimator=Pipeline(memory=FastMemory(location=C:\Users\alniquia\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['avg_brawler_trophies_diff',
                                             'max_brawler_trophies_diff',
                                             'min_brawler_trophies_diff',
                                             'battle_power...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, importance_type='split',
                                learning_rate=0.1, max_depth=-1,
                                min_child_samples=20, min_child_weight=0.001,
                                min_split_gain=0.0, n_estimators=100, n_jobs=-1,
                                num_leaves=31, objective=None, random_state=366,
                                reg_alpha=0.0, reg_lambda=0.0, silent='warn',
                                subsample=1.0, subsample_for_bin=200000,
                                subsample_freq=0))],
         verbose=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001D758552710>)
2023-06-13 18:13:27,270:INFO:Checking exceptions
2023-06-13 18:13:27,270:INFO:Preloading libraries
2023-06-13 18:13:27,271:INFO:Set up data.
2023-06-13 18:13:27,317:INFO:Set up index.
2023-06-13 18:13:27,933:INFO:                             Model  Accuracy     AUC  Recall   Prec.      F1   Kappa    MCC
2023-06-13 18:13:27,933:INFO:0  Light Gradient Boosting Machine    0.6792  0.7513  0.6571  0.6804  0.6685  0.3578  0.358
2023-06-13 18:13:28,046:INFO:{'accuracy': 0.6791549760686582, 'f1': 0.6891092275707661, 'precision': 0.6780487804878049, 'recall': 0.7005364981303853}
